{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pyCEURmake API Documentation","text":""},{"location":"#ceurws.ceur_ws","title":"<code>ceur_ws</code>","text":""},{"location":"#ceurws.ceur_ws.Conference","title":"<code>Conference</code>","text":"<p>               Bases: <code>JSONAble</code></p> <p>Represents a conference</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class Conference(JSONAble):\n    \"\"\"\n    Represents a conference\n    \"\"\"\n\n    @staticmethod\n    def getSamples() -&gt; list[dict]:\n        \"\"\"\n        get sample records of the entity\n        \"\"\"\n        samples = [\n            {\n                \"id\": \"Vol-2436\",\n                \"fullTitle\": \"SIAM International Conference on Data Mining\",\n                \"homepage\": \"https://www.siam.org/Conferences/CM/Main/sdm19\",\n                \"acronym\": \"SDM 2019\",\n            }\n        ]\n        return samples\n</code></pre>"},{"location":"#ceurws.ceur_ws.Conference.getSamples","title":"<code>getSamples()</code>  <code>staticmethod</code>","text":"<p>get sample records of the entity</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>@staticmethod\ndef getSamples() -&gt; list[dict]:\n    \"\"\"\n    get sample records of the entity\n    \"\"\"\n    samples = [\n        {\n            \"id\": \"Vol-2436\",\n            \"fullTitle\": \"SIAM International Conference on Data Mining\",\n            \"homepage\": \"https://www.siam.org/Conferences/CM/Main/sdm19\",\n            \"acronym\": \"SDM 2019\",\n        }\n    ]\n    return samples\n</code></pre>"},{"location":"#ceurws.ceur_ws.ConferenceManager","title":"<code>ConferenceManager</code>","text":"<p>               Bases: <code>EntityManager</code></p> <p>Contains multiple ceurws sessions</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class ConferenceManager(EntityManager):\n    \"\"\"\n    Contains multiple ceurws sessions\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(\n            listName=\"conferences\",\n            clazz=Conference,\n            tableName=\"conferences\",\n            entityName=Conference.__class__.__name__,\n            primaryKey=\"id\",\n            entityPluralName=\"conferences\",\n            config=CEURWS.CONFIG,\n            name=self.__class__.__name__,\n        )\n</code></pre>"},{"location":"#ceurws.ceur_ws.Editor","title":"<code>Editor</code>","text":"<p>               Bases: <code>JSONAble</code></p> <p>Represents a volume editor</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class Editor(JSONAble):\n    \"\"\"\n    Represents a volume editor\n    \"\"\"\n\n    @staticmethod\n    def getSamples() -&gt; list[dict]:\n        \"\"\"\n        get sample records of the entity\n        \"\"\"\n        samples = [\n            {\n                \"id\": \"Vol-2436/John Doe\",\n                \"name\": \"John Doe\",\n                \"homepage\": \"http://www.example.org/john\",\n                \"country\": \"Germany\",\n                \"affiliation\": \"Leibniz University Hannover &amp; L3S Research Center\",\n                \"submitted\": False,\n            },\n            {\n                \"id\": \"Vol-2436/Jane Doe\",\n                \"name\": \"Jane Doe\",\n                \"homepage\": \"http://www.example.org/jane\",\n                \"country\": \"Germany\",\n                \"affiliation\": \"Technical University Dortmund\",\n                \"submitted\": True,\n            },\n        ]\n        return samples\n</code></pre>"},{"location":"#ceurws.ceur_ws.Editor.getSamples","title":"<code>getSamples()</code>  <code>staticmethod</code>","text":"<p>get sample records of the entity</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>@staticmethod\ndef getSamples() -&gt; list[dict]:\n    \"\"\"\n    get sample records of the entity\n    \"\"\"\n    samples = [\n        {\n            \"id\": \"Vol-2436/John Doe\",\n            \"name\": \"John Doe\",\n            \"homepage\": \"http://www.example.org/john\",\n            \"country\": \"Germany\",\n            \"affiliation\": \"Leibniz University Hannover &amp; L3S Research Center\",\n            \"submitted\": False,\n        },\n        {\n            \"id\": \"Vol-2436/Jane Doe\",\n            \"name\": \"Jane Doe\",\n            \"homepage\": \"http://www.example.org/jane\",\n            \"country\": \"Germany\",\n            \"affiliation\": \"Technical University Dortmund\",\n            \"submitted\": True,\n        },\n    ]\n    return samples\n</code></pre>"},{"location":"#ceurws.ceur_ws.EditorManager","title":"<code>EditorManager</code>","text":"<p>               Bases: <code>EntityManager</code></p> <p>Contains multiple ceurws editors</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class EditorManager(EntityManager):\n    \"\"\"\n    Contains multiple ceurws editors\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(\n            listName=\"editors\",\n            clazz=Editor,\n            tableName=\"editors\",\n            entityName=Session.__class__.__name__,\n            primaryKey=\"id\",\n            entityPluralName=\"editors\",\n            config=CEURWS.CONFIG,\n            name=self.__class__.__name__,\n        )\n</code></pre>"},{"location":"#ceurws.ceur_ws.Paper","title":"<code>Paper</code>","text":"<p>               Bases: <code>JSONAble</code></p> <p>Represents a paper</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class Paper(JSONAble):\n    \"\"\"\n    Represents a paper\n    \"\"\"\n\n    def __init__(\n        self,\n        id: str | None = None,\n        title: str | None = None,\n        type: str | None = None,\n        position: int | None = None,\n        pagesFrom: int | None = None,\n        pagesTo: int | None = None,\n        authors: dict | None = None,\n    ):\n        super().__init__()\n        self.id = id\n        self.title = title\n        self.type = type\n        self.position = position\n        self.pagesFrom = pagesFrom\n        self.pagesTo = pagesTo\n        self.authors = authors\n\n    @staticmethod\n    def getSamples() -&gt; list[dict]:\n        \"\"\"\n        get sample records of the entity\n        \"\"\"\n        samples = [\n            {  # id is constructed with volume and position\n                # \u2192 &lt;volNumber&gt;/s&lt;position&gt;/&lt;type&gt;_&lt;position_relative_to_type&gt;\n                \"id\": \"Vol-2436/s1/summary\",\n                \"type\": \"summary\",\n                \"position\": 0,\n                \"title\": \"1st Workshop on Evaluation and Experimental Design in Data Mining and \"\n                \"Machine Learning (EDML 2019)\",\n                \"pdf\": \"http://ceur-ws.org/Vol-2436/summary.pdf\",\n                \"pagesFrom\": 1,\n                \"pagesTo\": 3,\n                \"authors\": [\n                    \"Eirini Ntoutsi\",\n                    \"Erich Schubert\",\n                    \"Arthur Zimek\",\n                    \"Albrecht Zimmermann\",\n                ],\n            },\n            {\n                \"id\": \"Vol-2436/s1/invited_1\",\n                \"type\": \"invited\",\n                \"position\": 1,\n                \"title\": \"Evaluation of Unsupervised Learning Results: Making the Seemingly Impossible Possible\",\n                \"pdf\": \"http://ceur-ws.org/Vol-2436/invited_1.pdf\",\n                \"pagesFrom\": 4,\n                \"pagesTo\": 4,\n                \"authors\": [\"Ricardo J. G. B. Campello\"],\n            },\n            {\n                \"id\": \"Vol-2436/s1/article_1\",\n                \"type\": \"article\",\n                \"position\": 2,\n                \"title\": \"EvalNE: A Framework for Evaluating Network Embeddings on Link Prediction\",\n                \"pdf\": \"http://ceur-ws.org/Vol-2436/article_2.pdf\",\n                \"pagesFrom\": 5,\n                \"pagesTo\": 13,\n                \"authors\": [\n                    \"Alexandru Mara\",\n                    \"Jefrey Lijffijt\",\n                    \"Tijl De Bie\",\n                ],\n            },\n        ]\n        return samples\n\n    def __str__(self):\n        \"\"\"\n        return my string representation\n\n        Returns:\n            str: my text representation\n        \"\"\"\n        text = self.title\n        return text\n</code></pre>"},{"location":"#ceurws.ceur_ws.Paper.__str__","title":"<code>__str__()</code>","text":"<p>return my string representation</p> <p>Returns:</p> Name Type Description <code>str</code> <p>my text representation</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def __str__(self):\n    \"\"\"\n    return my string representation\n\n    Returns:\n        str: my text representation\n    \"\"\"\n    text = self.title\n    return text\n</code></pre>"},{"location":"#ceurws.ceur_ws.Paper.getSamples","title":"<code>getSamples()</code>  <code>staticmethod</code>","text":"<p>get sample records of the entity</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>@staticmethod\ndef getSamples() -&gt; list[dict]:\n    \"\"\"\n    get sample records of the entity\n    \"\"\"\n    samples = [\n        {  # id is constructed with volume and position\n            # \u2192 &lt;volNumber&gt;/s&lt;position&gt;/&lt;type&gt;_&lt;position_relative_to_type&gt;\n            \"id\": \"Vol-2436/s1/summary\",\n            \"type\": \"summary\",\n            \"position\": 0,\n            \"title\": \"1st Workshop on Evaluation and Experimental Design in Data Mining and \"\n            \"Machine Learning (EDML 2019)\",\n            \"pdf\": \"http://ceur-ws.org/Vol-2436/summary.pdf\",\n            \"pagesFrom\": 1,\n            \"pagesTo\": 3,\n            \"authors\": [\n                \"Eirini Ntoutsi\",\n                \"Erich Schubert\",\n                \"Arthur Zimek\",\n                \"Albrecht Zimmermann\",\n            ],\n        },\n        {\n            \"id\": \"Vol-2436/s1/invited_1\",\n            \"type\": \"invited\",\n            \"position\": 1,\n            \"title\": \"Evaluation of Unsupervised Learning Results: Making the Seemingly Impossible Possible\",\n            \"pdf\": \"http://ceur-ws.org/Vol-2436/invited_1.pdf\",\n            \"pagesFrom\": 4,\n            \"pagesTo\": 4,\n            \"authors\": [\"Ricardo J. G. B. Campello\"],\n        },\n        {\n            \"id\": \"Vol-2436/s1/article_1\",\n            \"type\": \"article\",\n            \"position\": 2,\n            \"title\": \"EvalNE: A Framework for Evaluating Network Embeddings on Link Prediction\",\n            \"pdf\": \"http://ceur-ws.org/Vol-2436/article_2.pdf\",\n            \"pagesFrom\": 5,\n            \"pagesTo\": 13,\n            \"authors\": [\n                \"Alexandru Mara\",\n                \"Jefrey Lijffijt\",\n                \"Tijl De Bie\",\n            ],\n        },\n    ]\n    return samples\n</code></pre>"},{"location":"#ceurws.ceur_ws.PaperManager","title":"<code>PaperManager</code>","text":"<p>               Bases: <code>EntityManager</code></p> <p>Contains multiple ceurws papers</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class PaperManager(EntityManager):\n    \"\"\"\n    Contains multiple ceurws papers\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(\n            listName=\"papers\",\n            clazz=Paper,\n            tableName=\"papers\",\n            entityName=Paper.__class__.__name__,\n            primaryKey=\"id\",\n            entityPluralName=\"papers\",\n            config=CEURWS.CONFIG,\n            handleInvalidListTypes=True,\n            listSeparator=\",\",\n            name=self.__class__.__name__,\n        )\n</code></pre>"},{"location":"#ceurws.ceur_ws.Session","title":"<code>Session</code>","text":"<p>               Bases: <code>JSONAble</code></p> <p>Represents a session in ceur-ws</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class Session(JSONAble):\n    \"\"\"\n    Represents a session in ceur-ws\n    \"\"\"\n\n    def __init__(self, id: str | None, title: str | None, position: int | None, papers: dict[str, \"Paper\"] | None):\n        \"\"\"\n        constructor\n        \"\"\"\n        super().__init__()\n        self.id = id\n        self.title = title\n        self.position = position\n        self._papers = papers\n\n    @staticmethod\n    def getSamples() -&gt; list[dict]:\n        \"\"\"\n        get sample records of the entity\n        \"\"\"\n        samples = [\n            {\n                \"id\": \"Vol-2436/s1\",  # id is constructed with volume and position \u2192 &lt;volNumber&gt;/s&lt;position&gt;\n                \"title\": \"Information Technologies and Intelligent Decision Making Systems II\",\n                \"position\": 1,\n                \"papers\": {  # 1:n relation / command chain\n                    \"VOL-2436/s1/p1\": Paper,\n                    \"VOL-2436/s1/p2\": Paper,\n                },\n            }\n        ]\n        return samples\n\n    @property\n    def papers(self, cached: bool = False):  # dict: str\u2192Paper\n        if cached:\n            # check if cached\n            pass\n        else:\n            # load papers\n            if cached:\n                # set papers\n                pass\n        return self._papers\n\n    @papers.setter\n    def papers(self, paper: Paper):\n        # ToDo: Adjust to proper 1:n handling\n        if hasattr(self, \"_papers\") and isinstance(self._papers, dict) and paper.id:\n            self._papers[paper.id] = paper\n        else:\n            self._papers = paper\n</code></pre>"},{"location":"#ceurws.ceur_ws.Session.__init__","title":"<code>__init__(id, title, position, papers)</code>","text":"<p>constructor</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def __init__(self, id: str | None, title: str | None, position: int | None, papers: dict[str, \"Paper\"] | None):\n    \"\"\"\n    constructor\n    \"\"\"\n    super().__init__()\n    self.id = id\n    self.title = title\n    self.position = position\n    self._papers = papers\n</code></pre>"},{"location":"#ceurws.ceur_ws.Session.getSamples","title":"<code>getSamples()</code>  <code>staticmethod</code>","text":"<p>get sample records of the entity</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>@staticmethod\ndef getSamples() -&gt; list[dict]:\n    \"\"\"\n    get sample records of the entity\n    \"\"\"\n    samples = [\n        {\n            \"id\": \"Vol-2436/s1\",  # id is constructed with volume and position \u2192 &lt;volNumber&gt;/s&lt;position&gt;\n            \"title\": \"Information Technologies and Intelligent Decision Making Systems II\",\n            \"position\": 1,\n            \"papers\": {  # 1:n relation / command chain\n                \"VOL-2436/s1/p1\": Paper,\n                \"VOL-2436/s1/p2\": Paper,\n            },\n        }\n    ]\n    return samples\n</code></pre>"},{"location":"#ceurws.ceur_ws.SessionManager","title":"<code>SessionManager</code>","text":"<p>               Bases: <code>EntityManager</code></p> <p>Contains multiple ceurws sessions</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class SessionManager(EntityManager):\n    \"\"\"\n    Contains multiple ceurws sessions\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(\n            listName=\"sessions\",\n            clazz=Session,\n            tableName=\"sessions\",\n            entityName=Session.__class__.__name__,\n            primaryKey=\"id\",\n            # ToDo: check if just the title is a sufficent key or if an ID must be added\n            entityPluralName=\"sessions\",\n            config=CEURWS.CONFIG,\n            name=self.__class__.__name__,\n        )\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume","title":"<code>Volume</code>","text":"<p>               Bases: <code>JSONAble</code></p> <p>Represents a volume in ceur-ws</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class Volume(JSONAble):\n    \"\"\"\n    Represents a volume in ceur-ws\n    \"\"\"\n\n    def __init__(\n        self,\n        number: int | None = None,\n        url: str | None = None,\n        title: str | None = None,\n        fullTitle: str | None = None,\n        acronym: str | None = None,\n        lang: str | None = None,\n        location: str | None = None,\n        country: str | None = None,\n        countryWikidataId: str | None = None,\n        region: str | None = None,\n        city: str | None = None,\n        cityWikidataId: str | None = None,\n        ordinal: int | None = None,\n        date: datetime.datetime | None = None,\n        dateFrom: datetime.datetime | None = None,\n        dateTo: datetime.datetime | None = None,\n        pubYear: str | None = None,\n        pubDate: datetime.datetime | None = None,\n        submitDate: datetime.datetime | None = None,\n        valid: bool = True,\n        conference: Optional[\"Conference\"] = None,\n        editors: list[\"Editor\"] | None = None,\n        sessions: list[\"Session\"] | None = None,\n        virtualEvent: bool = False,\n        submittedBy: str | None = None,\n    ):\n        \"\"\"\n        constructor\n        \"\"\"\n        self.number = number\n        self.url = url\n        self.title = title\n        self.fullTitle = fullTitle\n        self.acronym = acronym\n        self.lang = lang\n        self.location = location\n        self.country = country\n        self.countryWikidataId = countryWikidataId\n        self.region = region\n        self.city = city\n        self.cityWikidataId = cityWikidataId\n        self.ordinal = ordinal\n        self.date = date\n        self.dateFrom = dateFrom\n        self.dateTo = dateTo\n        self.pubYear = pubYear\n        self.pubDate = pubDate\n        self.submitDate = submitDate\n        self.valid = valid\n        self.conference = conference\n        self.editors = editors\n        self.sessions = sessions\n        self.virtualEvent = virtualEvent\n        self.submittedBy = submittedBy\n\n    def getSamples(self):\n        samples = [\n            {\n                \"number\": 2436,\n                \"url\": \"http://ceur-ws.org/Vol-2436/\",\n                \"title\": \"Evaluation and Experimental Design in Data Mining and Machine Learning\",\n                \"fullTitle\": \"1st Workshop on Evaluation and Experimental Design in Data Mining and Machine Learning\",\n                \"acronym\": \"EDML 2019\",\n                \"lang\": \"en\",\n                \"location\": \"Calgary, Alberta, Canada\",\n                \"country\": \"Canada\",\n                \"region\": \"Alberta\",\n                \"city\": \"Calgary\",\n                \"ordinal\": 1,\n                \"date\": datetime.datetime(year=2019, month=5, day=4),\n                \"dateFrom\": \"\",\n                \"dateTo\": \"\",\n                \"pubYear\": 2019,\n                \"pubDate\": \"2019-09-08\",\n                \"submitDate\": \"2019-07-28\",\n                \"valid\": True,\n                \"conference\": Conference,\n                \"editors\": [Editor],\n                \"sessions\": [Session],\n                \"virtualEvent\": False,\n            }\n        ]\n        return samples\n\n    def getVolumeNumber(self):\n        \"\"\"\n        get number of the volume\n        \"\"\"\n        number = getattr(self, \"number\", \"Volume has no number\")\n        return number\n\n    def getVolumeUrl(self) -&gt; str | None:\n        \"\"\"\n        get the url of the volume page\n        \"\"\"\n        number = self.number\n        if number is None:\n            return None\n        url = self.getVolumeUrlOf(number)\n        return url\n\n    @staticmethod\n    def getVolumeUrlOf(\n        number: str | int,\n    ) -&gt; str | None:\n        \"\"\"\n        get the volume url of the given volume number\n        Args:\n            number: volume number\n        \"\"\"\n        url = None\n        if number is not None:\n            url = f\"http://ceur-ws.org/Vol-{number}/\"\n        return url\n\n    def isVirtualEvent(self) -&gt; bool:\n        \"\"\"\n        Returns True if the event is a virtual event\n        \"\"\"\n        return getattr(self, \"virtualEvent\", False)\n\n    def normalize(self):\n        \"\"\"\n        Tries to normalize the properties e.g. breaking loctime into designated location and time properties\n        Example: 'Vienna, Austria, July 25th, 2022'\n        \"\"\"\n        pass\n\n    def get_loctime(self) -&gt; str | None:\n        \"\"\"\n        get the loctime\n        \"\"\"\n        loctime = getattr(self, \"loctime\", None)\n        if loctime is None:\n            td_title = getattr(self, \"tdtitle\", None)\n            if td_title:\n                title_parts = td_title.split(\",\")\n                del title_parts[0]\n                loctime = \",\".join(title_parts)\n                loctime = loctime.strip(\".\")\n                self.loctime = loctime\n            else:\n                pass\n        elif not isinstance(loctime, str):\n            loctime = None\n        return loctime\n\n    def resolveLoctime(self):\n        \"\"\"\n        Resolve the loctime property by breaking it down to city, region, country, dateFrom, and dateTo\n        \"\"\"\n        loctime = self.get_loctime()\n        if loctime is None:\n            return None\n        dateFrom, dateTo = self.extractDates(loctime)\n        if dateFrom is not None:\n            self.dateFrom = dateFrom\n        if dateTo is not None:\n            self.dateTo = dateTo\n        self.extractAndSetLocation(locationStr=loctime)\n\n    def extractAndSetLocation(self, locationStr: str):\n        \"\"\"\n        Extracts the location from the given string and returns the found city and country\n        ToDo: Once the EventReferenceParser from cc is updated to support city country combinations switch to it\n        Args:\n            locationStr: string to extract the locations from\n        \"\"\"\n        parser = self.__class__.__dict__.get(\"locationparser\")\n        if parser is None:\n            parser = LocationContext.fromCache()\n            self.__class__.locationparser = parser\n        locationStr = self.removePartsMatching(locationStr, pattern=r\"\\d\")\n        for month in calendar.month_name:\n            if month == \"\":\n                continue\n            locationStr = locationStr.replace(month, \" \")\n        locations = parser.locateLocation(locationStr, verbose=True)\n        locations = self.rankLocations(locationStr, locations)\n        city = None\n        cityWikidataId = None\n        country = None\n        countryWikidataId = None\n        if locations is not None and len(locations) &gt; 0:\n            bestMatch = locations[0]\n            if isinstance(bestMatch, City):\n                city = bestMatch.name\n                cityWikidataId = bestMatch.wikidataid\n                country = bestMatch.country.name\n                countryWikidataId = bestMatch.country.wikidataid\n            elif isinstance(bestMatch, Country):\n                country = bestMatch.wikidataid\n        virtualEventKeywords = [\"virtual\", \"online\"]\n        for keyword in virtualEventKeywords:\n            if keyword in locationStr.lower():\n                self.virtualEvent = True\n        if city is not None:\n            self.city = city\n            self.cityWikidataId = cityWikidataId\n        if countryWikidataId is not None:\n            self.country = country\n            self.countryWikidataId = countryWikidataId\n\n    def extractDates(\n        self, dateStr: str, durationThreshold: int = 11\n    ) -&gt; tuple[datetime.date | None, datetime.date | None]:\n        \"\"\" \"\n        Extracts the start and end time from the given string\n        optimized for the format of the loctime property\n        Args:\n            dateStr: string to extract the dates from\n            durationThreshold: number of days allowed between two extracted dates\n        \"\"\"\n        dateFrom = None\n        dateTo = None\n        if dateStr is None:\n            return None, None\n        # normalize certain foreign language month names that occur regularly\n        if \"novembro\" in dateStr.lower():\n            dateStr = dateStr.lower().replace(\"novembro\", \"november\")\n        loctimeParts = re.split(\"[,)(]\", dateStr)\n        if re.fullmatch(r\"\\d{4}\", loctimeParts[-1].strip()):\n            year = loctimeParts[-1].strip()\n            rawDate = loctimeParts[-2].strip()\n            if len(loctimeParts) &gt;= 3 and loctimeParts[-3].lower().strip() in [\n                cn.lower() for cn in calendar.month_name\n            ]:\n                rawDate = f\"{loctimeParts[-3]} {rawDate}\"\n            dateParts: list = re.split(\"[-\u2013\u2010&amp;]| to | and \", rawDate)\n            try:\n                if len(dateParts) == 1:\n                    dateFrom = dateutil.parser.parse(f\"{dateParts[0]} {year}\")\n                    dateTo = dateFrom\n                elif len(dateParts) == 2:\n                    dateParts.sort(key=lambda r: len(r), reverse=True)\n                    dateOne = dateutil.parser.parse(f\"{dateParts[0]} {year}\")\n                    if len(dateParts[-1].strip()) &lt;= 4:\n                        dayMonthParts = dateParts[0].split(\" \")\n                        dayMonthParts.sort(key=lambda r: len(r), reverse=True)\n                        endDate = dayMonthParts[0] + dateParts[1]\n                        dateTwo = dateutil.parser.parse(f\"{endDate} {year}\")\n                    else:\n                        dateTwo = dateutil.parser.parse(f\"{dateParts[1]} {year}\")\n                    dates = [dateOne, dateTwo]\n                    dates.sort()\n                    dateFrom = dates[0]\n                    dateTo = dates[1]\n            except Exception:\n                pass\n            if dateTo is not None and dateFrom is not None:\n                delta = dateTo - dateFrom\n                if delta &lt; datetime.timedelta():\n                    print(\"Error this should not be possible\")\n                elif delta &gt; datetime.timedelta(days=durationThreshold):\n                    print(\n                        self.number,\n                        f\"Event with a duration of more than {durationThreshold} days seems suspicious\",\n                    )\n                else:\n                    return dateFrom.date(), dateTo.date()\n            else:\n                print(self.number, dateStr, \"\u2192 Dates could not be extracted\")\n            return None, None\n        else:\n            # corner case\n            return None, None\n\n    @staticmethod\n    def removePartsMatching(value: str, pattern: str, separator=\",\"):\n        \"\"\"\n        Removes parts from the given value matching the pattern\n        \"\"\"\n        parts = value.split(separator)\n        resParts = []\n        for part in parts:\n            if re.search(pattern, part) is None:\n                resParts.append(part)\n        resValue = separator.join(resParts)\n        return resValue\n\n    @staticmethod\n    def rankLocations(locationStr: str, locations: list[Location]):\n        \"\"\"\n        rank the given locations to find the best match to the given location string\n        Args:\n            locationStr: location string\n            locations: list of locations objects\n        \"\"\"\n        rankedLocations = []\n        for location in locations:\n            locationsToCheck = []\n            if isinstance(location, City):\n                locationsToCheck = [\n                    location,\n                    location.region,\n                    location.country,\n                ]\n            elif isinstance(location, Region):\n                locationsToCheck = [location, location.country]\n            elif isinstance(location, Country):\n                locationsToCheck = [location]\n            score = 0\n            for ltc in locationsToCheck:\n                if ltc.name in locationStr:\n                    score += 1\n            rankedLocations.append((score, location))\n        rankedLocations.sort(key=lambda scoreTuple: scoreTuple[0], reverse=True)\n        return [location for score, location in rankedLocations]\n\n    def __str__(self):\n        text = f\"Vol-{self.number}\"\n        return text\n\n    @property\n    def sessions(self):\n        \"\"\"\n        sessions of this volume\n        \"\"\"\n        return self._sessions\n\n    @sessions.setter\n    def sessions(self, session):\n        # ToDo: Adjust to proper 1:n handling\n        if hasattr(self, \"_sessions\") and isinstance(self._sessions, list):\n            self._sessions.append(session)\n        else:\n            self._sessions = session\n\n    @property\n    def papers(self):\n        \"\"\"\n        papers of this volume\n        \"\"\"\n        return\n\n    def extractValuesFromVolumePage(self, timeout: float = 3) -&gt; tuple[dict | None, BeautifulSoup | None]:\n        \"\"\"\n        extract values from the given volume page\n        \"\"\"\n        self.desc = \"?\"\n        self.h1 = \"?\"\n        if self.url is None:\n            return None, None\n        volumeParser = VolumeParser(timeout=timeout)\n        parseDict, soup = volumeParser.parse_volume(self.getVolumeNumber())\n        self.fromDict(parseDict)\n        return parseDict, soup\n\n    def getSubmittingEditor(self):\n        \"\"\"\n        Returns the Editor that submitted the volume\n        \"\"\"\n        submitter = None\n        if hasattr(self, \"editors\"):\n            for editor in self.editors:\n                if isinstance(editor, Editor) and getattr(editor, \"submitted\", False):\n                    submitter = editor\n                    break\n        return submitter\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.papers","title":"<code>papers</code>  <code>property</code>","text":"<p>papers of this volume</p>"},{"location":"#ceurws.ceur_ws.Volume.sessions","title":"<code>sessions</code>  <code>property</code> <code>writable</code>","text":"<p>sessions of this volume</p>"},{"location":"#ceurws.ceur_ws.Volume.__init__","title":"<code>__init__(number=None, url=None, title=None, fullTitle=None, acronym=None, lang=None, location=None, country=None, countryWikidataId=None, region=None, city=None, cityWikidataId=None, ordinal=None, date=None, dateFrom=None, dateTo=None, pubYear=None, pubDate=None, submitDate=None, valid=True, conference=None, editors=None, sessions=None, virtualEvent=False, submittedBy=None)</code>","text":"<p>constructor</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def __init__(\n    self,\n    number: int | None = None,\n    url: str | None = None,\n    title: str | None = None,\n    fullTitle: str | None = None,\n    acronym: str | None = None,\n    lang: str | None = None,\n    location: str | None = None,\n    country: str | None = None,\n    countryWikidataId: str | None = None,\n    region: str | None = None,\n    city: str | None = None,\n    cityWikidataId: str | None = None,\n    ordinal: int | None = None,\n    date: datetime.datetime | None = None,\n    dateFrom: datetime.datetime | None = None,\n    dateTo: datetime.datetime | None = None,\n    pubYear: str | None = None,\n    pubDate: datetime.datetime | None = None,\n    submitDate: datetime.datetime | None = None,\n    valid: bool = True,\n    conference: Optional[\"Conference\"] = None,\n    editors: list[\"Editor\"] | None = None,\n    sessions: list[\"Session\"] | None = None,\n    virtualEvent: bool = False,\n    submittedBy: str | None = None,\n):\n    \"\"\"\n    constructor\n    \"\"\"\n    self.number = number\n    self.url = url\n    self.title = title\n    self.fullTitle = fullTitle\n    self.acronym = acronym\n    self.lang = lang\n    self.location = location\n    self.country = country\n    self.countryWikidataId = countryWikidataId\n    self.region = region\n    self.city = city\n    self.cityWikidataId = cityWikidataId\n    self.ordinal = ordinal\n    self.date = date\n    self.dateFrom = dateFrom\n    self.dateTo = dateTo\n    self.pubYear = pubYear\n    self.pubDate = pubDate\n    self.submitDate = submitDate\n    self.valid = valid\n    self.conference = conference\n    self.editors = editors\n    self.sessions = sessions\n    self.virtualEvent = virtualEvent\n    self.submittedBy = submittedBy\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.extractAndSetLocation","title":"<code>extractAndSetLocation(locationStr)</code>","text":"<p>Extracts the location from the given string and returns the found city and country ToDo: Once the EventReferenceParser from cc is updated to support city country combinations switch to it Args:     locationStr: string to extract the locations from</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def extractAndSetLocation(self, locationStr: str):\n    \"\"\"\n    Extracts the location from the given string and returns the found city and country\n    ToDo: Once the EventReferenceParser from cc is updated to support city country combinations switch to it\n    Args:\n        locationStr: string to extract the locations from\n    \"\"\"\n    parser = self.__class__.__dict__.get(\"locationparser\")\n    if parser is None:\n        parser = LocationContext.fromCache()\n        self.__class__.locationparser = parser\n    locationStr = self.removePartsMatching(locationStr, pattern=r\"\\d\")\n    for month in calendar.month_name:\n        if month == \"\":\n            continue\n        locationStr = locationStr.replace(month, \" \")\n    locations = parser.locateLocation(locationStr, verbose=True)\n    locations = self.rankLocations(locationStr, locations)\n    city = None\n    cityWikidataId = None\n    country = None\n    countryWikidataId = None\n    if locations is not None and len(locations) &gt; 0:\n        bestMatch = locations[0]\n        if isinstance(bestMatch, City):\n            city = bestMatch.name\n            cityWikidataId = bestMatch.wikidataid\n            country = bestMatch.country.name\n            countryWikidataId = bestMatch.country.wikidataid\n        elif isinstance(bestMatch, Country):\n            country = bestMatch.wikidataid\n    virtualEventKeywords = [\"virtual\", \"online\"]\n    for keyword in virtualEventKeywords:\n        if keyword in locationStr.lower():\n            self.virtualEvent = True\n    if city is not None:\n        self.city = city\n        self.cityWikidataId = cityWikidataId\n    if countryWikidataId is not None:\n        self.country = country\n        self.countryWikidataId = countryWikidataId\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.extractDates","title":"<code>extractDates(dateStr, durationThreshold=11)</code>","text":"<p>\" Extracts the start and end time from the given string optimized for the format of the loctime property Args:     dateStr: string to extract the dates from     durationThreshold: number of days allowed between two extracted dates</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def extractDates(\n    self, dateStr: str, durationThreshold: int = 11\n) -&gt; tuple[datetime.date | None, datetime.date | None]:\n    \"\"\" \"\n    Extracts the start and end time from the given string\n    optimized for the format of the loctime property\n    Args:\n        dateStr: string to extract the dates from\n        durationThreshold: number of days allowed between two extracted dates\n    \"\"\"\n    dateFrom = None\n    dateTo = None\n    if dateStr is None:\n        return None, None\n    # normalize certain foreign language month names that occur regularly\n    if \"novembro\" in dateStr.lower():\n        dateStr = dateStr.lower().replace(\"novembro\", \"november\")\n    loctimeParts = re.split(\"[,)(]\", dateStr)\n    if re.fullmatch(r\"\\d{4}\", loctimeParts[-1].strip()):\n        year = loctimeParts[-1].strip()\n        rawDate = loctimeParts[-2].strip()\n        if len(loctimeParts) &gt;= 3 and loctimeParts[-3].lower().strip() in [\n            cn.lower() for cn in calendar.month_name\n        ]:\n            rawDate = f\"{loctimeParts[-3]} {rawDate}\"\n        dateParts: list = re.split(\"[-\u2013\u2010&amp;]| to | and \", rawDate)\n        try:\n            if len(dateParts) == 1:\n                dateFrom = dateutil.parser.parse(f\"{dateParts[0]} {year}\")\n                dateTo = dateFrom\n            elif len(dateParts) == 2:\n                dateParts.sort(key=lambda r: len(r), reverse=True)\n                dateOne = dateutil.parser.parse(f\"{dateParts[0]} {year}\")\n                if len(dateParts[-1].strip()) &lt;= 4:\n                    dayMonthParts = dateParts[0].split(\" \")\n                    dayMonthParts.sort(key=lambda r: len(r), reverse=True)\n                    endDate = dayMonthParts[0] + dateParts[1]\n                    dateTwo = dateutil.parser.parse(f\"{endDate} {year}\")\n                else:\n                    dateTwo = dateutil.parser.parse(f\"{dateParts[1]} {year}\")\n                dates = [dateOne, dateTwo]\n                dates.sort()\n                dateFrom = dates[0]\n                dateTo = dates[1]\n        except Exception:\n            pass\n        if dateTo is not None and dateFrom is not None:\n            delta = dateTo - dateFrom\n            if delta &lt; datetime.timedelta():\n                print(\"Error this should not be possible\")\n            elif delta &gt; datetime.timedelta(days=durationThreshold):\n                print(\n                    self.number,\n                    f\"Event with a duration of more than {durationThreshold} days seems suspicious\",\n                )\n            else:\n                return dateFrom.date(), dateTo.date()\n        else:\n            print(self.number, dateStr, \"\u2192 Dates could not be extracted\")\n        return None, None\n    else:\n        # corner case\n        return None, None\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.extractValuesFromVolumePage","title":"<code>extractValuesFromVolumePage(timeout=3)</code>","text":"<p>extract values from the given volume page</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def extractValuesFromVolumePage(self, timeout: float = 3) -&gt; tuple[dict | None, BeautifulSoup | None]:\n    \"\"\"\n    extract values from the given volume page\n    \"\"\"\n    self.desc = \"?\"\n    self.h1 = \"?\"\n    if self.url is None:\n        return None, None\n    volumeParser = VolumeParser(timeout=timeout)\n    parseDict, soup = volumeParser.parse_volume(self.getVolumeNumber())\n    self.fromDict(parseDict)\n    return parseDict, soup\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.getSubmittingEditor","title":"<code>getSubmittingEditor()</code>","text":"<p>Returns the Editor that submitted the volume</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def getSubmittingEditor(self):\n    \"\"\"\n    Returns the Editor that submitted the volume\n    \"\"\"\n    submitter = None\n    if hasattr(self, \"editors\"):\n        for editor in self.editors:\n            if isinstance(editor, Editor) and getattr(editor, \"submitted\", False):\n                submitter = editor\n                break\n    return submitter\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.getVolumeNumber","title":"<code>getVolumeNumber()</code>","text":"<p>get number of the volume</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def getVolumeNumber(self):\n    \"\"\"\n    get number of the volume\n    \"\"\"\n    number = getattr(self, \"number\", \"Volume has no number\")\n    return number\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.getVolumeUrl","title":"<code>getVolumeUrl()</code>","text":"<p>get the url of the volume page</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def getVolumeUrl(self) -&gt; str | None:\n    \"\"\"\n    get the url of the volume page\n    \"\"\"\n    number = self.number\n    if number is None:\n        return None\n    url = self.getVolumeUrlOf(number)\n    return url\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.getVolumeUrlOf","title":"<code>getVolumeUrlOf(number)</code>  <code>staticmethod</code>","text":"<p>get the volume url of the given volume number Args:     number: volume number</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>@staticmethod\ndef getVolumeUrlOf(\n    number: str | int,\n) -&gt; str | None:\n    \"\"\"\n    get the volume url of the given volume number\n    Args:\n        number: volume number\n    \"\"\"\n    url = None\n    if number is not None:\n        url = f\"http://ceur-ws.org/Vol-{number}/\"\n    return url\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.get_loctime","title":"<code>get_loctime()</code>","text":"<p>get the loctime</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def get_loctime(self) -&gt; str | None:\n    \"\"\"\n    get the loctime\n    \"\"\"\n    loctime = getattr(self, \"loctime\", None)\n    if loctime is None:\n        td_title = getattr(self, \"tdtitle\", None)\n        if td_title:\n            title_parts = td_title.split(\",\")\n            del title_parts[0]\n            loctime = \",\".join(title_parts)\n            loctime = loctime.strip(\".\")\n            self.loctime = loctime\n        else:\n            pass\n    elif not isinstance(loctime, str):\n        loctime = None\n    return loctime\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.isVirtualEvent","title":"<code>isVirtualEvent()</code>","text":"<p>Returns True if the event is a virtual event</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def isVirtualEvent(self) -&gt; bool:\n    \"\"\"\n    Returns True if the event is a virtual event\n    \"\"\"\n    return getattr(self, \"virtualEvent\", False)\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.normalize","title":"<code>normalize()</code>","text":"<p>Tries to normalize the properties e.g. breaking loctime into designated location and time properties Example: 'Vienna, Austria, July 25th, 2022'</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def normalize(self):\n    \"\"\"\n    Tries to normalize the properties e.g. breaking loctime into designated location and time properties\n    Example: 'Vienna, Austria, July 25th, 2022'\n    \"\"\"\n    pass\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.rankLocations","title":"<code>rankLocations(locationStr, locations)</code>  <code>staticmethod</code>","text":"<p>rank the given locations to find the best match to the given location string Args:     locationStr: location string     locations: list of locations objects</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>@staticmethod\ndef rankLocations(locationStr: str, locations: list[Location]):\n    \"\"\"\n    rank the given locations to find the best match to the given location string\n    Args:\n        locationStr: location string\n        locations: list of locations objects\n    \"\"\"\n    rankedLocations = []\n    for location in locations:\n        locationsToCheck = []\n        if isinstance(location, City):\n            locationsToCheck = [\n                location,\n                location.region,\n                location.country,\n            ]\n        elif isinstance(location, Region):\n            locationsToCheck = [location, location.country]\n        elif isinstance(location, Country):\n            locationsToCheck = [location]\n        score = 0\n        for ltc in locationsToCheck:\n            if ltc.name in locationStr:\n                score += 1\n        rankedLocations.append((score, location))\n    rankedLocations.sort(key=lambda scoreTuple: scoreTuple[0], reverse=True)\n    return [location for score, location in rankedLocations]\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.removePartsMatching","title":"<code>removePartsMatching(value, pattern, separator=',')</code>  <code>staticmethod</code>","text":"<p>Removes parts from the given value matching the pattern</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>@staticmethod\ndef removePartsMatching(value: str, pattern: str, separator=\",\"):\n    \"\"\"\n    Removes parts from the given value matching the pattern\n    \"\"\"\n    parts = value.split(separator)\n    resParts = []\n    for part in parts:\n        if re.search(pattern, part) is None:\n            resParts.append(part)\n    resValue = separator.join(resParts)\n    return resValue\n</code></pre>"},{"location":"#ceurws.ceur_ws.Volume.resolveLoctime","title":"<code>resolveLoctime()</code>","text":"<p>Resolve the loctime property by breaking it down to city, region, country, dateFrom, and dateTo</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def resolveLoctime(self):\n    \"\"\"\n    Resolve the loctime property by breaking it down to city, region, country, dateFrom, and dateTo\n    \"\"\"\n    loctime = self.get_loctime()\n    if loctime is None:\n        return None\n    dateFrom, dateTo = self.extractDates(loctime)\n    if dateFrom is not None:\n        self.dateFrom = dateFrom\n    if dateTo is not None:\n        self.dateTo = dateTo\n    self.extractAndSetLocation(locationStr=loctime)\n</code></pre>"},{"location":"#ceurws.ceur_ws.VolumeManager","title":"<code>VolumeManager</code>","text":"<p>               Bases: <code>EntityManager</code></p> <p>Contains multiple ceurws volumes</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>class VolumeManager(EntityManager):\n    \"\"\"\n    Contains multiple ceurws volumes\n    \"\"\"\n\n    def __init__(self, tableName: str = \"volumes\"):\n        super().__init__(\n            listName=\"volumes\",\n            clazz=Volume,\n            tableName=tableName,\n            entityName=Volume.__class__.__name__,\n            primaryKey=\"number\",\n            entityPluralName=\"volumes\",\n            config=CEURWS.CONFIG,\n            handleInvalidListTypes=True,\n            name=self.__class__.__name__,\n        )\n        self.volumes: list[Volume] = []\n\n    def load(self):\n        \"\"\"\n        load the volumeManager\n        \"\"\"\n        if Download.needsDownload(CEURWS.CACHE_FILE):\n            self.loadFromIndexHtml()\n            self.store()\n        else:\n            self.loadFromBackup()\n\n    def loadFromBackup(self):\n        \"\"\"\n        load from the SQLITE Cache file\n        \"\"\"\n        self.fromStore(cacheFile=CEURWS.CACHE_FILE)\n\n    def update(self, parser_config: ParserConfig):\n        \"\"\"\n        update me by a checking for recently added volumes\n        \"\"\"\n        self.set_down_to_volume(parser_config)\n        self.update_or_recreate(parser_config)\n\n    def set_down_to_volume(self, parser_config):\n        volumeCount = len(self.volumes)\n        if volumeCount &gt; 0:\n            max_vol = self.volumes[-1]\n            parser_config.down_to_volume = max_vol.number + 1\n        else:\n            pass\n\n    def recreate(self, parser_config: ParserConfig):\n        \"\"\"\n        recreate me by a full parse of all volume files\n\n        Args:\n            parser_config: parser configuration\n        \"\"\"\n\n        self.update_or_recreate(parser_config)\n\n    def update_or_recreate(self, parser_config: ParserConfig):\n        \"\"\"\n        recreate or update me by parsing the index.html file\n\n        Args:\n            parser_config: parser configuration\n        \"\"\"\n        progress_bar = parser_config.progress_bar\n        loctime_parser = LoctimeParser()\n        pm = PaperManager()\n        if parser_config.down_to_volume != 1:\n            pm.fromStore(cacheFile=CEURWS.CACHE_FILE)\n        paper_list = pm.getList()\n\n        # first reload me from the main index\n        self.loadFromIndexHtml(parser_config)\n        invalid = 0\n        for volume in self.volumes:\n            if volume.number and volume.number &lt; parser_config.down_to_volume:\n                break\n            _volume_record, soup = volume.extractValuesFromVolumePage()\n            if soup:\n                ptp = PaperTocParser(number=str(volume.number), soup=soup, debug=self.debug)\n                paper_records = ptp.parsePapers()\n                for paper_record in paper_records:\n                    paper = Paper()\n                    paper.fromDict(paper_record)\n                    paper_list.append(paper)\n            if not volume.valid:\n                invalid += 1\n            else:\n                loctime = volume.get_loctime()\n                if loctime:\n                    loc_time_dict = loctime_parser.parse(loctime)\n                    for key, value in loc_time_dict.items():\n                        attr = f\"loc_{key}\"\n                        setattr(volume, attr, value)\n                    volume.resolveLoctime()\n            # update progress bar\n            if progress_bar:\n                if volume.valid:\n                    # print(f\"{volume.url}:{volume.acronym}:{volume.desc}:{volume.h1}:{volume.title}\")\n                    description = volume.acronym[:20] if volume.acronym else \"?\"\n                    progress_bar.set_description(f\"{description}\")\n                progress_bar.update()\n        print(f\"storing recreated volume table for {len(self.volumes)} volumes ({invalid} invalid)\")\n        self.store(replace=True)\n        print(f\"storing {len(paper_list)} papers\")\n        pm.store(replace=True)\n\n    def loadFromIndexHtml(self, parser_config: ParserConfig | None = None, vol_limit: int | None = None):\n        \"\"\"\n        load my content from the index.html file\n\n        Args:\n            parser_config(ParserConfig): the parser Configuration to use\n        \"\"\"\n        force = parser_config.force_download if parser_config else True\n        htmlText = self.getIndexHtml(force)\n        indexParser = IndexHtmlParser(htmlText, parser_config)\n        volumeRecords = indexParser.parse(vol_limit)\n        for volumeRecord in volumeRecords.values():\n            volume = Volume()\n            volume.fromDict(volumeRecord)\n            for attr in [\"desc\", \"h1\"]:\n                if not hasattr(volume, attr):\n                    setattr(volume, attr, \"?\")\n            self.volumes.append(volume)\n\n    def getIndexHtml(self, force: bool = False):\n        \"\"\"\n        get the index html\n        \"\"\"\n        cacheHtml = CEURWS.CACHE_HTML\n        if cacheHtml.is_file() and not force:\n            with open(cacheHtml, encoding=\"utf-8\") as file:\n                html_page = file.read()\n        else:\n            req = Request(CEURWS.URL, headers={\"User-Agent\": \"pyCEURMake\"})\n            html_page = urlopen(req).read().decode()\n            CEURWS.CACHE_DIR.mkdir(parents=True, exist_ok=True)\n            with open(cacheHtml, mode=\"w\", encoding=\"utf-8\") as htmlFile:\n                print(html_page, file=htmlFile)\n        return html_page\n</code></pre>"},{"location":"#ceurws.ceur_ws.VolumeManager.getIndexHtml","title":"<code>getIndexHtml(force=False)</code>","text":"<p>get the index html</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def getIndexHtml(self, force: bool = False):\n    \"\"\"\n    get the index html\n    \"\"\"\n    cacheHtml = CEURWS.CACHE_HTML\n    if cacheHtml.is_file() and not force:\n        with open(cacheHtml, encoding=\"utf-8\") as file:\n            html_page = file.read()\n    else:\n        req = Request(CEURWS.URL, headers={\"User-Agent\": \"pyCEURMake\"})\n        html_page = urlopen(req).read().decode()\n        CEURWS.CACHE_DIR.mkdir(parents=True, exist_ok=True)\n        with open(cacheHtml, mode=\"w\", encoding=\"utf-8\") as htmlFile:\n            print(html_page, file=htmlFile)\n    return html_page\n</code></pre>"},{"location":"#ceurws.ceur_ws.VolumeManager.load","title":"<code>load()</code>","text":"<p>load the volumeManager</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def load(self):\n    \"\"\"\n    load the volumeManager\n    \"\"\"\n    if Download.needsDownload(CEURWS.CACHE_FILE):\n        self.loadFromIndexHtml()\n        self.store()\n    else:\n        self.loadFromBackup()\n</code></pre>"},{"location":"#ceurws.ceur_ws.VolumeManager.loadFromBackup","title":"<code>loadFromBackup()</code>","text":"<p>load from the SQLITE Cache file</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def loadFromBackup(self):\n    \"\"\"\n    load from the SQLITE Cache file\n    \"\"\"\n    self.fromStore(cacheFile=CEURWS.CACHE_FILE)\n</code></pre>"},{"location":"#ceurws.ceur_ws.VolumeManager.loadFromIndexHtml","title":"<code>loadFromIndexHtml(parser_config=None, vol_limit=None)</code>","text":"<p>load my content from the index.html file</p> <p>Parameters:</p> Name Type Description Default <code>parser_config(ParserConfig)</code> <p>the parser Configuration to use</p> required Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def loadFromIndexHtml(self, parser_config: ParserConfig | None = None, vol_limit: int | None = None):\n    \"\"\"\n    load my content from the index.html file\n\n    Args:\n        parser_config(ParserConfig): the parser Configuration to use\n    \"\"\"\n    force = parser_config.force_download if parser_config else True\n    htmlText = self.getIndexHtml(force)\n    indexParser = IndexHtmlParser(htmlText, parser_config)\n    volumeRecords = indexParser.parse(vol_limit)\n    for volumeRecord in volumeRecords.values():\n        volume = Volume()\n        volume.fromDict(volumeRecord)\n        for attr in [\"desc\", \"h1\"]:\n            if not hasattr(volume, attr):\n                setattr(volume, attr, \"?\")\n        self.volumes.append(volume)\n</code></pre>"},{"location":"#ceurws.ceur_ws.VolumeManager.recreate","title":"<code>recreate(parser_config)</code>","text":"<p>recreate me by a full parse of all volume files</p> <p>Parameters:</p> Name Type Description Default <code>parser_config</code> <code>ParserConfig</code> <p>parser configuration</p> required Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def recreate(self, parser_config: ParserConfig):\n    \"\"\"\n    recreate me by a full parse of all volume files\n\n    Args:\n        parser_config: parser configuration\n    \"\"\"\n\n    self.update_or_recreate(parser_config)\n</code></pre>"},{"location":"#ceurws.ceur_ws.VolumeManager.update","title":"<code>update(parser_config)</code>","text":"<p>update me by a checking for recently added volumes</p> Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def update(self, parser_config: ParserConfig):\n    \"\"\"\n    update me by a checking for recently added volumes\n    \"\"\"\n    self.set_down_to_volume(parser_config)\n    self.update_or_recreate(parser_config)\n</code></pre>"},{"location":"#ceurws.ceur_ws.VolumeManager.update_or_recreate","title":"<code>update_or_recreate(parser_config)</code>","text":"<p>recreate or update me by parsing the index.html file</p> <p>Parameters:</p> Name Type Description Default <code>parser_config</code> <code>ParserConfig</code> <p>parser configuration</p> required Source code in <code>ceurws/ceur_ws.py</code> <pre><code>def update_or_recreate(self, parser_config: ParserConfig):\n    \"\"\"\n    recreate or update me by parsing the index.html file\n\n    Args:\n        parser_config: parser configuration\n    \"\"\"\n    progress_bar = parser_config.progress_bar\n    loctime_parser = LoctimeParser()\n    pm = PaperManager()\n    if parser_config.down_to_volume != 1:\n        pm.fromStore(cacheFile=CEURWS.CACHE_FILE)\n    paper_list = pm.getList()\n\n    # first reload me from the main index\n    self.loadFromIndexHtml(parser_config)\n    invalid = 0\n    for volume in self.volumes:\n        if volume.number and volume.number &lt; parser_config.down_to_volume:\n            break\n        _volume_record, soup = volume.extractValuesFromVolumePage()\n        if soup:\n            ptp = PaperTocParser(number=str(volume.number), soup=soup, debug=self.debug)\n            paper_records = ptp.parsePapers()\n            for paper_record in paper_records:\n                paper = Paper()\n                paper.fromDict(paper_record)\n                paper_list.append(paper)\n        if not volume.valid:\n            invalid += 1\n        else:\n            loctime = volume.get_loctime()\n            if loctime:\n                loc_time_dict = loctime_parser.parse(loctime)\n                for key, value in loc_time_dict.items():\n                    attr = f\"loc_{key}\"\n                    setattr(volume, attr, value)\n                volume.resolveLoctime()\n        # update progress bar\n        if progress_bar:\n            if volume.valid:\n                # print(f\"{volume.url}:{volume.acronym}:{volume.desc}:{volume.h1}:{volume.title}\")\n                description = volume.acronym[:20] if volume.acronym else \"?\"\n                progress_bar.set_description(f\"{description}\")\n            progress_bar.update()\n    print(f\"storing recreated volume table for {len(self.volumes)} volumes ({invalid} invalid)\")\n    self.store(replace=True)\n    print(f\"storing {len(paper_list)} papers\")\n    pm.store(replace=True)\n</code></pre>"},{"location":"#ceurws.ceur_ws_web_cmd","title":"<code>ceur_ws_web_cmd</code>","text":"<p>Created on 2024-02-22</p> <p>@author: wf</p>"},{"location":"#ceurws.ceur_ws_web_cmd.CeurWsCmd","title":"<code>CeurWsCmd</code>","text":"<p>               Bases: <code>WebserverCmd</code></p> <p>command line handling for CEUR-WS Volume browser</p> Source code in <code>ceurws/ceur_ws_web_cmd.py</code> <pre><code>class CeurWsCmd(WebserverCmd):\n    \"\"\"\n    command line handling for CEUR-WS Volume browser\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        constructor\n        \"\"\"\n        config = CeurWsWebServer.get_config()\n        WebserverCmd.__init__(self, config, CeurWsWebServer, DEBUG)\n        pass\n\n    def getArgParser(self, description: str, version_msg) -&gt; ArgumentParser:\n        \"\"\"\n        override the default argparser call\n        \"\"\"\n        parser = super().getArgParser(description, version_msg)\n        parser.add_argument(\n            \"-dbu\",\n            \"--dblp_update\",\n            action=\"store_true\",\n            help=\"update dblp cache\",\n        )\n        parser.add_argument(\n            \"-nq\",\n            \"--namedqueries\",\n            action=\"store_true\",\n            help=\"generate named queries [default: %(default)s]\",\n        )\n        parser.add_argument(\n            \"-den\",\n            \"--dblp_endpoint_name\",\n            help=\"name of dblp endpoint to use %(default)s\",\n            default=\"qlever-dblp\",\n        )\n        parser.add_argument(\n            \"-f\",\n            \"--force\",\n            action=\"store_true\",\n            help=\"force update [default: %(default)s]\",\n        )\n        parser.add_argument(\n            \"--list\",\n            action=\"store_true\",\n            help=\"list all volumes [default: %(default)s]\",\n        )\n        parser.add_argument(\n            \"-rc\",\n            \"--recreate\",\n            action=\"store_true\",\n            help=\"recreate caches e.g. volume table\",\n        )\n        parser.add_argument(\n            \"-uv\",\n            \"--update\",\n            action=\"store_true\",\n            help=\"update volumes by parsing index.html adding recently published volumes\",\n        )\n        parser.add_argument(\n            \"-wen\",\n            \"--wikidata_endpoint_name\",\n            help=\"name of wikidata endpoint to use %(default)s\",\n            default=\"wikidata\",\n        )\n        parser.add_argument(\n            \"-wdu\",\n            \"--wikidata_update\",\n            action=\"store_true\",\n            help=\"update tables from wikidata\",\n        )\n        return parser\n\n    def handle_args(self) -&gt; bool:\n        \"\"\"\n        handle the command line arguments\n        \"\"\"\n        args = self.args\n        if args.namedqueries:\n            nq = NamedQueries()\n            yaml = nq.toYaml()\n            print(yaml)\n        if args.list:\n            manager = VolumeManager()\n            manager.loadFromBackup()\n            for volume in manager.getList():\n                print(volume)\n        if args.recreate or args.update:\n            manager = VolumeManager()\n            manager.load()\n            progress_bar = tqdm(total=len(manager.volumes))\n            parser_config = ParserConfig(progress_bar, debug=args.debug)\n\n            if args.recreate:\n                manager.recreate(parser_config)\n            else:\n                manager.update(parser_config)\n        if args.wikidata_update:\n            wdsync = WikidataSync.from_args(args)\n            wdsync.update(withStore=True)\n        if args.dblp_update:\n            wdsync = WikidataSync.from_args(args)\n            endpoint = wdsync.dblpEndpoint\n            print(f\"updating dblp cache from SPARQL endpoint {endpoint.sparql.url}\")\n            # Instantiate the progress bar\n            pbar = tqdm(total=len(wdsync.dblpEndpoint.dblp_managers))\n            for _step, (cache_name, dblp_manager) in enumerate(endpoint.dblp_managers.items(), start=1):\n                # Call the corresponding function to refresh cache data\n                dblp_manager.load(force_query=args.force)\n                # Update the progress bar description with the cache name and increment\n                pbar.set_description(f\"{cache_name} updated ...\")\n\n                # Update the progress bar manually\n                pbar.update(1)  # Increment the progress bar by 1 for each iteration\n\n            # Close the progress bar after the loop\n            pbar.close()\n            table_data = []\n            for _step, cache_name in enumerate(endpoint.dblp_managers.keys(), start=1):\n                cache = endpoint.cache_manager.get_cache_by_name(cache_name)\n                table_data.append(asdict(cache))\n            table = tabulate(table_data, headers=\"keys\", tablefmt=\"grid\")\n            print(table)\n            pass\n        handled = super().handle_args()\n        return handled\n</code></pre>"},{"location":"#ceurws.ceur_ws_web_cmd.CeurWsCmd.__init__","title":"<code>__init__()</code>","text":"<p>constructor</p> Source code in <code>ceurws/ceur_ws_web_cmd.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    constructor\n    \"\"\"\n    config = CeurWsWebServer.get_config()\n    WebserverCmd.__init__(self, config, CeurWsWebServer, DEBUG)\n    pass\n</code></pre>"},{"location":"#ceurws.ceur_ws_web_cmd.CeurWsCmd.getArgParser","title":"<code>getArgParser(description, version_msg)</code>","text":"<p>override the default argparser call</p> Source code in <code>ceurws/ceur_ws_web_cmd.py</code> <pre><code>def getArgParser(self, description: str, version_msg) -&gt; ArgumentParser:\n    \"\"\"\n    override the default argparser call\n    \"\"\"\n    parser = super().getArgParser(description, version_msg)\n    parser.add_argument(\n        \"-dbu\",\n        \"--dblp_update\",\n        action=\"store_true\",\n        help=\"update dblp cache\",\n    )\n    parser.add_argument(\n        \"-nq\",\n        \"--namedqueries\",\n        action=\"store_true\",\n        help=\"generate named queries [default: %(default)s]\",\n    )\n    parser.add_argument(\n        \"-den\",\n        \"--dblp_endpoint_name\",\n        help=\"name of dblp endpoint to use %(default)s\",\n        default=\"qlever-dblp\",\n    )\n    parser.add_argument(\n        \"-f\",\n        \"--force\",\n        action=\"store_true\",\n        help=\"force update [default: %(default)s]\",\n    )\n    parser.add_argument(\n        \"--list\",\n        action=\"store_true\",\n        help=\"list all volumes [default: %(default)s]\",\n    )\n    parser.add_argument(\n        \"-rc\",\n        \"--recreate\",\n        action=\"store_true\",\n        help=\"recreate caches e.g. volume table\",\n    )\n    parser.add_argument(\n        \"-uv\",\n        \"--update\",\n        action=\"store_true\",\n        help=\"update volumes by parsing index.html adding recently published volumes\",\n    )\n    parser.add_argument(\n        \"-wen\",\n        \"--wikidata_endpoint_name\",\n        help=\"name of wikidata endpoint to use %(default)s\",\n        default=\"wikidata\",\n    )\n    parser.add_argument(\n        \"-wdu\",\n        \"--wikidata_update\",\n        action=\"store_true\",\n        help=\"update tables from wikidata\",\n    )\n    return parser\n</code></pre>"},{"location":"#ceurws.ceur_ws_web_cmd.CeurWsCmd.handle_args","title":"<code>handle_args()</code>","text":"<p>handle the command line arguments</p> Source code in <code>ceurws/ceur_ws_web_cmd.py</code> <pre><code>def handle_args(self) -&gt; bool:\n    \"\"\"\n    handle the command line arguments\n    \"\"\"\n    args = self.args\n    if args.namedqueries:\n        nq = NamedQueries()\n        yaml = nq.toYaml()\n        print(yaml)\n    if args.list:\n        manager = VolumeManager()\n        manager.loadFromBackup()\n        for volume in manager.getList():\n            print(volume)\n    if args.recreate or args.update:\n        manager = VolumeManager()\n        manager.load()\n        progress_bar = tqdm(total=len(manager.volumes))\n        parser_config = ParserConfig(progress_bar, debug=args.debug)\n\n        if args.recreate:\n            manager.recreate(parser_config)\n        else:\n            manager.update(parser_config)\n    if args.wikidata_update:\n        wdsync = WikidataSync.from_args(args)\n        wdsync.update(withStore=True)\n    if args.dblp_update:\n        wdsync = WikidataSync.from_args(args)\n        endpoint = wdsync.dblpEndpoint\n        print(f\"updating dblp cache from SPARQL endpoint {endpoint.sparql.url}\")\n        # Instantiate the progress bar\n        pbar = tqdm(total=len(wdsync.dblpEndpoint.dblp_managers))\n        for _step, (cache_name, dblp_manager) in enumerate(endpoint.dblp_managers.items(), start=1):\n            # Call the corresponding function to refresh cache data\n            dblp_manager.load(force_query=args.force)\n            # Update the progress bar description with the cache name and increment\n            pbar.set_description(f\"{cache_name} updated ...\")\n\n            # Update the progress bar manually\n            pbar.update(1)  # Increment the progress bar by 1 for each iteration\n\n        # Close the progress bar after the loop\n        pbar.close()\n        table_data = []\n        for _step, cache_name in enumerate(endpoint.dblp_managers.keys(), start=1):\n            cache = endpoint.cache_manager.get_cache_by_name(cache_name)\n            table_data.append(asdict(cache))\n        table = tabulate(table_data, headers=\"keys\", tablefmt=\"grid\")\n        print(table)\n        pass\n    handled = super().handle_args()\n    return handled\n</code></pre>"},{"location":"#ceurws.ceur_ws_web_cmd.main","title":"<code>main(argv=None)</code>","text":"<p>main call</p> Source code in <code>ceurws/ceur_ws_web_cmd.py</code> <pre><code>def main(argv: list | None = None):\n    \"\"\"\n    main call\n    \"\"\"\n    cmd = CeurWsCmd()\n    exit_code = cmd.cmd_main(argv)\n    return exit_code\n</code></pre>"},{"location":"#ceurws.config","title":"<code>config</code>","text":""},{"location":"#ceurws.config.CEURWS","title":"<code>CEURWS</code>","text":"<p>CEUR-WS</p> Source code in <code>ceurws/config.py</code> <pre><code>class CEURWS:\n    \"\"\"\n    CEUR-WS\n    \"\"\"\n\n    @staticmethod\n    def get_home_path() -&gt; Path:\n        \"\"\"\n        Get home path\n        \"\"\"\n        home = Path.home()\n        if \"GITHUB_WORKSPACE\" in os.environ:\n            home = Path(os.environ[\"GITHUB_WORKSPACE\"])\n        return home\n\n    URL = \"http://ceur-ws.org\"\n    home = get_home_path()\n    CACHE_DIR = home.joinpath(\".ceurws\")\n    CACHE_FILE = CACHE_DIR.joinpath(\"ceurws.db\")\n    CACHE_HTML = CACHE_DIR.joinpath(\"index.html\")\n    CONFIG = StorageConfig(cacheFile=str(CACHE_FILE))\n</code></pre>"},{"location":"#ceurws.config.CEURWS.get_home_path","title":"<code>get_home_path()</code>  <code>staticmethod</code>","text":"<p>Get home path</p> Source code in <code>ceurws/config.py</code> <pre><code>@staticmethod\ndef get_home_path() -&gt; Path:\n    \"\"\"\n    Get home path\n    \"\"\"\n    home = Path.home()\n    if \"GITHUB_WORKSPACE\" in os.environ:\n        home = Path(os.environ[\"GITHUB_WORKSPACE\"])\n    return home\n</code></pre>"},{"location":"#ceurws.dblp","title":"<code>dblp</code>","text":"<p>Created on 2024-03-09</p> <p>@author: wf</p>"},{"location":"#ceurws.dblp.DblpAuthorIdentifier","title":"<code>DblpAuthorIdentifier</code>  <code>dataclass</code>","text":"<p>represents an author id available in dblp and the corresponding property in wikidata</p> Source code in <code>ceurws/dblp.py</code> <pre><code>@dataclass\nclass DblpAuthorIdentifier:\n    \"\"\"\n    represents an author id available in dblp\n    and the corresponding property in wikidata\n    \"\"\"\n\n    name: str  # the name should be usable as SPARQL variable\n    dblp_property: str\n    wikidata_property: str | None\n\n    @classmethod\n    def all(cls) -&gt; list[\"DblpAuthorIdentifier\"]:\n        \"\"\"\n        returns all available identifiers\n        \"\"\"\n        res = [\n            DblpAuthorIdentifier(\"dblp\", \"datacite:dblp\", \"P2456\"),\n            DblpAuthorIdentifier(\"wikidata\", \"datacite:wikidata\", None),\n            DblpAuthorIdentifier(\"orcid\", \"datacite:orcid\", \"P496\"),\n            DblpAuthorIdentifier(\"googleScholar\", \"datacite:google-scholar\", \"P1960\"),\n            DblpAuthorIdentifier(\"acm\", \"datacite:acm\", \"P864\"),\n            DblpAuthorIdentifier(\"twitter\", \"datacite:twitter\", \"P2002\"),\n            DblpAuthorIdentifier(\"github\", \"datacite:github\", \"P2037\"),\n            DblpAuthorIdentifier(\"viaf\", \"datacite:viaf\", \"P214\"),\n            DblpAuthorIdentifier(\"scigraph\", \"datacite:scigraph\", \"P10861\"),\n            DblpAuthorIdentifier(\"zbmath\", \"datacite:zbmath\", \"P1556\"),\n            DblpAuthorIdentifier(\"researchGate\", \"datacite:research-gate\", \"P6023\"),\n            DblpAuthorIdentifier(\"mathGenealogy\", \"datacite:math-genealogy\", \"P549\"),\n            DblpAuthorIdentifier(\"loc\", \"datacite:loc\", \"P244\"),\n            DblpAuthorIdentifier(\"linkedin\", \"datacite:linkedin\", \"P6634\"),\n            DblpAuthorIdentifier(\"lattes\", \"datacite:lattes\", \"P1007\"),\n            DblpAuthorIdentifier(\"isni\", \"datacite:isni\", \"P213\"),\n            DblpAuthorIdentifier(\"ieee\", \"datacite:ieee\", \"P6479\"),\n            DblpAuthorIdentifier(\"gepris\", \"datacite:gepris\", \"P4872\"),\n            DblpAuthorIdentifier(\"gnd\", \"datacite:gnd\", \"P227\"),\n        ]\n        return res\n\n    @classmethod\n    def getAllAsMap(cls) -&gt; dict[str, \"DblpAuthorIdentifier\"]:\n        \"\"\"\n        return all all available identifiers as map\n        \"\"\"\n        res = dict()\n        for identifier in cls.all():\n            res[identifier.name] = identifier\n        return res\n\n    @classmethod\n    def getWikidataIdQueryPart(cls, id_name: str, value: str, var: str):\n        \"\"\"\n        Generates for the given identifier the wikidata query\n        Args:\n            id_name: name of the identifier\n            value: the identifier value\n            var: name of the variable which should have the id\n        \"\"\"\n        if not var.startswith(\"?\"):\n            var = \"?\" + var\n        query = None\n        dblp_author_ids = cls.getAllAsMap().get(id_name)\n        if dblp_author_ids is None:\n            # unknown identifier\n            return \"\"\n        wd_prop = dblp_author_ids.wikidata_property\n        values: str | list[str]\n        if id_name == \"wikidata\":\n            values = value\n            if isinstance(value, str):\n                values = [value]\n            value_urls = \" \".join([f\"wd:{value}\" for value in values])\n            query = f\"\"\"{{ SELECT * WHERE {{ VALUES ?person {{ {value_urls} }} }} }}# {id_name}\"\"\"\n        elif id_name in cls.getAllAsMap():\n            if isinstance(value, list):\n                values = \" \".join([f'\"{value}\"' for value in value])\n                query = f\"\"\"{{OPTIONAL{{\n                            VALUES ?{id_name} {{ {values} }}\n                            {var} wdt:{wd_prop} ?{id_name}.}} \n                            }}  # {id_name}\"\"\"\n            else:\n                query = f\"\"\"{{ {var} wdt:{wd_prop} \"{value}\". }}  # {id_name}\"\"\"\n        else:\n            pass\n        return query\n</code></pre>"},{"location":"#ceurws.dblp.DblpAuthorIdentifier.all","title":"<code>all()</code>  <code>classmethod</code>","text":"<p>returns all available identifiers</p> Source code in <code>ceurws/dblp.py</code> <pre><code>@classmethod\ndef all(cls) -&gt; list[\"DblpAuthorIdentifier\"]:\n    \"\"\"\n    returns all available identifiers\n    \"\"\"\n    res = [\n        DblpAuthorIdentifier(\"dblp\", \"datacite:dblp\", \"P2456\"),\n        DblpAuthorIdentifier(\"wikidata\", \"datacite:wikidata\", None),\n        DblpAuthorIdentifier(\"orcid\", \"datacite:orcid\", \"P496\"),\n        DblpAuthorIdentifier(\"googleScholar\", \"datacite:google-scholar\", \"P1960\"),\n        DblpAuthorIdentifier(\"acm\", \"datacite:acm\", \"P864\"),\n        DblpAuthorIdentifier(\"twitter\", \"datacite:twitter\", \"P2002\"),\n        DblpAuthorIdentifier(\"github\", \"datacite:github\", \"P2037\"),\n        DblpAuthorIdentifier(\"viaf\", \"datacite:viaf\", \"P214\"),\n        DblpAuthorIdentifier(\"scigraph\", \"datacite:scigraph\", \"P10861\"),\n        DblpAuthorIdentifier(\"zbmath\", \"datacite:zbmath\", \"P1556\"),\n        DblpAuthorIdentifier(\"researchGate\", \"datacite:research-gate\", \"P6023\"),\n        DblpAuthorIdentifier(\"mathGenealogy\", \"datacite:math-genealogy\", \"P549\"),\n        DblpAuthorIdentifier(\"loc\", \"datacite:loc\", \"P244\"),\n        DblpAuthorIdentifier(\"linkedin\", \"datacite:linkedin\", \"P6634\"),\n        DblpAuthorIdentifier(\"lattes\", \"datacite:lattes\", \"P1007\"),\n        DblpAuthorIdentifier(\"isni\", \"datacite:isni\", \"P213\"),\n        DblpAuthorIdentifier(\"ieee\", \"datacite:ieee\", \"P6479\"),\n        DblpAuthorIdentifier(\"gepris\", \"datacite:gepris\", \"P4872\"),\n        DblpAuthorIdentifier(\"gnd\", \"datacite:gnd\", \"P227\"),\n    ]\n    return res\n</code></pre>"},{"location":"#ceurws.dblp.DblpAuthorIdentifier.getAllAsMap","title":"<code>getAllAsMap()</code>  <code>classmethod</code>","text":"<p>return all all available identifiers as map</p> Source code in <code>ceurws/dblp.py</code> <pre><code>@classmethod\ndef getAllAsMap(cls) -&gt; dict[str, \"DblpAuthorIdentifier\"]:\n    \"\"\"\n    return all all available identifiers as map\n    \"\"\"\n    res = dict()\n    for identifier in cls.all():\n        res[identifier.name] = identifier\n    return res\n</code></pre>"},{"location":"#ceurws.dblp.DblpAuthorIdentifier.getWikidataIdQueryPart","title":"<code>getWikidataIdQueryPart(id_name, value, var)</code>  <code>classmethod</code>","text":"<p>Generates for the given identifier the wikidata query Args:     id_name: name of the identifier     value: the identifier value     var: name of the variable which should have the id</p> Source code in <code>ceurws/dblp.py</code> <pre><code>@classmethod\ndef getWikidataIdQueryPart(cls, id_name: str, value: str, var: str):\n    \"\"\"\n    Generates for the given identifier the wikidata query\n    Args:\n        id_name: name of the identifier\n        value: the identifier value\n        var: name of the variable which should have the id\n    \"\"\"\n    if not var.startswith(\"?\"):\n        var = \"?\" + var\n    query = None\n    dblp_author_ids = cls.getAllAsMap().get(id_name)\n    if dblp_author_ids is None:\n        # unknown identifier\n        return \"\"\n    wd_prop = dblp_author_ids.wikidata_property\n    values: str | list[str]\n    if id_name == \"wikidata\":\n        values = value\n        if isinstance(value, str):\n            values = [value]\n        value_urls = \" \".join([f\"wd:{value}\" for value in values])\n        query = f\"\"\"{{ SELECT * WHERE {{ VALUES ?person {{ {value_urls} }} }} }}# {id_name}\"\"\"\n    elif id_name in cls.getAllAsMap():\n        if isinstance(value, list):\n            values = \" \".join([f'\"{value}\"' for value in value])\n            query = f\"\"\"{{OPTIONAL{{\n                        VALUES ?{id_name} {{ {values} }}\n                        {var} wdt:{wd_prop} ?{id_name}.}} \n                        }}  # {id_name}\"\"\"\n        else:\n            query = f\"\"\"{{ {var} wdt:{wd_prop} \"{value}\". }}  # {id_name}\"\"\"\n    else:\n        pass\n    return query\n</code></pre>"},{"location":"#ceurws.dblp.DblpAuthors","title":"<code>DblpAuthors</code>","text":"<p>               Bases: <code>DblpManager</code></p> <p>Manage all authors of DBLP indexed volumes.</p> Source code in <code>ceurws/dblp.py</code> <pre><code>class DblpAuthors(DblpManager):\n    \"\"\"\n    Manage all authors of DBLP indexed volumes.\n    \"\"\"\n\n    def __init__(self, endpoint: \"DblpEndpoint\"):\n        super().__init__(endpoint, \"dblp/authors\", \"CEUR-WS Paper Authors\")\n        self.authors: list[DblpScholar] | None = None\n\n    def load(self, force_query: bool = False):\n        \"\"\"\n        load my authors\n        \"\"\"\n        if self.authors is None:\n            super().load(force_query=force_query)\n            self.authors = []\n            for d in self.lod:\n                author = DblpScholar(**d)\n                self.authors.append(author)\n            self.authorsById = {a.dblp_author_id: a for a in self.authors}\n</code></pre>"},{"location":"#ceurws.dblp.DblpAuthors.load","title":"<code>load(force_query=False)</code>","text":"<p>load my authors</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def load(self, force_query: bool = False):\n    \"\"\"\n    load my authors\n    \"\"\"\n    if self.authors is None:\n        super().load(force_query=force_query)\n        self.authors = []\n        for d in self.lod:\n            author = DblpScholar(**d)\n            self.authors.append(author)\n        self.authorsById = {a.dblp_author_id: a for a in self.authors}\n</code></pre>"},{"location":"#ceurws.dblp.DblpEditors","title":"<code>DblpEditors</code>","text":"<p>               Bases: <code>DblpManager</code></p> <p>Manage all editors of DBLP indexed volumes.</p> Source code in <code>ceurws/dblp.py</code> <pre><code>class DblpEditors(DblpManager):\n    \"\"\"\n    Manage all editors of DBLP indexed volumes.\n    \"\"\"\n\n    def __init__(self, endpoint: \"DblpEndpoint\"):\n        super().__init__(endpoint, \"dblp/editors\", \"CEUR-WS all Editors\")\n        self.editors: list[DblpScholar] | None = None\n\n    def load(self, force_query: bool = False):\n        \"\"\"\n        load my editors\n        \"\"\"\n        if self.editors is None:\n            super().load(force_query=force_query)\n            self.editors = []\n            for d in self.lod:\n                editor = DblpScholar(**d)\n                self.editors.append(editor)\n            self.editorsById = {e.dblp_author_id: e for e in self.editors}\n</code></pre>"},{"location":"#ceurws.dblp.DblpEditors.load","title":"<code>load(force_query=False)</code>","text":"<p>load my editors</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def load(self, force_query: bool = False):\n    \"\"\"\n    load my editors\n    \"\"\"\n    if self.editors is None:\n        super().load(force_query=force_query)\n        self.editors = []\n        for d in self.lod:\n            editor = DblpScholar(**d)\n            self.editors.append(editor)\n        self.editorsById = {e.dblp_author_id: e for e in self.editors}\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint","title":"<code>DblpEndpoint</code>","text":"<p>provides queries and a dblp endpoint to execute them</p> Source code in <code>ceurws/dblp.py</code> <pre><code>class DblpEndpoint:\n    \"\"\"\n    provides queries and a dblp endpoint to execute them\n    \"\"\"\n\n    DBLP_REC_PREFIX = \"https://dblp.org/rec/\"\n    DBLP_EVENT_PREFIX = \"https://dblp.org/db/\"\n\n    def __init__(self, endpoint, debug: bool = False):\n        \"\"\"\n        constructor\n        \"\"\"\n        self.debug = debug\n        self.sparql = SPARQL(endpoint)\n        path = os.path.dirname(__file__)\n        qYamlFile = f\"{path}/resources/queries/dblp.yaml\"\n        if os.path.isfile(qYamlFile):\n            self.qm = QueryManager(lang=\"sparql\", queriesPath=qYamlFile)\n        # there is one cache manager for all our json caches\n        self.cache_manager = CacheManager(\"ceurws\")\n        self.dblp_authors = DblpAuthors(endpoint=self)\n        self.dblp_editors = DblpEditors(endpoint=self)\n        self.dblp_papers = DblpPapers(endpoint=self)\n        self.dblp_volumes = DblpVolumes(endpoint=self)\n        self.dblp_managers = {\n            \"dblp/authors\": self.dblp_authors,\n            \"dblp/editors\": self.dblp_editors,\n            \"dblp/papers\": self.dblp_papers,\n            \"dblp/volumes\": self.dblp_volumes,\n        }\n        self.progress_bar = None\n\n    def load_all(self, force_query: bool = False):\n        \"\"\"\n        load all managers\n        \"\"\"\n        for _key, manager in self.dblp_managers.items():\n            manager.load(force_query=force_query)\n\n    def get_lod(self, cache_name: str, query_name: str, force_query: bool = False) -&gt; list:\n        \"\"\"\n        Get the list of dictionaries for the given cache and query names,\n        optionally forcing a query.\n\n        Args:\n            cache_name (str): The name of the cache to load or store the LOD.\n            query_name (str): The name of the query to execute if the data is not cached or forced to query.\n            force_query (bool): If True, forces the query execution even if the data is cached. Defaults to False.\n\n        Returns:\n            List[Dict]: The list of dictionaries loaded either from cache or by executing the SPARQL query.\n        \"\"\"\n        start_time = time.time()  # Record the start time of the operation\n        cache = self.cache_manager.get_cache_by_name(cache_name)\n        if cache.is_stored and not force_query:\n            if self.debug:\n                print(f\"loading {cache_name} from cache\")\n            lod = self.cache_manager.load(cache_name)\n        else:\n            query = self.qm.queriesByName[query_name]\n            if self.debug:\n                print(f\"loading {cache_name} from SPARQL query {query_name}\")\n            lod = self.sparql.queryAsListOfDicts(query.query)\n            self.cache_manager.store(cache_name, lod)\n        end_time = time.time()  # Record the end time of the operation\n        duration = end_time - start_time  # Calculate the duration of the loading process\n\n        if self.debug:\n            print(f\"loaded {len(lod)} records for {cache_name} in {duration:.2f} seconds\")\n        if self.progress_bar:\n            self.progress_bar.update(duration * 100 / 36)\n        return lod\n\n    def get_ceur_volume_papers(self, volume_number: int) -&gt; list[DblpPaper]:\n        \"\"\"\n        Get all papers published in CEUR-WS from dblp\n        \"\"\"\n        cache_name = f\"dblp/Vol-{volume_number}/papers\"\n        lod = self.cache_manager.load(cache_name)\n        papers = [DblpPaper(**d) for d in lod]\n        return papers\n\n    def get_ceur_proceeding(self, volume_number: int) -&gt; DblpProceeding:\n        \"\"\"\n        get ceur proceeding by volume number from dblp\n        Args:\n            volume_number: number of the volume\n        \"\"\"\n        cache_name = f\"dblp/Vol-{volume_number}/metadata\"\n        volume = self.cache_manager.load(cache_name, cls=DblpProceeding)\n        return volume\n\n    def getDblpIdByVolumeNumber(self, number) -&gt; list[str]:\n        \"\"\"\n        Get the dblp entity id by given volume number\n        Args:\n            number: volume number\n        \"\"\"\n        query = f\"\"\"PREFIX dblp: &lt;https://dblp.org/rdf/schema#&gt;\n            SELECT *\n            WHERE {{ \n                ?proceeding dblp:publishedIn \"CEUR Workshop Proceedings\";\n                            dblp:publishedInSeriesVolume \"{number}\".\n                }}\n        \"\"\"\n        try:\n            qres = self.sparql.queryAsListOfDicts(query)\n        except HTTPError:\n            print(\"dblp sparql endpoint unavailable\")\n            qres = None\n        qIds = []\n        if qres is not None and qres != []:\n            qIds = [record.get(\"proceeding\")[len(self.DBLP_REC_PREFIX) :] for record in qres]\n        return qIds\n\n    def getDblpUrlByDblpId(self, entityId: str | None = None) -&gt; str | None:\n        \"\"\"\n        Get the dblp url for given entity id\n        Args:\n            entityId: volume url\n        \"\"\"\n        if entityId is None or entityId == \"\":\n            return None\n        entityUrl = self.DBLP_REC_PREFIX + entityId\n        query = f\"\"\"PREFIX dblp: &lt;https://dblp.org/rdf/schema#&gt;\n                SELECT *\n                WHERE {{ \n                    &lt;{entityUrl}&gt; dblp:listedOnTocPage ?url .\n                    }}\n            \"\"\"\n        qres = self.sparql.queryAsListOfDicts(query)\n        qIds = []\n        if qres is not None and qres != []:\n            qIds = [record.get(\"url\")[len(self.DBLP_EVENT_PREFIX) :] for record in qres]\n        qId = qIds[0] if qIds is not None and len(qIds) &gt; 0 else None\n        return qId\n\n    def convertEntityIdToUrlId(self, entityId: str | None) -&gt; str | None:\n        \"\"\"\n        Convert the given entityId to the id used in the url\n        Note: use with care this conversion does not always work\n        Args:\n            entityId: id of the entity\n        Example:\n            conf/aaai/2022 \u2192 conf/aaai/aaai2022\n\n        Returns\n            str - id used in the url\n            None - if the given entityId can not be converted\n        \"\"\"\n        return self.getDblpUrlByDblpId(entityId)\n\n    def toDblpUrl(self, entityId: str, withPostfix: bool = False) -&gt; str | None:\n        \"\"\"\n        Convert the given id to the corresponding dblp url\n        Args:\n            entityId: dblp event id\n            withPostfix: If True add the postfix \".html\"\n\n        Returns:\n            dblp url of None if the url can not be generated for the given input\n        \"\"\"\n        urlId = self.convertEntityIdToUrlId(entityId)\n        if urlId is None:\n            return None\n        postfix = \".html\"\n        url = self.DBLP_EVENT_PREFIX + urlId\n        if withPostfix:\n            url += postfix\n        return url\n\n    def getEditorsOfVolume(self, number: int | str | None) -&gt; list[dict]:\n        \"\"\"\n        Get the editors for the given volume number\n        Args:\n            number: number of the volume if none query for all ceur-ws editors\n\n        Returns:\n            list of dictionaries where a dict represents one editor containing all identifiers of the editor\n        \"\"\"\n        number_var = \"?volumeNumber\" if number is None else f'\"{number}\"'\n        dblp_identifiers = DblpAuthorIdentifier.all()\n        optional_clauses: list[str] = []\n        id_vars: list[str] = []\n        for identifier in dblp_identifiers:\n            id_var = f\"?{identifier.name}\"\n            optional_clauses.append(\n                f\"\"\"OPTIONAL{{\n                ?editor datacite:hasIdentifier {id_var}_blank.\n                {id_var}_blank datacite:usesIdentifierScheme {identifier.dblp_property};\n                litre:hasLiteralValue {id_var}Var.}}\"\"\"\n            )\n            id_vars.append(id_var)\n        id_selects = \"\\n\".join(\n            [f\"(group_concat(DISTINCT {id_var}Var;separator='|') as {id_var})\" for id_var in id_vars]\n        )\n        id_queries = \"\\n\".join(optional_clauses)\n        query = f\"\"\"PREFIX datacite: &lt;http://purl.org/spar/datacite/&gt;\n                    PREFIX dblp: &lt;https://dblp.org/rdf/schema#&gt;\n                    PREFIX litre: &lt;http://purl.org/spar/literal/&gt;\n                    SELECT DISTINCT (group_concat(DISTINCT ?nameVar;separator='|') as ?name) \n                                    (group_concat(DISTINCT ?homepageVar;separator='|') as ?homepage)\n                                    (group_concat(DISTINCT ?affiliationVar;separator='|') as ?affiliation)\n                                    {id_selects}\n                    WHERE{{\n                        ?proceeding dblp:publishedIn \"CEUR Workshop Proceedings\";\n                                    dblp:publishedInSeriesVolume {number_var};\n                                    dblp:editedBy ?editor.\n                        ?editor dblp:primaryCreatorName ?nameVar.\n                        OPTIONAL{{?editor dblp:primaryHomepage ?homepageVar.}}\n                        OPTIONAL{{?editor dblp:primaryAffiliation ?affiliationVar.}}\n                        {id_queries}\n                    }}\n                    GROUP BY ?editor\n                \"\"\"\n        qres = self.sparql.queryAsListOfDicts(query)\n        for record in qres:\n            for key, value in record.items():\n                if \"|\" in value:\n                    record[key] = value.split(\n                        '\"|\"'\n                    )  # issue in qlever see https://github.com/ad-freiburg/qlever/discussions/806\n        return qres\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.__init__","title":"<code>__init__(endpoint, debug=False)</code>","text":"<p>constructor</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def __init__(self, endpoint, debug: bool = False):\n    \"\"\"\n    constructor\n    \"\"\"\n    self.debug = debug\n    self.sparql = SPARQL(endpoint)\n    path = os.path.dirname(__file__)\n    qYamlFile = f\"{path}/resources/queries/dblp.yaml\"\n    if os.path.isfile(qYamlFile):\n        self.qm = QueryManager(lang=\"sparql\", queriesPath=qYamlFile)\n    # there is one cache manager for all our json caches\n    self.cache_manager = CacheManager(\"ceurws\")\n    self.dblp_authors = DblpAuthors(endpoint=self)\n    self.dblp_editors = DblpEditors(endpoint=self)\n    self.dblp_papers = DblpPapers(endpoint=self)\n    self.dblp_volumes = DblpVolumes(endpoint=self)\n    self.dblp_managers = {\n        \"dblp/authors\": self.dblp_authors,\n        \"dblp/editors\": self.dblp_editors,\n        \"dblp/papers\": self.dblp_papers,\n        \"dblp/volumes\": self.dblp_volumes,\n    }\n    self.progress_bar = None\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.convertEntityIdToUrlId","title":"<code>convertEntityIdToUrlId(entityId)</code>","text":"<p>Convert the given entityId to the id used in the url Note: use with care this conversion does not always work Args:     entityId: id of the entity Example:     conf/aaai/2022 \u2192 conf/aaai/aaai2022</p> <p>Returns     str - id used in the url     None - if the given entityId can not be converted</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def convertEntityIdToUrlId(self, entityId: str | None) -&gt; str | None:\n    \"\"\"\n    Convert the given entityId to the id used in the url\n    Note: use with care this conversion does not always work\n    Args:\n        entityId: id of the entity\n    Example:\n        conf/aaai/2022 \u2192 conf/aaai/aaai2022\n\n    Returns\n        str - id used in the url\n        None - if the given entityId can not be converted\n    \"\"\"\n    return self.getDblpUrlByDblpId(entityId)\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.getDblpIdByVolumeNumber","title":"<code>getDblpIdByVolumeNumber(number)</code>","text":"<p>Get the dblp entity id by given volume number Args:     number: volume number</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def getDblpIdByVolumeNumber(self, number) -&gt; list[str]:\n    \"\"\"\n    Get the dblp entity id by given volume number\n    Args:\n        number: volume number\n    \"\"\"\n    query = f\"\"\"PREFIX dblp: &lt;https://dblp.org/rdf/schema#&gt;\n        SELECT *\n        WHERE {{ \n            ?proceeding dblp:publishedIn \"CEUR Workshop Proceedings\";\n                        dblp:publishedInSeriesVolume \"{number}\".\n            }}\n    \"\"\"\n    try:\n        qres = self.sparql.queryAsListOfDicts(query)\n    except HTTPError:\n        print(\"dblp sparql endpoint unavailable\")\n        qres = None\n    qIds = []\n    if qres is not None and qres != []:\n        qIds = [record.get(\"proceeding\")[len(self.DBLP_REC_PREFIX) :] for record in qres]\n    return qIds\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.getDblpUrlByDblpId","title":"<code>getDblpUrlByDblpId(entityId=None)</code>","text":"<p>Get the dblp url for given entity id Args:     entityId: volume url</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def getDblpUrlByDblpId(self, entityId: str | None = None) -&gt; str | None:\n    \"\"\"\n    Get the dblp url for given entity id\n    Args:\n        entityId: volume url\n    \"\"\"\n    if entityId is None or entityId == \"\":\n        return None\n    entityUrl = self.DBLP_REC_PREFIX + entityId\n    query = f\"\"\"PREFIX dblp: &lt;https://dblp.org/rdf/schema#&gt;\n            SELECT *\n            WHERE {{ \n                &lt;{entityUrl}&gt; dblp:listedOnTocPage ?url .\n                }}\n        \"\"\"\n    qres = self.sparql.queryAsListOfDicts(query)\n    qIds = []\n    if qres is not None and qres != []:\n        qIds = [record.get(\"url\")[len(self.DBLP_EVENT_PREFIX) :] for record in qres]\n    qId = qIds[0] if qIds is not None and len(qIds) &gt; 0 else None\n    return qId\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.getEditorsOfVolume","title":"<code>getEditorsOfVolume(number)</code>","text":"<p>Get the editors for the given volume number Args:     number: number of the volume if none query for all ceur-ws editors</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list of dictionaries where a dict represents one editor containing all identifiers of the editor</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def getEditorsOfVolume(self, number: int | str | None) -&gt; list[dict]:\n    \"\"\"\n    Get the editors for the given volume number\n    Args:\n        number: number of the volume if none query for all ceur-ws editors\n\n    Returns:\n        list of dictionaries where a dict represents one editor containing all identifiers of the editor\n    \"\"\"\n    number_var = \"?volumeNumber\" if number is None else f'\"{number}\"'\n    dblp_identifiers = DblpAuthorIdentifier.all()\n    optional_clauses: list[str] = []\n    id_vars: list[str] = []\n    for identifier in dblp_identifiers:\n        id_var = f\"?{identifier.name}\"\n        optional_clauses.append(\n            f\"\"\"OPTIONAL{{\n            ?editor datacite:hasIdentifier {id_var}_blank.\n            {id_var}_blank datacite:usesIdentifierScheme {identifier.dblp_property};\n            litre:hasLiteralValue {id_var}Var.}}\"\"\"\n        )\n        id_vars.append(id_var)\n    id_selects = \"\\n\".join(\n        [f\"(group_concat(DISTINCT {id_var}Var;separator='|') as {id_var})\" for id_var in id_vars]\n    )\n    id_queries = \"\\n\".join(optional_clauses)\n    query = f\"\"\"PREFIX datacite: &lt;http://purl.org/spar/datacite/&gt;\n                PREFIX dblp: &lt;https://dblp.org/rdf/schema#&gt;\n                PREFIX litre: &lt;http://purl.org/spar/literal/&gt;\n                SELECT DISTINCT (group_concat(DISTINCT ?nameVar;separator='|') as ?name) \n                                (group_concat(DISTINCT ?homepageVar;separator='|') as ?homepage)\n                                (group_concat(DISTINCT ?affiliationVar;separator='|') as ?affiliation)\n                                {id_selects}\n                WHERE{{\n                    ?proceeding dblp:publishedIn \"CEUR Workshop Proceedings\";\n                                dblp:publishedInSeriesVolume {number_var};\n                                dblp:editedBy ?editor.\n                    ?editor dblp:primaryCreatorName ?nameVar.\n                    OPTIONAL{{?editor dblp:primaryHomepage ?homepageVar.}}\n                    OPTIONAL{{?editor dblp:primaryAffiliation ?affiliationVar.}}\n                    {id_queries}\n                }}\n                GROUP BY ?editor\n            \"\"\"\n    qres = self.sparql.queryAsListOfDicts(query)\n    for record in qres:\n        for key, value in record.items():\n            if \"|\" in value:\n                record[key] = value.split(\n                    '\"|\"'\n                )  # issue in qlever see https://github.com/ad-freiburg/qlever/discussions/806\n    return qres\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.get_ceur_proceeding","title":"<code>get_ceur_proceeding(volume_number)</code>","text":"<p>get ceur proceeding by volume number from dblp Args:     volume_number: number of the volume</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def get_ceur_proceeding(self, volume_number: int) -&gt; DblpProceeding:\n    \"\"\"\n    get ceur proceeding by volume number from dblp\n    Args:\n        volume_number: number of the volume\n    \"\"\"\n    cache_name = f\"dblp/Vol-{volume_number}/metadata\"\n    volume = self.cache_manager.load(cache_name, cls=DblpProceeding)\n    return volume\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.get_ceur_volume_papers","title":"<code>get_ceur_volume_papers(volume_number)</code>","text":"<p>Get all papers published in CEUR-WS from dblp</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def get_ceur_volume_papers(self, volume_number: int) -&gt; list[DblpPaper]:\n    \"\"\"\n    Get all papers published in CEUR-WS from dblp\n    \"\"\"\n    cache_name = f\"dblp/Vol-{volume_number}/papers\"\n    lod = self.cache_manager.load(cache_name)\n    papers = [DblpPaper(**d) for d in lod]\n    return papers\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.get_lod","title":"<code>get_lod(cache_name, query_name, force_query=False)</code>","text":"<p>Get the list of dictionaries for the given cache and query names, optionally forcing a query.</p> <p>Parameters:</p> Name Type Description Default <code>cache_name</code> <code>str</code> <p>The name of the cache to load or store the LOD.</p> required <code>query_name</code> <code>str</code> <p>The name of the query to execute if the data is not cached or forced to query.</p> required <code>force_query</code> <code>bool</code> <p>If True, forces the query execution even if the data is cached. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list</code> <p>List[Dict]: The list of dictionaries loaded either from cache or by executing the SPARQL query.</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def get_lod(self, cache_name: str, query_name: str, force_query: bool = False) -&gt; list:\n    \"\"\"\n    Get the list of dictionaries for the given cache and query names,\n    optionally forcing a query.\n\n    Args:\n        cache_name (str): The name of the cache to load or store the LOD.\n        query_name (str): The name of the query to execute if the data is not cached or forced to query.\n        force_query (bool): If True, forces the query execution even if the data is cached. Defaults to False.\n\n    Returns:\n        List[Dict]: The list of dictionaries loaded either from cache or by executing the SPARQL query.\n    \"\"\"\n    start_time = time.time()  # Record the start time of the operation\n    cache = self.cache_manager.get_cache_by_name(cache_name)\n    if cache.is_stored and not force_query:\n        if self.debug:\n            print(f\"loading {cache_name} from cache\")\n        lod = self.cache_manager.load(cache_name)\n    else:\n        query = self.qm.queriesByName[query_name]\n        if self.debug:\n            print(f\"loading {cache_name} from SPARQL query {query_name}\")\n        lod = self.sparql.queryAsListOfDicts(query.query)\n        self.cache_manager.store(cache_name, lod)\n    end_time = time.time()  # Record the end time of the operation\n    duration = end_time - start_time  # Calculate the duration of the loading process\n\n    if self.debug:\n        print(f\"loaded {len(lod)} records for {cache_name} in {duration:.2f} seconds\")\n    if self.progress_bar:\n        self.progress_bar.update(duration * 100 / 36)\n    return lod\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.load_all","title":"<code>load_all(force_query=False)</code>","text":"<p>load all managers</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def load_all(self, force_query: bool = False):\n    \"\"\"\n    load all managers\n    \"\"\"\n    for _key, manager in self.dblp_managers.items():\n        manager.load(force_query=force_query)\n</code></pre>"},{"location":"#ceurws.dblp.DblpEndpoint.toDblpUrl","title":"<code>toDblpUrl(entityId, withPostfix=False)</code>","text":"<p>Convert the given id to the corresponding dblp url Args:     entityId: dblp event id     withPostfix: If True add the postfix \".html\"</p> <p>Returns:</p> Type Description <code>str | None</code> <p>dblp url of None if the url can not be generated for the given input</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def toDblpUrl(self, entityId: str, withPostfix: bool = False) -&gt; str | None:\n    \"\"\"\n    Convert the given id to the corresponding dblp url\n    Args:\n        entityId: dblp event id\n        withPostfix: If True add the postfix \".html\"\n\n    Returns:\n        dblp url of None if the url can not be generated for the given input\n    \"\"\"\n    urlId = self.convertEntityIdToUrlId(entityId)\n    if urlId is None:\n        return None\n    postfix = \".html\"\n    url = self.DBLP_EVENT_PREFIX + urlId\n    if withPostfix:\n        url += postfix\n    return url\n</code></pre>"},{"location":"#ceurws.dblp.DblpManager","title":"<code>DblpManager</code>","text":"<p>Manage DBLP entities.</p> <p>Attributes:</p> Name Type Description <code>endpoint</code> <code>DblpEndpoint</code> <p>The endpoint for DBLP queries.</p> <code>cache_name</code> <code>str</code> <p>The name of the cache to use.</p> <code>query_name</code> <code>str</code> <p>The name of the query to execute.</p> Source code in <code>ceurws/dblp.py</code> <pre><code>class DblpManager:\n    \"\"\"\n    Manage DBLP entities.\n\n    Attributes:\n        endpoint (DblpEndpoint): The endpoint for DBLP queries.\n        cache_name (str): The name of the cache to use.\n        query_name (str): The name of the query to execute.\n    \"\"\"\n\n    def __init__(self, endpoint: \"DblpEndpoint\", cache_name: str, query_name: str):\n        \"\"\"\n        Initializes the DBLP Manager with the given endpoint, cache name, and query name.\n\n        Args:\n            endpoint (DblpEndpoint): The endpoint for DBLP queries.\n            cache_name (str): The name of the cache to use.\n            query_name (str): The name of the query to execute.\n        \"\"\"\n        self.endpoint = endpoint\n        self.cache_name = cache_name\n        self.query_name = query_name\n\n    def load(self, force_query: bool = False):\n        \"\"\"\n        Loads a list of dictionaries from the DBLP endpoint.\n\n        Args:\n            force_query (bool): If True, forces a new query to the endpoint. Defaults to False.\n        \"\"\"\n        self.lod = self.endpoint.get_lod(self.cache_name, self.query_name, force_query=force_query)\n</code></pre>"},{"location":"#ceurws.dblp.DblpManager.__init__","title":"<code>__init__(endpoint, cache_name, query_name)</code>","text":"<p>Initializes the DBLP Manager with the given endpoint, cache name, and query name.</p> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>DblpEndpoint</code> <p>The endpoint for DBLP queries.</p> required <code>cache_name</code> <code>str</code> <p>The name of the cache to use.</p> required <code>query_name</code> <code>str</code> <p>The name of the query to execute.</p> required Source code in <code>ceurws/dblp.py</code> <pre><code>def __init__(self, endpoint: \"DblpEndpoint\", cache_name: str, query_name: str):\n    \"\"\"\n    Initializes the DBLP Manager with the given endpoint, cache name, and query name.\n\n    Args:\n        endpoint (DblpEndpoint): The endpoint for DBLP queries.\n        cache_name (str): The name of the cache to use.\n        query_name (str): The name of the query to execute.\n    \"\"\"\n    self.endpoint = endpoint\n    self.cache_name = cache_name\n    self.query_name = query_name\n</code></pre>"},{"location":"#ceurws.dblp.DblpManager.load","title":"<code>load(force_query=False)</code>","text":"<p>Loads a list of dictionaries from the DBLP endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>force_query</code> <code>bool</code> <p>If True, forces a new query to the endpoint. Defaults to False.</p> <code>False</code> Source code in <code>ceurws/dblp.py</code> <pre><code>def load(self, force_query: bool = False):\n    \"\"\"\n    Loads a list of dictionaries from the DBLP endpoint.\n\n    Args:\n        force_query (bool): If True, forces a new query to the endpoint. Defaults to False.\n    \"\"\"\n    self.lod = self.endpoint.get_lod(self.cache_name, self.query_name, force_query=force_query)\n</code></pre>"},{"location":"#ceurws.dblp.DblpPapers","title":"<code>DblpPapers</code>","text":"<p>               Bases: <code>DblpManager</code></p> <p>manage all CEUR-WS papers indexed by dblp</p> Source code in <code>ceurws/dblp.py</code> <pre><code>class DblpPapers(DblpManager):\n    \"\"\"\n    manage all CEUR-WS papers indexed by dblp\n    \"\"\"\n\n    def __init__(self, endpoint: \"DblpEndpoint\"):\n        super().__init__(endpoint, \"dblp/papers\", \"CEUR-WS all Papers\")\n        self.papers: list[DblpPaper] | None = None\n        self.papers_by_volume: dict[str, dict] = {}\n        self.papersById: dict[str, DblpPaper] = {}\n        self.papersByProceeding: dict[str, list[DblpPaper]] = {}\n\n    def load(self, force_query: bool = False):\n        \"\"\"\n        load my editors\n        \"\"\"\n        if self.papers is None:\n            super().load(force_query=force_query)\n            dblp_authors = self.endpoint.dblp_authors\n            dblp_authors.load(force_query=force_query)\n            self.papers = []\n            for d in self.lod:\n                pdf_id = d.get(\"pdf_url\", None)\n                if pdf_id and isinstance(pdf_id, str):\n                    pdf_id = pdf_id.replace(\"http://ceur-ws.org/\", \"\")\n                    pdf_id = pdf_id.replace(\"https://ceur-ws.org/\", \"\")\n                    pdf_id = pdf_id.replace(\".pdf\", \"\")\n                authors = []\n                # get the authors string\n                authors_str = d.get(\"author\", \"\")\n                # &gt;;&lt;  qlever quirk until 2023-12\n                delim = \"&gt;;&lt;\" if \"&gt;;&lt;\" in authors_str else \";\"\n                for dblp_author_id in authors_str.split(delim):  #\n                    author = dblp_authors.authorsById.get(dblp_author_id, None)\n                    if author:\n                        authors.append(author)\n                paper = DblpPaper(\n                    dblp_publication_id=d.get(\"paper\"),\n                    volume_number=int(d.get(\"volume_number\")),\n                    dblp_proceeding_id=d.get(\"proceeding\"),\n                    title=d.get(\"title\"),\n                    pdf_id=pdf_id,\n                    authors=authors,\n                )  # type: ignore\n                self.papers.append(paper)\n            self.papers_by_volume = LOD.getLookup(self.papers, \"volume_number\", withDuplicates=True)\n            self.papersByProceeding = {\n                key: list(group) for key, group in groupby(self.papers, lambda paper: paper.dblp_proceeding_id)\n            }\n            self.papersById = {p.dblp_publication_id: p for p in self.papers} if self.papers is not None else {}\n            # papers per volume\n            for volume_number, vol_papers in sorted(self.papers_by_volume.items()):\n                vol_paper_lod = [dataclasses.asdict(paper) for paper in vol_papers]\n                cache_name = f\"dblp/Vol-{volume_number}/papers\"\n                if self.endpoint.progress_bar:\n                    self.endpoint.progress_bar.update(30 / 3650)\n                    # print(f\"caching {cache_name}\")\n                self.endpoint.cache_manager.store(\n                    cache_name,\n                    vol_paper_lod,\n                )\n</code></pre>"},{"location":"#ceurws.dblp.DblpPapers.load","title":"<code>load(force_query=False)</code>","text":"<p>load my editors</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def load(self, force_query: bool = False):\n    \"\"\"\n    load my editors\n    \"\"\"\n    if self.papers is None:\n        super().load(force_query=force_query)\n        dblp_authors = self.endpoint.dblp_authors\n        dblp_authors.load(force_query=force_query)\n        self.papers = []\n        for d in self.lod:\n            pdf_id = d.get(\"pdf_url\", None)\n            if pdf_id and isinstance(pdf_id, str):\n                pdf_id = pdf_id.replace(\"http://ceur-ws.org/\", \"\")\n                pdf_id = pdf_id.replace(\"https://ceur-ws.org/\", \"\")\n                pdf_id = pdf_id.replace(\".pdf\", \"\")\n            authors = []\n            # get the authors string\n            authors_str = d.get(\"author\", \"\")\n            # &gt;;&lt;  qlever quirk until 2023-12\n            delim = \"&gt;;&lt;\" if \"&gt;;&lt;\" in authors_str else \";\"\n            for dblp_author_id in authors_str.split(delim):  #\n                author = dblp_authors.authorsById.get(dblp_author_id, None)\n                if author:\n                    authors.append(author)\n            paper = DblpPaper(\n                dblp_publication_id=d.get(\"paper\"),\n                volume_number=int(d.get(\"volume_number\")),\n                dblp_proceeding_id=d.get(\"proceeding\"),\n                title=d.get(\"title\"),\n                pdf_id=pdf_id,\n                authors=authors,\n            )  # type: ignore\n            self.papers.append(paper)\n        self.papers_by_volume = LOD.getLookup(self.papers, \"volume_number\", withDuplicates=True)\n        self.papersByProceeding = {\n            key: list(group) for key, group in groupby(self.papers, lambda paper: paper.dblp_proceeding_id)\n        }\n        self.papersById = {p.dblp_publication_id: p for p in self.papers} if self.papers is not None else {}\n        # papers per volume\n        for volume_number, vol_papers in sorted(self.papers_by_volume.items()):\n            vol_paper_lod = [dataclasses.asdict(paper) for paper in vol_papers]\n            cache_name = f\"dblp/Vol-{volume_number}/papers\"\n            if self.endpoint.progress_bar:\n                self.endpoint.progress_bar.update(30 / 3650)\n                # print(f\"caching {cache_name}\")\n            self.endpoint.cache_manager.store(\n                cache_name,\n                vol_paper_lod,\n            )\n</code></pre>"},{"location":"#ceurws.dblp.DblpVolumes","title":"<code>DblpVolumes</code>","text":"<p>               Bases: <code>DblpManager</code></p> <p>Manage all DBLP indexed volumes.</p> Source code in <code>ceurws/dblp.py</code> <pre><code>class DblpVolumes(DblpManager):\n    \"\"\"\n    Manage all DBLP indexed volumes.\n    \"\"\"\n\n    def __init__(self, endpoint: \"DblpEndpoint\"):\n        super().__init__(endpoint, \"dblp/volumes\", \"CEUR-WS all Volumes\")\n        self.volumes = None\n\n    def load(self, force_query: bool = False):\n        \"\"\"\n        load my volumes\n        \"\"\"\n        if self.volumes is None:\n            super().load(force_query=force_query)\n            volumes = []\n            dblp_editors = self.endpoint.dblp_editors\n            dblp_editors.load(force_query=force_query)\n            dblp_papers = self.endpoint.dblp_papers\n            dblp_papers.load(force_query=force_query)\n            for d in self.lod:\n                if int(d.get(\"volume_number\")) == 3000:\n                    pass\n                vol_editors = []\n                editor_str = d.get(\"editor\", \"\")\n                # &gt;;&lt;  qlever quirk until 2023-12\n                delim = \"&gt;;&lt;\" if \"&gt;;&lt;\" in editor_str else \";\"\n                for dblp_author_id in editor_str.split(delim):\n                    editor = dblp_editors.editorsById.get(dblp_author_id, None)\n                    if editor:\n                        vol_editors.append(editor)\n                volume = DblpProceeding(\n                    dblp_publication_id=d.get(\"proceeding\"),\n                    volume_number=int(d.get(\"volume_number\")),\n                    dblp_event_id=d.get(\"dblp_event_id\"),\n                    title=d.get(\"title\"),\n                    editors=vol_editors,\n                    papers=dblp_papers.papersByProceeding.get(d.get(\"proceeding\")),\n                )  # type: ignore\n                volumes.append(volume)\n            volume_by_number, _errors = LOD.getLookup(volumes, \"volume_number\")\n            for number, volume in sorted(volume_by_number.items()):\n                cache_name = f\"dblp/Vol-{number}/metadata\"\n                if self.endpoint.progress_bar:\n                    self.endpoint.progress_bar.update(int(30 / 3650))\n                self.endpoint.cache_manager.store(cache_name, volume)\n        return self.volumes\n</code></pre>"},{"location":"#ceurws.dblp.DblpVolumes.load","title":"<code>load(force_query=False)</code>","text":"<p>load my volumes</p> Source code in <code>ceurws/dblp.py</code> <pre><code>def load(self, force_query: bool = False):\n    \"\"\"\n    load my volumes\n    \"\"\"\n    if self.volumes is None:\n        super().load(force_query=force_query)\n        volumes = []\n        dblp_editors = self.endpoint.dblp_editors\n        dblp_editors.load(force_query=force_query)\n        dblp_papers = self.endpoint.dblp_papers\n        dblp_papers.load(force_query=force_query)\n        for d in self.lod:\n            if int(d.get(\"volume_number\")) == 3000:\n                pass\n            vol_editors = []\n            editor_str = d.get(\"editor\", \"\")\n            # &gt;;&lt;  qlever quirk until 2023-12\n            delim = \"&gt;;&lt;\" if \"&gt;;&lt;\" in editor_str else \";\"\n            for dblp_author_id in editor_str.split(delim):\n                editor = dblp_editors.editorsById.get(dblp_author_id, None)\n                if editor:\n                    vol_editors.append(editor)\n            volume = DblpProceeding(\n                dblp_publication_id=d.get(\"proceeding\"),\n                volume_number=int(d.get(\"volume_number\")),\n                dblp_event_id=d.get(\"dblp_event_id\"),\n                title=d.get(\"title\"),\n                editors=vol_editors,\n                papers=dblp_papers.papersByProceeding.get(d.get(\"proceeding\")),\n            )  # type: ignore\n            volumes.append(volume)\n        volume_by_number, _errors = LOD.getLookup(volumes, \"volume_number\")\n        for number, volume in sorted(volume_by_number.items()):\n            cache_name = f\"dblp/Vol-{number}/metadata\"\n            if self.endpoint.progress_bar:\n                self.endpoint.progress_bar.update(int(30 / 3650))\n            self.endpoint.cache_manager.store(cache_name, volume)\n    return self.volumes\n</code></pre>"},{"location":"#ceurws.indexparser","title":"<code>indexparser</code>","text":"<p>Created on 11.08.2022</p> <p>@author: wf</p>"},{"location":"#ceurws.indexparser.IndexHtmlParser","title":"<code>IndexHtmlParser</code>","text":"<p>               Bases: <code>Textparser</code></p> <p>CEUR-WS Index.html parser</p> Source code in <code>ceurws/indexparser.py</code> <pre><code>class IndexHtmlParser(Textparser):\n    \"\"\"\n    CEUR-WS Index.html parser\n    \"\"\"\n\n    def __init__(self, htmlText: str, config: ParserConfig | None = None):\n        \"\"\"\n        Constructor\n\n        Args:\n            htmlText(str): the HTML text of the index page\n        \"\"\"\n        if config is None:\n            config = ParserConfig()\n        self.config = config\n        Textparser.__init__(self, debug=config.debug)\n        self.htmlText = htmlText\n        # soup (in memory is slow)\n        # soup = BeautifulSoup(html_page, 'html.parser'\n        self.lines = htmlText.split(\"\\n\")\n        # trStart, trEnd = makeHTMLTags(\"tr\")\n        # self.tr = trStart + SkipTo(trEnd).setResultsName(\"tr\") + trEnd.suppress()\n        self.linkPattern = re.compile(r\"\"\".*href=[\\'\"]?([^\\'\" &gt;]+).*\"\"\", re.I)\n        self.volPattern = re.compile(\"http://ceur-ws.org/Vol-([0-9]+)\")\n        self.volLinkPattern = re.compile(\n            r\"\"\".*&lt;a\\s+href=[\\'\"]http://ceur-ws.org/Vol-([0-9]+)[/]?[\\'\"]&gt;([^&lt;]*)&lt;/a&gt;.*\"\"\",\n            re.I | re.DOTALL,\n        )\n        # Pre-compile patterns used in find and findVolume\n        self.thColspanPattern = re.compile(r\"^.*&lt;th\\s*colspan\", re.I)\n        self.trStartPattern = re.compile(r\"^\\s*&lt;tr&gt;\", re.I)\n        self.trEndPattern = re.compile(r\"^\\s*&lt;/tr&gt;\", re.I)\n        # Pre-compile patterns used in setVolumeTitle\n        self.editedByPattern = re.compile(\"Edited by:\")\n        self.tdBgColorPattern = re.compile(\"&lt;td bgcolor\", re.I)\n\n    def find(self, startLine: int, compiledPattern, step: int = 1) -&gt; int | None:\n        \"\"\"\n        find the next line with the given compiled regular expression pattern\n\n        Args:\n            startLine(int): index of the line to start search\n            compiledPattern(re.Pattern): the compiled regular expression pattern to search for\n            step(int): the steps to take e.g. +1 for forward -1 for backwards\n\n        Return:\n            int: the line number of the line or None if nothing was found\n        \"\"\"\n        lineNo = startLine\n        while 0 &lt; lineNo &lt; len(self.lines) + 1:\n            line = self.lines[lineNo - 1]\n            if compiledPattern.match(line):\n                return lineNo\n            lineNo += step\n        return None\n\n    def findVolume(\n        self,\n        volCount: int,\n        startLine: int,\n        expectedTr: int = 3,\n        progress: int = 10,\n    ) -&gt; tuple[int | None, int | None]:\n        \"\"\"\n        find Volume lines from the given startLine\n\n        Args:\n            volCount(int): the volumeCount before the startLine\n            startLine(int): index of the line to search\n            expectedTr(int): number of &lt;tr&gt; tags expected\n            progress(int): how often to show the progress\n\n        Returns:\n            endLine of the volume html or None\n        \"\"\"\n        trStartLine = self.find(startLine, self.thColspanPattern)\n        if trStartLine is not None:\n            lineNo = trStartLine + 1\n            trCount = 1\n            while lineNo &lt; len(self.lines):\n                trLine = self.find(lineNo, self.trStartPattern)\n                if trLine is None:\n                    break\n                else:\n                    lineNo = trLine + 1\n                    trCount += 1\n                    if trCount == expectedTr:\n                        trEndLine = self.find(lineNo + 1, self.trEndPattern)\n                        if volCount % progress == 0 and self.config.verbose:\n                            print(f\"volume count {volCount+1:4}: lines {trStartLine:6}-{trEndLine:6}\")\n                        return trStartLine, trEndLine\n        return None, None\n\n    def setVolumeNumber(self, volume, href):\n        \"\"\"\n        set the volumen number\n        \"\"\"\n        if href is None:\n            return\n        volNumber = self.getMatch(self.volPattern, href, 1)\n        if volNumber is not None:\n            volume[\"number\"] = int(volNumber)\n\n    def setVolumeName(self, volume, line):\n        \"\"\"\n        set the volume name\n        \"\"\"\n        volName = self.getMatch(self.volLinkPattern, line, 2)\n        if volName is not None:\n            valid = True\n            if not volName.startswith(\"http:\"):\n                invalidKeys = [\"deleted upon editor request\", \"Not used\"]\n                for invalidKey in invalidKeys:\n                    if invalidKey in volName:\n                        href = self.getMatch(self.linkPattern, line, 1)\n                        self.setVolumeNumber(volume, href)\n                        valid = False\n                volume[\"valid\"] = valid\n                if valid:\n                    volName = html.unescape(volName)\n                    volName = Textparser.sanitize(volName)\n                    volume[\"volname\"] = volName\n\n    def setVolumeTitle(self, volume: dict, lineIndex: int):\n        \"\"\"\n        set the volume title\n\n        Args:\n            volume(dict): the volumeRecord to modify\n            lineIndex: where to start setting the volumeTitle\n        \"\"\"\n        editedByLine = self.find(lineIndex, self.editedByPattern)\n        if editedByLine is not None:\n            tdLine = self.find(editedByLine, self.tdBgColorPattern, step=-1)\n            if tdLine is not None:\n                tdIndex = tdLine - 1\n                title = \"\"\n                delim = \"\"\n                while tdIndex &lt; len(self.lines):\n                    line = self.lines[tdIndex]\n                    if line.startswith(\"Edited by:\"):\n                        break\n                    for tag in [\n                        '&lt;TD bgcolor=\"#FFFFFF\"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD bgcolor=\"#FFFFFF\"&gt;',\n                        '&lt;TD bgcolor=\"#FFFFFF\"&gt;',\n                        '&lt;td bgcolor=\"#FFFFFF\"&gt;',\n                        \"&lt;BR&gt;\",\n                        \"&lt;br&gt;\",\n                    ]:\n                        line = line.replace(tag, \"\")\n                    line = line.replace(\"\\r\", \" \")\n                    title += line + delim\n                    delim = \" \"\n                    tdIndex += 1\n                volume[\"tdtitle\"] = html.unescape(title).strip()\n\n    def setSeeAlsoVolumes(self, volume: dict, firstLine: int, lastLine: int):\n        \"\"\"\n        Extract and set the volume numbers form the see also list\n        Example result {\"seealso\": [\"Vol-3067\"]}\n\n        Args:\n            volume: the volumeRecord to modify\n            lineIndex: where to start setting the volumeTitle\n        \"\"\"\n        volumes = []\n        see_also = \"\"\n        for line in range(firstLine, lastLine):\n            see_also += self.lines[line]\n        see_also_section = re.search(r\"see also:(.*?)&lt;/font&gt;\", see_also, re.DOTALL | re.IGNORECASE)\n\n        if see_also_section:\n            # Extract the volumes using regex from the see also section\n            volumes = re.findall(\n                r'&lt;a href=\"#(Vol-\\d+)\"&gt;',\n                see_also_section.group(1),\n                re.IGNORECASE,\n            )\n        volume[\"seealso\"] = volumes\n\n    def getInfo(self, volume: dict, info: str, pattern, line: str):\n        \"\"\"\n        get the info for the given patterns trying to match the pattern on\n        the given line\n\n        Args:\n            volume(dict): the result dict\n            info(str): the name of the dict key to fill\n            pattern(regexp): the regular expression to check\n            line(str): the line to check\n        \"\"\"\n        infoValue = self.getMatch(pattern, line, 1)\n        if infoValue is not None:\n            for delim in [\"&lt;BR&gt;\", \"&lt;br&gt;\"]:\n                infoValue = infoValue.replace(delim, \"\")\n            infoValue = infoValue.strip()\n            if info in [\"editors\", \"submittedBy\"]:\n                infoValue = html.unescape(infoValue)\n            if info == \"pubDate\":\n                try:\n                    infoValue = datetime.datetime.strptime(infoValue, \"%d-%b-%Y\")\n                    published = infoValue.strftime(\"%Y-%m-%d\")\n                    volume[\"published\"] = published\n                    volume[\"year\"] = infoValue.year\n                except ValueError as ve:\n                    msg = f\"pubDate: {infoValue} of {volume} parsing failed with {ve}\"\n                    self.log(msg)\n            if info in [\"urn\", \"url\", \"archive\"]:\n                href = self.getMatch(self.linkPattern, infoValue, 1)\n                if href is not None:\n                    infoValue = href\n                    if info == \"url\":\n                        self.setVolumeNumber(volume, href)\n                    if info == \"urn\":\n                        infoValue = href.replace(\"https://nbn-resolving.org/\", \"\")\n            volume[info] = infoValue\n\n    def parseVolume(self, volCount: int, fromLine: int, toLine: int, verbose: bool):\n        \"\"\"\n        parse a volume from the given line range\n        \"\"\"\n        lineCount = toLine - fromLine\n        volume = {\n            \"fromLine\": fromLine,\n            \"toLine\": toLine,\n            \"valid\": None,\n            \"url\": None,\n            \"acronym\": None,\n            \"title\": None,\n            \"loctime\": None,\n        }\n        self.setVolumeTitle(volume, fromLine)\n        self.setSeeAlsoVolumes(volume, fromLine, toLine)\n\n        infoPattern = {}\n        infoMappings = [\n            (\"URN\", \"urn\"),\n            (\"ONLINE\", \"url\"),\n            (\"ARCHIVE\", \"archive\"),\n            (\"Edited by\", \"editors\"),\n            (\"Submitted by\", \"submittedBy\"),\n            (\"Published on CEUR-WS\", \"pubDate\"),\n        ]\n        for prefix, info in infoMappings:\n            infoPattern[info] = re.compile(rf\"^\\s*{prefix}:(.*)\")\n        for lineIndex in range(fromLine, toLine):\n            line = self.lines[lineIndex]\n            for info, pattern in infoPattern.items():\n                self.getInfo(volume, info, pattern, line)\n            self.setVolumeName(volume, line)\n            if verbose:\n                print(line)\n        volumeNumber = volume.get(\"number\", \"?\")\n        acronym = volume.get(\"acronym\", \"?\")\n        self.log(f\"{volumeNumber:4}-{volCount:4}:{fromLine}+{lineCount} {acronym}\")\n        return volume\n\n    def parse(self, vol_limit: int | None = None):\n        \"\"\"\n        parse my html code for Volume info\n        \"\"\"\n        # Compile the regex pattern right before its usage\n        mainTablePattern = re.compile(r'\\s*&lt;TABLE id=\"MAINTABLE\"', re.I)\n        lineNo = self.find(1, mainTablePattern)\n        volCount = 0\n        volumes = {}\n        while self.lines and lineNo and lineNo &lt; len(self.lines):\n            if vol_limit and volCount &gt;= vol_limit:\n                break\n            expectedTr = 3\n            volStartLine, volEndLine = self.findVolume(volCount, lineNo, expectedTr=expectedTr)\n            if volStartLine is None or volEndLine is None:\n                break\n            else:\n                volCount += 1\n                volume = self.parseVolume(\n                    volCount,\n                    volStartLine,\n                    volEndLine,\n                    verbose=self.config.verbose,\n                )\n                # synchronize on &lt;tr&gt;&lt;th and not on end since trailing TR might be missing\n                lineNo = volStartLine + 1\n                if \"number\" in volume:\n                    volume_number = volume[\"number\"]\n                    if volume_number &lt; self.config.down_to_volume:\n                        break\n                    volumes[volume_number] = volume\n                    if self.config.progress_bar:\n                        self.config.progress_bar.update()\n                else:\n                    self.log(f\"volume not found for volume at {volStartLine}\")\n        return volumes\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.__init__","title":"<code>__init__(htmlText, config=None)</code>","text":"<p>Constructor</p> <p>Parameters:</p> Name Type Description Default <code>htmlText(str)</code> <p>the HTML text of the index page</p> required Source code in <code>ceurws/indexparser.py</code> <pre><code>def __init__(self, htmlText: str, config: ParserConfig | None = None):\n    \"\"\"\n    Constructor\n\n    Args:\n        htmlText(str): the HTML text of the index page\n    \"\"\"\n    if config is None:\n        config = ParserConfig()\n    self.config = config\n    Textparser.__init__(self, debug=config.debug)\n    self.htmlText = htmlText\n    # soup (in memory is slow)\n    # soup = BeautifulSoup(html_page, 'html.parser'\n    self.lines = htmlText.split(\"\\n\")\n    # trStart, trEnd = makeHTMLTags(\"tr\")\n    # self.tr = trStart + SkipTo(trEnd).setResultsName(\"tr\") + trEnd.suppress()\n    self.linkPattern = re.compile(r\"\"\".*href=[\\'\"]?([^\\'\" &gt;]+).*\"\"\", re.I)\n    self.volPattern = re.compile(\"http://ceur-ws.org/Vol-([0-9]+)\")\n    self.volLinkPattern = re.compile(\n        r\"\"\".*&lt;a\\s+href=[\\'\"]http://ceur-ws.org/Vol-([0-9]+)[/]?[\\'\"]&gt;([^&lt;]*)&lt;/a&gt;.*\"\"\",\n        re.I | re.DOTALL,\n    )\n    # Pre-compile patterns used in find and findVolume\n    self.thColspanPattern = re.compile(r\"^.*&lt;th\\s*colspan\", re.I)\n    self.trStartPattern = re.compile(r\"^\\s*&lt;tr&gt;\", re.I)\n    self.trEndPattern = re.compile(r\"^\\s*&lt;/tr&gt;\", re.I)\n    # Pre-compile patterns used in setVolumeTitle\n    self.editedByPattern = re.compile(\"Edited by:\")\n    self.tdBgColorPattern = re.compile(\"&lt;td bgcolor\", re.I)\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.find","title":"<code>find(startLine, compiledPattern, step=1)</code>","text":"<p>find the next line with the given compiled regular expression pattern</p> <p>Parameters:</p> Name Type Description Default <code>startLine(int)</code> <p>index of the line to start search</p> required <code>compiledPattern(re.Pattern)</code> <p>the compiled regular expression pattern to search for</p> required <code>step(int)</code> <p>the steps to take e.g. +1 for forward -1 for backwards</p> required Return <p>int: the line number of the line or None if nothing was found</p> Source code in <code>ceurws/indexparser.py</code> <pre><code>def find(self, startLine: int, compiledPattern, step: int = 1) -&gt; int | None:\n    \"\"\"\n    find the next line with the given compiled regular expression pattern\n\n    Args:\n        startLine(int): index of the line to start search\n        compiledPattern(re.Pattern): the compiled regular expression pattern to search for\n        step(int): the steps to take e.g. +1 for forward -1 for backwards\n\n    Return:\n        int: the line number of the line or None if nothing was found\n    \"\"\"\n    lineNo = startLine\n    while 0 &lt; lineNo &lt; len(self.lines) + 1:\n        line = self.lines[lineNo - 1]\n        if compiledPattern.match(line):\n            return lineNo\n        lineNo += step\n    return None\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.findVolume","title":"<code>findVolume(volCount, startLine, expectedTr=3, progress=10)</code>","text":"<p>find Volume lines from the given startLine</p> <p>Parameters:</p> Name Type Description Default <code>volCount(int)</code> <p>the volumeCount before the startLine</p> required <code>startLine(int)</code> <p>index of the line to search</p> required <code>expectedTr(int)</code> <p>number of  tags expected required <code>progress(int)</code> <p>how often to show the progress</p> required <p>Returns:</p> Type Description <code>tuple[int | None, int | None]</code> <p>endLine of the volume html or None</p> Source code in <code>ceurws/indexparser.py</code> <pre><code>def findVolume(\n    self,\n    volCount: int,\n    startLine: int,\n    expectedTr: int = 3,\n    progress: int = 10,\n) -&gt; tuple[int | None, int | None]:\n    \"\"\"\n    find Volume lines from the given startLine\n\n    Args:\n        volCount(int): the volumeCount before the startLine\n        startLine(int): index of the line to search\n        expectedTr(int): number of &lt;tr&gt; tags expected\n        progress(int): how often to show the progress\n\n    Returns:\n        endLine of the volume html or None\n    \"\"\"\n    trStartLine = self.find(startLine, self.thColspanPattern)\n    if trStartLine is not None:\n        lineNo = trStartLine + 1\n        trCount = 1\n        while lineNo &lt; len(self.lines):\n            trLine = self.find(lineNo, self.trStartPattern)\n            if trLine is None:\n                break\n            else:\n                lineNo = trLine + 1\n                trCount += 1\n                if trCount == expectedTr:\n                    trEndLine = self.find(lineNo + 1, self.trEndPattern)\n                    if volCount % progress == 0 and self.config.verbose:\n                        print(f\"volume count {volCount+1:4}: lines {trStartLine:6}-{trEndLine:6}\")\n                    return trStartLine, trEndLine\n    return None, None\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.getInfo","title":"<code>getInfo(volume, info, pattern, line)</code>","text":"<p>get the info for the given patterns trying to match the pattern on the given line</p> <p>Parameters:</p> Name Type Description Default <code>volume(dict)</code> <p>the result dict</p> required <code>info(str)</code> <p>the name of the dict key to fill</p> required <code>pattern(regexp)</code> <p>the regular expression to check</p> required <code>line(str)</code> <p>the line to check</p> required Source code in <code>ceurws/indexparser.py</code> <pre><code>def getInfo(self, volume: dict, info: str, pattern, line: str):\n    \"\"\"\n    get the info for the given patterns trying to match the pattern on\n    the given line\n\n    Args:\n        volume(dict): the result dict\n        info(str): the name of the dict key to fill\n        pattern(regexp): the regular expression to check\n        line(str): the line to check\n    \"\"\"\n    infoValue = self.getMatch(pattern, line, 1)\n    if infoValue is not None:\n        for delim in [\"&lt;BR&gt;\", \"&lt;br&gt;\"]:\n            infoValue = infoValue.replace(delim, \"\")\n        infoValue = infoValue.strip()\n        if info in [\"editors\", \"submittedBy\"]:\n            infoValue = html.unescape(infoValue)\n        if info == \"pubDate\":\n            try:\n                infoValue = datetime.datetime.strptime(infoValue, \"%d-%b-%Y\")\n                published = infoValue.strftime(\"%Y-%m-%d\")\n                volume[\"published\"] = published\n                volume[\"year\"] = infoValue.year\n            except ValueError as ve:\n                msg = f\"pubDate: {infoValue} of {volume} parsing failed with {ve}\"\n                self.log(msg)\n        if info in [\"urn\", \"url\", \"archive\"]:\n            href = self.getMatch(self.linkPattern, infoValue, 1)\n            if href is not None:\n                infoValue = href\n                if info == \"url\":\n                    self.setVolumeNumber(volume, href)\n                if info == \"urn\":\n                    infoValue = href.replace(\"https://nbn-resolving.org/\", \"\")\n        volume[info] = infoValue\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.parse","title":"<code>parse(vol_limit=None)</code>","text":"<p>parse my html code for Volume info</p> Source code in <code>ceurws/indexparser.py</code> <pre><code>def parse(self, vol_limit: int | None = None):\n    \"\"\"\n    parse my html code for Volume info\n    \"\"\"\n    # Compile the regex pattern right before its usage\n    mainTablePattern = re.compile(r'\\s*&lt;TABLE id=\"MAINTABLE\"', re.I)\n    lineNo = self.find(1, mainTablePattern)\n    volCount = 0\n    volumes = {}\n    while self.lines and lineNo and lineNo &lt; len(self.lines):\n        if vol_limit and volCount &gt;= vol_limit:\n            break\n        expectedTr = 3\n        volStartLine, volEndLine = self.findVolume(volCount, lineNo, expectedTr=expectedTr)\n        if volStartLine is None or volEndLine is None:\n            break\n        else:\n            volCount += 1\n            volume = self.parseVolume(\n                volCount,\n                volStartLine,\n                volEndLine,\n                verbose=self.config.verbose,\n            )\n            # synchronize on &lt;tr&gt;&lt;th and not on end since trailing TR might be missing\n            lineNo = volStartLine + 1\n            if \"number\" in volume:\n                volume_number = volume[\"number\"]\n                if volume_number &lt; self.config.down_to_volume:\n                    break\n                volumes[volume_number] = volume\n                if self.config.progress_bar:\n                    self.config.progress_bar.update()\n            else:\n                self.log(f\"volume not found for volume at {volStartLine}\")\n    return volumes\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.parseVolume","title":"<code>parseVolume(volCount, fromLine, toLine, verbose)</code>","text":"<p>parse a volume from the given line range</p> Source code in <code>ceurws/indexparser.py</code> <pre><code>def parseVolume(self, volCount: int, fromLine: int, toLine: int, verbose: bool):\n    \"\"\"\n    parse a volume from the given line range\n    \"\"\"\n    lineCount = toLine - fromLine\n    volume = {\n        \"fromLine\": fromLine,\n        \"toLine\": toLine,\n        \"valid\": None,\n        \"url\": None,\n        \"acronym\": None,\n        \"title\": None,\n        \"loctime\": None,\n    }\n    self.setVolumeTitle(volume, fromLine)\n    self.setSeeAlsoVolumes(volume, fromLine, toLine)\n\n    infoPattern = {}\n    infoMappings = [\n        (\"URN\", \"urn\"),\n        (\"ONLINE\", \"url\"),\n        (\"ARCHIVE\", \"archive\"),\n        (\"Edited by\", \"editors\"),\n        (\"Submitted by\", \"submittedBy\"),\n        (\"Published on CEUR-WS\", \"pubDate\"),\n    ]\n    for prefix, info in infoMappings:\n        infoPattern[info] = re.compile(rf\"^\\s*{prefix}:(.*)\")\n    for lineIndex in range(fromLine, toLine):\n        line = self.lines[lineIndex]\n        for info, pattern in infoPattern.items():\n            self.getInfo(volume, info, pattern, line)\n        self.setVolumeName(volume, line)\n        if verbose:\n            print(line)\n    volumeNumber = volume.get(\"number\", \"?\")\n    acronym = volume.get(\"acronym\", \"?\")\n    self.log(f\"{volumeNumber:4}-{volCount:4}:{fromLine}+{lineCount} {acronym}\")\n    return volume\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.setSeeAlsoVolumes","title":"<code>setSeeAlsoVolumes(volume, firstLine, lastLine)</code>","text":"<p>Extract and set the volume numbers form the see also list Example result {\"seealso\": [\"Vol-3067\"]}</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>dict</code> <p>the volumeRecord to modify</p> required <code>lineIndex</code> <p>where to start setting the volumeTitle</p> required Source code in <code>ceurws/indexparser.py</code> <pre><code>def setSeeAlsoVolumes(self, volume: dict, firstLine: int, lastLine: int):\n    \"\"\"\n    Extract and set the volume numbers form the see also list\n    Example result {\"seealso\": [\"Vol-3067\"]}\n\n    Args:\n        volume: the volumeRecord to modify\n        lineIndex: where to start setting the volumeTitle\n    \"\"\"\n    volumes = []\n    see_also = \"\"\n    for line in range(firstLine, lastLine):\n        see_also += self.lines[line]\n    see_also_section = re.search(r\"see also:(.*?)&lt;/font&gt;\", see_also, re.DOTALL | re.IGNORECASE)\n\n    if see_also_section:\n        # Extract the volumes using regex from the see also section\n        volumes = re.findall(\n            r'&lt;a href=\"#(Vol-\\d+)\"&gt;',\n            see_also_section.group(1),\n            re.IGNORECASE,\n        )\n    volume[\"seealso\"] = volumes\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.setVolumeName","title":"<code>setVolumeName(volume, line)</code>","text":"<p>set the volume name</p> Source code in <code>ceurws/indexparser.py</code> <pre><code>def setVolumeName(self, volume, line):\n    \"\"\"\n    set the volume name\n    \"\"\"\n    volName = self.getMatch(self.volLinkPattern, line, 2)\n    if volName is not None:\n        valid = True\n        if not volName.startswith(\"http:\"):\n            invalidKeys = [\"deleted upon editor request\", \"Not used\"]\n            for invalidKey in invalidKeys:\n                if invalidKey in volName:\n                    href = self.getMatch(self.linkPattern, line, 1)\n                    self.setVolumeNumber(volume, href)\n                    valid = False\n            volume[\"valid\"] = valid\n            if valid:\n                volName = html.unescape(volName)\n                volName = Textparser.sanitize(volName)\n                volume[\"volname\"] = volName\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.setVolumeNumber","title":"<code>setVolumeNumber(volume, href)</code>","text":"<p>set the volumen number</p> Source code in <code>ceurws/indexparser.py</code> <pre><code>def setVolumeNumber(self, volume, href):\n    \"\"\"\n    set the volumen number\n    \"\"\"\n    if href is None:\n        return\n    volNumber = self.getMatch(self.volPattern, href, 1)\n    if volNumber is not None:\n        volume[\"number\"] = int(volNumber)\n</code></pre>"},{"location":"#ceurws.indexparser.IndexHtmlParser.setVolumeTitle","title":"<code>setVolumeTitle(volume, lineIndex)</code>","text":"<p>set the volume title</p> <p>Parameters:</p> Name Type Description Default <code>volume(dict)</code> <p>the volumeRecord to modify</p> required <code>lineIndex</code> <code>int</code> <p>where to start setting the volumeTitle</p> required Source code in <code>ceurws/indexparser.py</code> <pre><code>def setVolumeTitle(self, volume: dict, lineIndex: int):\n    \"\"\"\n    set the volume title\n\n    Args:\n        volume(dict): the volumeRecord to modify\n        lineIndex: where to start setting the volumeTitle\n    \"\"\"\n    editedByLine = self.find(lineIndex, self.editedByPattern)\n    if editedByLine is not None:\n        tdLine = self.find(editedByLine, self.tdBgColorPattern, step=-1)\n        if tdLine is not None:\n            tdIndex = tdLine - 1\n            title = \"\"\n            delim = \"\"\n            while tdIndex &lt; len(self.lines):\n                line = self.lines[tdIndex]\n                if line.startswith(\"Edited by:\"):\n                    break\n                for tag in [\n                    '&lt;TD bgcolor=\"#FFFFFF\"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD bgcolor=\"#FFFFFF\"&gt;',\n                    '&lt;TD bgcolor=\"#FFFFFF\"&gt;',\n                    '&lt;td bgcolor=\"#FFFFFF\"&gt;',\n                    \"&lt;BR&gt;\",\n                    \"&lt;br&gt;\",\n                ]:\n                    line = line.replace(tag, \"\")\n                line = line.replace(\"\\r\", \" \")\n                title += line + delim\n                delim = \" \"\n                tdIndex += 1\n            volume[\"tdtitle\"] = html.unescape(title).strip()\n</code></pre>"},{"location":"#ceurws.indexparser.ParserConfig","title":"<code>ParserConfig</code>","text":"<p>parser configuration</p> Source code in <code>ceurws/indexparser.py</code> <pre><code>class ParserConfig:\n    \"\"\"\n    parser configuration\n    \"\"\"\n\n    def __init__(\n        self,\n        progress_bar: tqdm | None = None,\n        down_to_volume: int = 1,\n        force_download: bool = False,\n        verbose: bool = False,\n        debug: bool = False,\n    ):\n        \"\"\"\n        Initializes the ParserConfig with a progress bar, volume threshold, and debug mode setting.\n\n        Args:\n            progress_bar : An instance of a Progressbar class to be used for showing progress\n                during parsing.\n            down_to_volume (int, optional): The volume threshold for parsing.\n                Only volumes equal to or less than this value will be considered. Defaults to 1.\n            force_download(bool): if True download the file to parse\n            verbose(bool): if True give verbose feedback\n            debug (bool, optional): Indicates whether debugging mode is enabled.\n                If True, additional debug information will be provided during parsing. Defaults to False.\n        \"\"\"\n        self.progress_bar = progress_bar\n        self.down_to_volume = down_to_volume\n        self.force_download = force_download\n        self.verbose = verbose\n        self.debug = debug\n</code></pre>"},{"location":"#ceurws.indexparser.ParserConfig.__init__","title":"<code>__init__(progress_bar=None, down_to_volume=1, force_download=False, verbose=False, debug=False)</code>","text":"<p>Initializes the ParserConfig with a progress bar, volume threshold, and debug mode setting.</p> <p>Parameters:</p> Name Type Description Default <code>progress_bar</code> <p>An instance of a Progressbar class to be used for showing progress during parsing.</p> <code>None</code> <code>down_to_volume</code> <code>int</code> <p>The volume threshold for parsing. Only volumes equal to or less than this value will be considered. Defaults to 1.</p> <code>1</code> <code>force_download(bool)</code> <p>if True download the file to parse</p> required <code>verbose(bool)</code> <p>if True give verbose feedback</p> required <code>debug</code> <code>bool</code> <p>Indicates whether debugging mode is enabled. If True, additional debug information will be provided during parsing. Defaults to False.</p> <code>False</code> Source code in <code>ceurws/indexparser.py</code> <pre><code>def __init__(\n    self,\n    progress_bar: tqdm | None = None,\n    down_to_volume: int = 1,\n    force_download: bool = False,\n    verbose: bool = False,\n    debug: bool = False,\n):\n    \"\"\"\n    Initializes the ParserConfig with a progress bar, volume threshold, and debug mode setting.\n\n    Args:\n        progress_bar : An instance of a Progressbar class to be used for showing progress\n            during parsing.\n        down_to_volume (int, optional): The volume threshold for parsing.\n            Only volumes equal to or less than this value will be considered. Defaults to 1.\n        force_download(bool): if True download the file to parse\n        verbose(bool): if True give verbose feedback\n        debug (bool, optional): Indicates whether debugging mode is enabled.\n            If True, additional debug information will be provided during parsing. Defaults to False.\n    \"\"\"\n    self.progress_bar = progress_bar\n    self.down_to_volume = down_to_volume\n    self.force_download = force_download\n    self.verbose = verbose\n    self.debug = debug\n</code></pre>"},{"location":"#ceurws.location","title":"<code>location</code>","text":"<p>Created on 2023-07-15</p> <p>@author: wf</p>"},{"location":"#ceurws.location.LocationLookup","title":"<code>LocationLookup</code>","text":"<p>Class for location lookup.</p> Source code in <code>ceurws/location.py</code> <pre><code>class LocationLookup:\n    \"\"\"\n    Class for location lookup.\n    \"\"\"\n\n    predefinedLocations: dict[str, str | None] = {}\n\n    @classmethod\n    def initPredefinedLocations(cls):\n        \"\"\"\n        Initialize predefined locations.\n        \"\"\"\n        locMap = {\n            \"Not Known\": None,\n            \"Online\": None,\n            \"Virtual\": None,\n            \"Virtual, USA\": None,\n            \"Virtual Event, USA\": None,\n            \"Amsterdam\": \"Q727\",\n            \"Amsterdam, Amsterdam\": \"Q727\",\n            \"Amsterdam Netherlands\": \"Q727\",\n            \"Amsterdam, Netherlands\": \"Q727\",\n            \"Amsterdam, The Netherlands\": \"Q727\",\n            \"Amsterdam The Netherlands\": \"Q727\",\n            # ... add more predefined locations ...\n        }\n        cls.predefinedLocations = locMap\n\n    def __init__(self):\n        \"\"\"\n        Constructor for LocationLookup.\n        \"\"\"\n        LocationLookup.initPredefinedLocations()\n        self.locationContext = LocationContext.fromCache()\n        cacheRootDir = LocationContext.getDefaultConfig().cacheRootDir\n        cacheDir = f\"{cacheRootDir}/.nominatim\"\n        self.nominatimWrapper = NominatimWrapper(cacheDir=cacheDir)\n\n    def getCityByWikiDataId(self, wikidataID: str):\n        \"\"\"\n        Get the city for the given wikidataID.\n\n        Args:\n            wikidataID (str): The wikidata ID.\n\n        Returns:\n            City: The city with the given wikidataID.\n        \"\"\"\n        citiesGen = self.locationContext.cityManager.getLocationsByWikidataId(wikidataID)\n        if citiesGen is not None:\n            cities = list(citiesGen)\n            if len(cities) &gt; 0:\n                return cities[0]\n        else:\n            return None\n\n    def lookupNominatim(self, locationText: str):\n        \"\"\"\n        Lookup the location for the given locationText (if any).\n\n        Args:\n            locationText (str): The location text to search for.\n\n        Returns:\n            City: The location found by Nominatim.\n        \"\"\"\n        location = None\n        wikidataId = self.nominatimWrapper.lookupWikiDataId(locationText)\n        if wikidataId is not None:\n            location = self.getCityByWikiDataId(wikidataId)\n        return location\n\n    def lookup(self, locationText: str, logFile=sys.stdout):\n        \"\"\"\n        Lookup a location based on the given locationText.\n\n        Args:\n            locationText (str): The location to lookup.\n            logFile (file): The log file to write the output.\n\n        Returns:\n            City: The located city based on the locationText.\n        \"\"\"\n        if locationText in LocationLookup.predefinedLocations:\n            locationId = LocationLookup.predefinedLocations[locationText]\n            if locationId is None:\n                return None\n            else:\n                location = self.getCityByWikiDataId(locationId)\n                if location is None:\n                    print(\n                        f\"\u274c\u274c-predefinedLocation {locationText}\u2192{locationId} wikidataId not resolved\",\n                        file=logFile,\n                    )\n                return location\n        lg = self.lookupGeograpy(locationText)\n        ln = self.lookupNominatim(locationText)\n        if ln is not None and lg is not None and ln.wikidataid != lg.wikidataid:\n            print(f\"\u274c\u274c{locationText}\u2192{lg}!={ln}\", file=logFile)\n            return None\n        return lg\n\n    def lookupGeograpy(self, locationText: str):\n        \"\"\"\n        Lookup the given location by the given locationText.\n\n        Args:\n            locationText (str): The location to lookup.\n\n        Returns:\n            City: The located city based on the locationText.\n        \"\"\"\n        locations = self.locationContext.locateLocation(locationText)\n        if len(locations) &gt; 0:\n            return locations[0]\n        else:\n            return None\n</code></pre>"},{"location":"#ceurws.location.LocationLookup.__init__","title":"<code>__init__()</code>","text":"<p>Constructor for LocationLookup.</p> Source code in <code>ceurws/location.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Constructor for LocationLookup.\n    \"\"\"\n    LocationLookup.initPredefinedLocations()\n    self.locationContext = LocationContext.fromCache()\n    cacheRootDir = LocationContext.getDefaultConfig().cacheRootDir\n    cacheDir = f\"{cacheRootDir}/.nominatim\"\n    self.nominatimWrapper = NominatimWrapper(cacheDir=cacheDir)\n</code></pre>"},{"location":"#ceurws.location.LocationLookup.getCityByWikiDataId","title":"<code>getCityByWikiDataId(wikidataID)</code>","text":"<p>Get the city for the given wikidataID.</p> <p>Parameters:</p> Name Type Description Default <code>wikidataID</code> <code>str</code> <p>The wikidata ID.</p> required <p>Returns:</p> Name Type Description <code>City</code> <p>The city with the given wikidataID.</p> Source code in <code>ceurws/location.py</code> <pre><code>def getCityByWikiDataId(self, wikidataID: str):\n    \"\"\"\n    Get the city for the given wikidataID.\n\n    Args:\n        wikidataID (str): The wikidata ID.\n\n    Returns:\n        City: The city with the given wikidataID.\n    \"\"\"\n    citiesGen = self.locationContext.cityManager.getLocationsByWikidataId(wikidataID)\n    if citiesGen is not None:\n        cities = list(citiesGen)\n        if len(cities) &gt; 0:\n            return cities[0]\n    else:\n        return None\n</code></pre>"},{"location":"#ceurws.location.LocationLookup.initPredefinedLocations","title":"<code>initPredefinedLocations()</code>  <code>classmethod</code>","text":"<p>Initialize predefined locations.</p> Source code in <code>ceurws/location.py</code> <pre><code>@classmethod\ndef initPredefinedLocations(cls):\n    \"\"\"\n    Initialize predefined locations.\n    \"\"\"\n    locMap = {\n        \"Not Known\": None,\n        \"Online\": None,\n        \"Virtual\": None,\n        \"Virtual, USA\": None,\n        \"Virtual Event, USA\": None,\n        \"Amsterdam\": \"Q727\",\n        \"Amsterdam, Amsterdam\": \"Q727\",\n        \"Amsterdam Netherlands\": \"Q727\",\n        \"Amsterdam, Netherlands\": \"Q727\",\n        \"Amsterdam, The Netherlands\": \"Q727\",\n        \"Amsterdam The Netherlands\": \"Q727\",\n        # ... add more predefined locations ...\n    }\n    cls.predefinedLocations = locMap\n</code></pre>"},{"location":"#ceurws.location.LocationLookup.lookup","title":"<code>lookup(locationText, logFile=sys.stdout)</code>","text":"<p>Lookup a location based on the given locationText.</p> <p>Parameters:</p> Name Type Description Default <code>locationText</code> <code>str</code> <p>The location to lookup.</p> required <code>logFile</code> <code>file</code> <p>The log file to write the output.</p> <code>stdout</code> <p>Returns:</p> Name Type Description <code>City</code> <p>The located city based on the locationText.</p> Source code in <code>ceurws/location.py</code> <pre><code>def lookup(self, locationText: str, logFile=sys.stdout):\n    \"\"\"\n    Lookup a location based on the given locationText.\n\n    Args:\n        locationText (str): The location to lookup.\n        logFile (file): The log file to write the output.\n\n    Returns:\n        City: The located city based on the locationText.\n    \"\"\"\n    if locationText in LocationLookup.predefinedLocations:\n        locationId = LocationLookup.predefinedLocations[locationText]\n        if locationId is None:\n            return None\n        else:\n            location = self.getCityByWikiDataId(locationId)\n            if location is None:\n                print(\n                    f\"\u274c\u274c-predefinedLocation {locationText}\u2192{locationId} wikidataId not resolved\",\n                    file=logFile,\n                )\n            return location\n    lg = self.lookupGeograpy(locationText)\n    ln = self.lookupNominatim(locationText)\n    if ln is not None and lg is not None and ln.wikidataid != lg.wikidataid:\n        print(f\"\u274c\u274c{locationText}\u2192{lg}!={ln}\", file=logFile)\n        return None\n    return lg\n</code></pre>"},{"location":"#ceurws.location.LocationLookup.lookupGeograpy","title":"<code>lookupGeograpy(locationText)</code>","text":"<p>Lookup the given location by the given locationText.</p> <p>Parameters:</p> Name Type Description Default <code>locationText</code> <code>str</code> <p>The location to lookup.</p> required <p>Returns:</p> Name Type Description <code>City</code> <p>The located city based on the locationText.</p> Source code in <code>ceurws/location.py</code> <pre><code>def lookupGeograpy(self, locationText: str):\n    \"\"\"\n    Lookup the given location by the given locationText.\n\n    Args:\n        locationText (str): The location to lookup.\n\n    Returns:\n        City: The located city based on the locationText.\n    \"\"\"\n    locations = self.locationContext.locateLocation(locationText)\n    if len(locations) &gt; 0:\n        return locations[0]\n    else:\n        return None\n</code></pre>"},{"location":"#ceurws.location.LocationLookup.lookupNominatim","title":"<code>lookupNominatim(locationText)</code>","text":"<p>Lookup the location for the given locationText (if any).</p> <p>Parameters:</p> Name Type Description Default <code>locationText</code> <code>str</code> <p>The location text to search for.</p> required <p>Returns:</p> Name Type Description <code>City</code> <p>The location found by Nominatim.</p> Source code in <code>ceurws/location.py</code> <pre><code>def lookupNominatim(self, locationText: str):\n    \"\"\"\n    Lookup the location for the given locationText (if any).\n\n    Args:\n        locationText (str): The location text to search for.\n\n    Returns:\n        City: The location found by Nominatim.\n    \"\"\"\n    location = None\n    wikidataId = self.nominatimWrapper.lookupWikiDataId(locationText)\n    if wikidataId is not None:\n        location = self.getCityByWikiDataId(wikidataId)\n    return location\n</code></pre>"},{"location":"#ceurws.loctime","title":"<code>loctime</code>","text":"<p>Created on 2023-12-22</p> <p>@author: wf</p>"},{"location":"#ceurws.loctime.LoctimeParser","title":"<code>LoctimeParser</code>","text":"<p>A parser class for handling loctime lookups. This class provides methods to load, parse, and update loctime data using a dictionary of dictionaries structure.</p> <p>Attributes:</p> Name Type Description <code>filepath</code> <code>str</code> <p>The file path to the loctime YAML configuration.</p> <code>lookups</code> <code>dict</code> <p>The loaded lookup dictionaries from the YAML file.</p> <code>multi_word</code> <code>dict</code> <p>A dictionary to handle multi-word keys.</p> <code>multi_word_lookups</code> <code>dict</code> <p>A version of lookups with keys as concatenated words.</p> <code>counters</code> <code>dict</code> <p>A dictionary of Counter objects for various categories.</p> <code>year_pattern</code> <code>Pattern</code> <p>A compiled regex pattern to match 4-digit years.</p> <code>total_loctimes</code> <code>int</code> <p>The total count of processed loctimes.</p> Source code in <code>ceurws/loctime.py</code> <pre><code>class LoctimeParser:\n    \"\"\"\n    A parser class for handling loctime lookups. This class provides methods to\n    load, parse, and update loctime data using a dictionary of dictionaries structure.\n\n    Attributes:\n        filepath (str): The file path to the loctime YAML configuration.\n        lookups (dict): The loaded lookup dictionaries from the YAML file.\n        multi_word (dict): A dictionary to handle multi-word keys.\n        multi_word_lookups (dict): A version of lookups with keys as concatenated words.\n        counters (dict): A dictionary of Counter objects for various categories.\n        year_pattern (re.Pattern): A compiled regex pattern to match 4-digit years.\n        total_loctimes (int): The total count of processed loctimes.\n    \"\"\"\n\n    def __init__(self, filepath: str | None = None):\n        \"\"\"\n        Initializes the LoctimeParser object, setting up paths, loading lookups,\n        and initializing counters and patterns.\n\n        Args:\n            filepath (Path, optional): The path to the loctime YAML file.\n                                      Defaults to a predefined path if None is provided.\n        Raises:\n            FileNotFoundError: Raises an error if the specified YAML file does not exist.\n        \"\"\"\n        if filepath is None:\n            self.ceurws_path = CEURWS.CACHE_DIR\n            self.filepath: Path = self.ceurws_path.joinpath(\"loctime.yaml\")\n        else:\n            self.file_path = Path(filepath)\n        self.lookups = self.load()\n        self.setup()\n        self.counters: dict[str, Counter] = {\"4digit-year\": Counter()}\n        for reverse_pos in range(1, 8):\n            self.counters[str(reverse_pos)] = Counter()\n        for key in self.lookups:\n            self.counters[key] = Counter()\n\n        # Compile a pattern to match a 4-digit year\n        self.year_pattern = re.compile(r\"\\b\\d{4}\\b\")\n        self.total_loctimes = 0\n\n    def setup(self):\n        \"\"\"\n        Prepares the parser by initializing multi-word handling and creating\n        a modified version of the lookup dictionaries with keys as concatenated words.\n        This method sets up the 'multi_word' and 'multi_word_lookups' dictionaries\n        to facilitate the parsing process, especially for multi-word keys.\n        \"\"\"\n        self.multi_word = {}\n        for lookup in self.lookups.values():\n            for key in lookup:\n                if \" \" in key:\n                    self.multi_word[key] = key.replace(\" \", \"_\")\n\n        # Initialize a dictionary derived from self.lookups with underscored keys\n        self.multi_word_lookups = {}\n        for category, lookup in self.lookups.items():\n            self.multi_word_lookups[category] = {key.replace(\" \", \"_\"): value for key, value in lookup.items()}\n\n    def load(\n        self,\n    ) -&gt; dict:\n        \"\"\"\n        Loads the lookup data from the YAML file specified by the filepath attribute.\n\n        This method attempts to open and read the YAML file, converting its contents\n        into a dictionary. If the file is empty or does not exist, it returns an empty dictionary.\n\n        Returns:\n            dict: A dictionary representing the loaded data from the YAML file. If the file\n                  is empty or non-existent, an empty dictionary is returned.\n\n        Raises:\n            FileNotFoundError: If the specified file does not exist.\n            yaml.YAMLError: If there is an error parsing the YAML file.\n        \"\"\"\n        data_dict = {}\n        if os.path.isfile(self.filepath) and os.path.getsize(self.filepath) &gt; 0:\n            with open(self.filepath) as yaml_file:\n                data_dict = yaml.safe_load(yaml_file)\n        return data_dict\n\n    def save(self):\n        \"\"\"\n        Saves the current lookup dictionary to a YAML file.\n        \"\"\"\n        os.makedirs(os.path.dirname(self.filepath), exist_ok=True)  # Ensure directory exists\n        with open(self.filepath, \"w\", encoding=\"utf-8\") as yaml_file:\n            yaml.dump(\n                self.lookups,\n                yaml_file,\n                default_flow_style=False,\n                allow_unicode=True,\n            )\n\n    def get_parts(self, loctime):\n        \"\"\"\n        Splits the loctime string into parts and subparts, considering multi-word entries.\n\n        Args:\n            loctime (str): The loctime string to split.\n\n        Returns:\n            list: A list of parts and subparts.\n        \"\"\"\n        # Replace known multi-word entries with their underscore versions\n        for original, underscored in self.multi_word.items():\n            loctime = loctime.replace(original, underscored)\n\n        parts = loctime.split(\",\")  # First, split by comma\n        all_parts = []\n        for part in parts:\n            # Further split each part by whitespace, considering underscore as part of the word\n            subparts = part.strip().split()\n            all_parts.extend(subparts)  # Add all subparts to the list\n\n        return all_parts\n\n    def parse(self, loctime: str) -&gt; dict:\n        \"\"\"\n        Alternative parse of CEUR-WS loctimes using lookups\n\n        Args:\n            loctime (str): The loctime string to parse.\n\n        \"\"\"\n        result = {}\n        self.total_loctimes += 1\n        lt_parts = self.get_parts(loctime)\n\n        # Process each part of loctime\n        for index, part in enumerate(lt_parts):\n            part = part.strip()\n            reverse_pos = len(lt_parts) - index  # Position from end\n\n            found_in_lookup = False\n            # Check against each lookup and update corresponding counter\n            for (\n                lookup_key,\n                lookup_dict,\n            ) in self.multi_word_lookups.items():\n                if part in lookup_dict:\n                    self.counters[lookup_key][part] += 1  # Increment the lookup counter\n                    found_in_lookup = True\n                    # set result dict\n                    result[lookup_key] = part\n                    break  # Break if found, assuming part can't be in multiple lookups\n            if not found_in_lookup:\n                # Update counter for each part's position from end\n                key = str(reverse_pos)\n                if key in self.counters:\n                    self.counters[key][part] += 1\n\n            # Special handling for 4-digit years\n            if index == len(lt_parts) - 1 and self.year_pattern.match(part):\n                self.counters[\"4digit-year\"][part] += 1\n        return result\n\n    def update_lookup_counts(self):\n        \"\"\"\n        to be called  ffter processing all loctimes\n        and updating counters update lookup dicts with new counts\n        \"\"\"\n        for category, counter in self.counters.items():\n            if category in self.lookups:\n                for underscore_key, count in counter.items():\n                    # Convert underscore_key back to space-separated key\n                    original_key = underscore_key.replace(\"_\", \" \")\n                    if original_key in self.lookups[category]:\n                        # Update the count for the original key\n                        self.lookups[category][original_key] += count\n                    else:\n                        # Initialize count for the original key\n                        self.lookups[category][original_key] = count\n\n    def create_pareto_analysis(self, level: int = 3, outof: int = 5):\n        \"\"\"\n        Creates a Pareto analysis for each category in the lookups and returns\n        the percentage table for the distribution across the specified levels.\n\n        Args:\n            level (int): The number of segments to divide the data into within the top \"outof\" parts.\n            outof (int): 1 out of n value e.g. on level 1 we have 1:5 which leads to\n                the original pareto 80:20 percent rule, on level 2 we have 80:(20=16:4) percent\n                which is equivalent to 80/96 thresholds percent on level 3 we have 80:(20=16:4=(3.2:0.8)\n                percent which leads to 80%,96%,99.2% thresholds\n        \"\"\"\n        pareto_dict = {}\n        for category, counter in self.counters.items():\n            # Sort items by count in descending order\n            sorted_items = counter.most_common()\n            total = sum(counter.values())\n\n            # Calculate segment thresholds based on the diminishing series\n            thresholds = []\n            threshold = 0.0\n            for _ in range(1, level + 1):\n                # current range to calculate out of for\n                trange = 100 - threshold  # 100/80/96/99.2 ...\n                # right side of range\n                right_range = trange / outof  # 20/4/0.8 ...\n                # left threshold is new threshold\n                threshold = 100 - right_range\n                thresholds.append(threshold)\n            thresholds.append(100)\n\n            segment_counts = {threshold: 0 for threshold in thresholds}  # Initialize count dict for each segment\n            segment_cutoff = {threshold: 0 for threshold in thresholds}  # Initialize count dict for each segment\n            tindex = 0\n            current_threshold = thresholds[tindex]\n            total_pc = 0.0\n            # Calculate cumulative counts for each segment\n            for _, count in sorted_items:\n                item_percentage = count / total * 100\n                if total_pc + item_percentage &gt; current_threshold + 0.000000000001:\n                    segment_cutoff[current_threshold] = count\n                    tindex += 1\n                    if tindex &gt;= len(thresholds):\n                        break\n                    current_threshold = thresholds[tindex]\n                total_pc += item_percentage\n                segment_counts[current_threshold] += count\n\n            pareto_dict[category] = segment_cutoff\n        return pareto_dict\n</code></pre>"},{"location":"#ceurws.loctime.LoctimeParser.__init__","title":"<code>__init__(filepath=None)</code>","text":"<p>Initializes the LoctimeParser object, setting up paths, loading lookups, and initializing counters and patterns.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>The path to the loctime YAML file.                       Defaults to a predefined path if None is provided.</p> <code>None</code> <p>Raises:     FileNotFoundError: Raises an error if the specified YAML file does not exist.</p> Source code in <code>ceurws/loctime.py</code> <pre><code>def __init__(self, filepath: str | None = None):\n    \"\"\"\n    Initializes the LoctimeParser object, setting up paths, loading lookups,\n    and initializing counters and patterns.\n\n    Args:\n        filepath (Path, optional): The path to the loctime YAML file.\n                                  Defaults to a predefined path if None is provided.\n    Raises:\n        FileNotFoundError: Raises an error if the specified YAML file does not exist.\n    \"\"\"\n    if filepath is None:\n        self.ceurws_path = CEURWS.CACHE_DIR\n        self.filepath: Path = self.ceurws_path.joinpath(\"loctime.yaml\")\n    else:\n        self.file_path = Path(filepath)\n    self.lookups = self.load()\n    self.setup()\n    self.counters: dict[str, Counter] = {\"4digit-year\": Counter()}\n    for reverse_pos in range(1, 8):\n        self.counters[str(reverse_pos)] = Counter()\n    for key in self.lookups:\n        self.counters[key] = Counter()\n\n    # Compile a pattern to match a 4-digit year\n    self.year_pattern = re.compile(r\"\\b\\d{4}\\b\")\n    self.total_loctimes = 0\n</code></pre>"},{"location":"#ceurws.loctime.LoctimeParser.create_pareto_analysis","title":"<code>create_pareto_analysis(level=3, outof=5)</code>","text":"<p>Creates a Pareto analysis for each category in the lookups and returns the percentage table for the distribution across the specified levels.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int</code> <p>The number of segments to divide the data into within the top \"outof\" parts.</p> <code>3</code> <code>outof</code> <code>int</code> <p>1 out of n value e.g. on level 1 we have 1:5 which leads to the original pareto 80:20 percent rule, on level 2 we have 80:(20=16:4) percent which is equivalent to 80/96 thresholds percent on level 3 we have 80:(20=16:4=(3.2:0.8) percent which leads to 80%,96%,99.2% thresholds</p> <code>5</code> Source code in <code>ceurws/loctime.py</code> <pre><code>def create_pareto_analysis(self, level: int = 3, outof: int = 5):\n    \"\"\"\n    Creates a Pareto analysis for each category in the lookups and returns\n    the percentage table for the distribution across the specified levels.\n\n    Args:\n        level (int): The number of segments to divide the data into within the top \"outof\" parts.\n        outof (int): 1 out of n value e.g. on level 1 we have 1:5 which leads to\n            the original pareto 80:20 percent rule, on level 2 we have 80:(20=16:4) percent\n            which is equivalent to 80/96 thresholds percent on level 3 we have 80:(20=16:4=(3.2:0.8)\n            percent which leads to 80%,96%,99.2% thresholds\n    \"\"\"\n    pareto_dict = {}\n    for category, counter in self.counters.items():\n        # Sort items by count in descending order\n        sorted_items = counter.most_common()\n        total = sum(counter.values())\n\n        # Calculate segment thresholds based on the diminishing series\n        thresholds = []\n        threshold = 0.0\n        for _ in range(1, level + 1):\n            # current range to calculate out of for\n            trange = 100 - threshold  # 100/80/96/99.2 ...\n            # right side of range\n            right_range = trange / outof  # 20/4/0.8 ...\n            # left threshold is new threshold\n            threshold = 100 - right_range\n            thresholds.append(threshold)\n        thresholds.append(100)\n\n        segment_counts = {threshold: 0 for threshold in thresholds}  # Initialize count dict for each segment\n        segment_cutoff = {threshold: 0 for threshold in thresholds}  # Initialize count dict for each segment\n        tindex = 0\n        current_threshold = thresholds[tindex]\n        total_pc = 0.0\n        # Calculate cumulative counts for each segment\n        for _, count in sorted_items:\n            item_percentage = count / total * 100\n            if total_pc + item_percentage &gt; current_threshold + 0.000000000001:\n                segment_cutoff[current_threshold] = count\n                tindex += 1\n                if tindex &gt;= len(thresholds):\n                    break\n                current_threshold = thresholds[tindex]\n            total_pc += item_percentage\n            segment_counts[current_threshold] += count\n\n        pareto_dict[category] = segment_cutoff\n    return pareto_dict\n</code></pre>"},{"location":"#ceurws.loctime.LoctimeParser.get_parts","title":"<code>get_parts(loctime)</code>","text":"<p>Splits the loctime string into parts and subparts, considering multi-word entries.</p> <p>Parameters:</p> Name Type Description Default <code>loctime</code> <code>str</code> <p>The loctime string to split.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list of parts and subparts.</p> Source code in <code>ceurws/loctime.py</code> <pre><code>def get_parts(self, loctime):\n    \"\"\"\n    Splits the loctime string into parts and subparts, considering multi-word entries.\n\n    Args:\n        loctime (str): The loctime string to split.\n\n    Returns:\n        list: A list of parts and subparts.\n    \"\"\"\n    # Replace known multi-word entries with their underscore versions\n    for original, underscored in self.multi_word.items():\n        loctime = loctime.replace(original, underscored)\n\n    parts = loctime.split(\",\")  # First, split by comma\n    all_parts = []\n    for part in parts:\n        # Further split each part by whitespace, considering underscore as part of the word\n        subparts = part.strip().split()\n        all_parts.extend(subparts)  # Add all subparts to the list\n\n    return all_parts\n</code></pre>"},{"location":"#ceurws.loctime.LoctimeParser.load","title":"<code>load()</code>","text":"<p>Loads the lookup data from the YAML file specified by the filepath attribute.</p> <p>This method attempts to open and read the YAML file, converting its contents into a dictionary. If the file is empty or does not exist, it returns an empty dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representing the loaded data from the YAML file. If the file   is empty or non-existent, an empty dictionary is returned.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified file does not exist.</p> <code>YAMLError</code> <p>If there is an error parsing the YAML file.</p> Source code in <code>ceurws/loctime.py</code> <pre><code>def load(\n    self,\n) -&gt; dict:\n    \"\"\"\n    Loads the lookup data from the YAML file specified by the filepath attribute.\n\n    This method attempts to open and read the YAML file, converting its contents\n    into a dictionary. If the file is empty or does not exist, it returns an empty dictionary.\n\n    Returns:\n        dict: A dictionary representing the loaded data from the YAML file. If the file\n              is empty or non-existent, an empty dictionary is returned.\n\n    Raises:\n        FileNotFoundError: If the specified file does not exist.\n        yaml.YAMLError: If there is an error parsing the YAML file.\n    \"\"\"\n    data_dict = {}\n    if os.path.isfile(self.filepath) and os.path.getsize(self.filepath) &gt; 0:\n        with open(self.filepath) as yaml_file:\n            data_dict = yaml.safe_load(yaml_file)\n    return data_dict\n</code></pre>"},{"location":"#ceurws.loctime.LoctimeParser.parse","title":"<code>parse(loctime)</code>","text":"<p>Alternative parse of CEUR-WS loctimes using lookups</p> <p>Parameters:</p> Name Type Description Default <code>loctime</code> <code>str</code> <p>The loctime string to parse.</p> required Source code in <code>ceurws/loctime.py</code> <pre><code>def parse(self, loctime: str) -&gt; dict:\n    \"\"\"\n    Alternative parse of CEUR-WS loctimes using lookups\n\n    Args:\n        loctime (str): The loctime string to parse.\n\n    \"\"\"\n    result = {}\n    self.total_loctimes += 1\n    lt_parts = self.get_parts(loctime)\n\n    # Process each part of loctime\n    for index, part in enumerate(lt_parts):\n        part = part.strip()\n        reverse_pos = len(lt_parts) - index  # Position from end\n\n        found_in_lookup = False\n        # Check against each lookup and update corresponding counter\n        for (\n            lookup_key,\n            lookup_dict,\n        ) in self.multi_word_lookups.items():\n            if part in lookup_dict:\n                self.counters[lookup_key][part] += 1  # Increment the lookup counter\n                found_in_lookup = True\n                # set result dict\n                result[lookup_key] = part\n                break  # Break if found, assuming part can't be in multiple lookups\n        if not found_in_lookup:\n            # Update counter for each part's position from end\n            key = str(reverse_pos)\n            if key in self.counters:\n                self.counters[key][part] += 1\n\n        # Special handling for 4-digit years\n        if index == len(lt_parts) - 1 and self.year_pattern.match(part):\n            self.counters[\"4digit-year\"][part] += 1\n    return result\n</code></pre>"},{"location":"#ceurws.loctime.LoctimeParser.save","title":"<code>save()</code>","text":"<p>Saves the current lookup dictionary to a YAML file.</p> Source code in <code>ceurws/loctime.py</code> <pre><code>def save(self):\n    \"\"\"\n    Saves the current lookup dictionary to a YAML file.\n    \"\"\"\n    os.makedirs(os.path.dirname(self.filepath), exist_ok=True)  # Ensure directory exists\n    with open(self.filepath, \"w\", encoding=\"utf-8\") as yaml_file:\n        yaml.dump(\n            self.lookups,\n            yaml_file,\n            default_flow_style=False,\n            allow_unicode=True,\n        )\n</code></pre>"},{"location":"#ceurws.loctime.LoctimeParser.setup","title":"<code>setup()</code>","text":"<p>Prepares the parser by initializing multi-word handling and creating a modified version of the lookup dictionaries with keys as concatenated words. This method sets up the 'multi_word' and 'multi_word_lookups' dictionaries to facilitate the parsing process, especially for multi-word keys.</p> Source code in <code>ceurws/loctime.py</code> <pre><code>def setup(self):\n    \"\"\"\n    Prepares the parser by initializing multi-word handling and creating\n    a modified version of the lookup dictionaries with keys as concatenated words.\n    This method sets up the 'multi_word' and 'multi_word_lookups' dictionaries\n    to facilitate the parsing process, especially for multi-word keys.\n    \"\"\"\n    self.multi_word = {}\n    for lookup in self.lookups.values():\n        for key in lookup:\n            if \" \" in key:\n                self.multi_word[key] = key.replace(\" \", \"_\")\n\n    # Initialize a dictionary derived from self.lookups with underscored keys\n    self.multi_word_lookups = {}\n    for category, lookup in self.lookups.items():\n        self.multi_word_lookups[category] = {key.replace(\" \", \"_\"): value for key, value in lookup.items()}\n</code></pre>"},{"location":"#ceurws.loctime.LoctimeParser.update_lookup_counts","title":"<code>update_lookup_counts()</code>","text":"<p>to be called  ffter processing all loctimes and updating counters update lookup dicts with new counts</p> Source code in <code>ceurws/loctime.py</code> <pre><code>def update_lookup_counts(self):\n    \"\"\"\n    to be called  ffter processing all loctimes\n    and updating counters update lookup dicts with new counts\n    \"\"\"\n    for category, counter in self.counters.items():\n        if category in self.lookups:\n            for underscore_key, count in counter.items():\n                # Convert underscore_key back to space-separated key\n                original_key = underscore_key.replace(\"_\", \" \")\n                if original_key in self.lookups[category]:\n                    # Update the count for the original key\n                    self.lookups[category][original_key] += count\n                else:\n                    # Initialize count for the original key\n                    self.lookups[category][original_key] = count\n</code></pre>"},{"location":"#ceurws.loctime.PercentageTable","title":"<code>PercentageTable</code>","text":"<p>A class for creating a table that displays values and their corresponding percentages of a total.</p> <p>Attributes:</p> Name Type Description <code>total</code> <code>float</code> <p>The total value used for calculating percentages.</p> <code>column_title</code> <code>str</code> <p>The title for the first column in the table.</p> <code>digits</code> <code>int</code> <p>The number of decimal places for rounding percentages.</p> <code>rows</code> <code>list</code> <p>A list of dictionaries representing rows in the table.</p> Source code in <code>ceurws/loctime.py</code> <pre><code>class PercentageTable:\n    \"\"\"\n    A class for creating a table that displays values and their corresponding percentages of a total.\n\n    Attributes:\n        total (float): The total value used for calculating percentages.\n        column_title (str): The title for the first column in the table.\n        digits (int): The number of decimal places for rounding percentages.\n        rows (list): A list of dictionaries representing rows in the table.\n    \"\"\"\n\n    def __init__(self, column_title: str, total: float, digits: int):\n        \"\"\"\n        Initializes the PercentageTable with a title for the column,\n        a total value, and specified precision for percentages.\n\n        Args:\n            column_title (str): The title for the first column.\n            total (float): The total value for calculating percentages.\n            digits (int): The precision for percentage values.\n        \"\"\"\n        self.total = total\n        self.column_title = column_title\n        self.digits = digits\n        self.rows = [{self.column_title: \"Total\", \"#\": total, \"%\": 100.0}]\n\n    def add_value(self, row_title: str, value: float):\n        \"\"\"\n        Adds a row to the table with the given title and value, calculating the percentage of the total.\n\n        Args:\n            row_title (str): The title for the row.\n            value (float): The value for the row, which is used to calculate its percentage of the total.\n        \"\"\"\n        percentage = round((value / self.total) * 100, self.digits) if self.total else 0\n        self.rows.append({self.column_title: row_title, \"#\": value, \"%\": percentage})\n\n    def generate_table(self, tablefmt=\"grid\") -&gt; str:\n        \"\"\"\n        Generates a string representation of the table using the tabulate library.\n\n        Returns:\n            str: The string representation of the table with headers and formatted rows.\n        \"\"\"\n        if not self.rows:\n            return \"\"\n        tabulate_markup = tabulate(\n            self.rows,\n            headers=\"keys\",\n            tablefmt=tablefmt,\n            floatfmt=f\".{self.digits}f\",\n        )\n        return tabulate_markup\n</code></pre>"},{"location":"#ceurws.loctime.PercentageTable.__init__","title":"<code>__init__(column_title, total, digits)</code>","text":"<p>Initializes the PercentageTable with a title for the column, a total value, and specified precision for percentages.</p> <p>Parameters:</p> Name Type Description Default <code>column_title</code> <code>str</code> <p>The title for the first column.</p> required <code>total</code> <code>float</code> <p>The total value for calculating percentages.</p> required <code>digits</code> <code>int</code> <p>The precision for percentage values.</p> required Source code in <code>ceurws/loctime.py</code> <pre><code>def __init__(self, column_title: str, total: float, digits: int):\n    \"\"\"\n    Initializes the PercentageTable with a title for the column,\n    a total value, and specified precision for percentages.\n\n    Args:\n        column_title (str): The title for the first column.\n        total (float): The total value for calculating percentages.\n        digits (int): The precision for percentage values.\n    \"\"\"\n    self.total = total\n    self.column_title = column_title\n    self.digits = digits\n    self.rows = [{self.column_title: \"Total\", \"#\": total, \"%\": 100.0}]\n</code></pre>"},{"location":"#ceurws.loctime.PercentageTable.add_value","title":"<code>add_value(row_title, value)</code>","text":"<p>Adds a row to the table with the given title and value, calculating the percentage of the total.</p> <p>Parameters:</p> Name Type Description Default <code>row_title</code> <code>str</code> <p>The title for the row.</p> required <code>value</code> <code>float</code> <p>The value for the row, which is used to calculate its percentage of the total.</p> required Source code in <code>ceurws/loctime.py</code> <pre><code>def add_value(self, row_title: str, value: float):\n    \"\"\"\n    Adds a row to the table with the given title and value, calculating the percentage of the total.\n\n    Args:\n        row_title (str): The title for the row.\n        value (float): The value for the row, which is used to calculate its percentage of the total.\n    \"\"\"\n    percentage = round((value / self.total) * 100, self.digits) if self.total else 0\n    self.rows.append({self.column_title: row_title, \"#\": value, \"%\": percentage})\n</code></pre>"},{"location":"#ceurws.loctime.PercentageTable.generate_table","title":"<code>generate_table(tablefmt='grid')</code>","text":"<p>Generates a string representation of the table using the tabulate library.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The string representation of the table with headers and formatted rows.</p> Source code in <code>ceurws/loctime.py</code> <pre><code>def generate_table(self, tablefmt=\"grid\") -&gt; str:\n    \"\"\"\n    Generates a string representation of the table using the tabulate library.\n\n    Returns:\n        str: The string representation of the table with headers and formatted rows.\n    \"\"\"\n    if not self.rows:\n        return \"\"\n    tabulate_markup = tabulate(\n        self.rows,\n        headers=\"keys\",\n        tablefmt=tablefmt,\n        floatfmt=f\".{self.digits}f\",\n    )\n    return tabulate_markup\n</code></pre>"},{"location":"#ceurws.models","title":"<code>models</code>","text":""},{"location":"#ceurws.models.ceur","title":"<code>ceur</code>","text":"<p>Created on 2024-03-17</p> <p>CEUR Workshop Proceedings (CEUR-WS.org)</p> <p>Metamodel @author: wf</p>"},{"location":"#ceurws.models.ceur.Paper","title":"<code>Paper</code>","text":"<p>               Bases: <code>SQLModel</code></p> <p>Represents a paper with details such as authors, volume number, and title.</p> Source code in <code>ceurws/models/ceur.py</code> <pre><code>class Paper(SQLModel, table=True):  # type: ignore\n    \"\"\"\n    Represents a paper with details such as authors, volume number, and title.\n    \"\"\"\n\n    __tablename__ = \"papers\"\n    authors: str | None = Field(default=None, index=False)\n    vol_number: int | None = Field(default=None, index=True)\n    pdf_name: str | None = Field(default=None, index=False)\n    id: str = Field(primary_key=True)\n    title: str | None = Field(default=None, index=False)\n    pages: str | None = Field(default=None, index=False)\n    fail: str | None = Field(default=None, index=False)\n</code></pre>"},{"location":"#ceurws.models.ceur.Volume","title":"<code>Volume</code>","text":"<p>               Bases: <code>SQLModel</code></p> <p>a single CEUR-WS Volume</p> Source code in <code>ceurws/models/ceur.py</code> <pre><code>class Volume(SQLModel, table=True):  # type: ignore\n    \"\"\"\n    a single CEUR-WS Volume\n    \"\"\"\n\n    __tablename__ = \"volumes\"\n\n    fromLine: int | None = Field(default=None)\n    toLine: int | None = Field(default=None)\n    valid: int | None = Field(default=None)\n    url: str | None = Field(default=None)\n    acronym: str | None = Field(default=None)\n    title: str | None = Field(default=None)\n    seealso: str | None = Field(default=None)\n    editors: str | None = Field(default=None)\n    submittedBy: str | None = Field(default=None)\n    published: str | None = Field(default=None)\n    pubDate: datetime | None = Field(default=None)\n    number: int = Field(primary_key=True)\n    archive: str | None = Field(default=None)\n    desc: str | None = Field(alias=\"description\", default=None)  # 'desc' is a SQL keyword, so it's aliased\n    h1: str | None = Field(default=None)\n    h3: str | None = Field(default=None)\n    volname: str | None = Field(default=None)\n    homepage: str | None = Field(default=None)\n    year: str | None = Field(default=None)\n    urn: str | None = Field(default=None)\n    # vol_number: Optional[int] = Field(default=None)\n    loctime: str | None = Field(default=None)\n    volume_number: str | None = Field(default=None)\n    voltitle: str | None = Field(default=None)\n    dateFrom: date | None = Field(default=None)\n    dateTo: date | None = Field(default=None)\n    city: str | None = Field(default=None)\n    cityWikidataId: str | None = Field(default=None)\n    country: str | None = Field(default=None)\n    countryWikidataId: str | None = Field(default=None)\n    urn_check_digit: int | None = Field(default=None)\n    urn_ok: int | None = Field(default=None)\n    ceurpubdate: str | None = Field(default=None)\n    colocated: str | None = Field(default=None)\n    virtualEvent: int | None = Field(default=None)\n    tdtitle: str | None = Field(default=None)\n</code></pre>"},{"location":"#ceurws.models.dblp","title":"<code>dblp</code>","text":"<p>Created on 2023 @author: Tim Holzheim</p> <p>refactored 2024-03-09 by wf</p>"},{"location":"#ceurws.models.dblp.DblpPaper","title":"<code>DblpPaper</code>","text":"<p>a paper indexed by dblp.org</p> Source code in <code>ceurws/models/dblp.py</code> <pre><code>@lod_storable\nclass DblpPaper:\n    \"\"\"\n    a paper indexed by dblp.org\n    \"\"\"\n\n    dblp_publication_id: str\n    dblp_proceeding_id: str\n    volume_number: int\n    title: str\n    authors: list[DblpScholar] | None = field(default_factory=list)\n    pdf_id: str | None = None\n\n    def __post_init__(self):\n        for i, author in enumerate(self.authors):\n            if isinstance(author, dict):\n                self.authors[i] = DblpScholar(**author)\n</code></pre>"},{"location":"#ceurws.models.dblp.DblpProceeding","title":"<code>DblpProceeding</code>","text":"<p>a proceeding indexed by dblp.org</p> Source code in <code>ceurws/models/dblp.py</code> <pre><code>@lod_storable\nclass DblpProceeding:\n    \"\"\"\n    a proceeding indexed by dblp.org\n    \"\"\"\n\n    dblp_publication_id: str\n    volume_number: int\n    title: str\n    dblp_event_id: str | None = None\n    papers: list[DblpPaper] | None = field(default_factory=list)\n    editors: list[DblpScholar] | None = field(default_factory=list)\n\n    def __post_init__(self):\n        if self.editors:\n            for i, editor in enumerate(self.editors):\n                if isinstance(editor, dict):\n                    self.editors[i] = DblpScholar(**editor)\n        if self.papers:\n            for i, paper in enumerate(self.papers):\n                if isinstance(paper, dict):\n                    self.papers[i] = DblpPaper(**paper)\n</code></pre>"},{"location":"#ceurws.models.dblp.DblpScholar","title":"<code>DblpScholar</code>","text":"<p>a scholar indexed by dblp.org</p> <p>example: Tim Berners-Lee https://dblp.org/pid/b/TimBernersLee.html</p> Source code in <code>ceurws/models/dblp.py</code> <pre><code>@lod_storable\nclass DblpScholar:\n    \"\"\"\n    a scholar indexed by dblp.org\n\n    example: Tim Berners-Lee\n    https://dblp.org/pid/b/TimBernersLee.html\n\n    \"\"\"\n\n    dblp_author_id: str\n    label: str | None = None\n    wikidata_id: str | None = None\n    orcid_id: str | None = None\n    gnd_id: str | None = None\n</code></pre>"},{"location":"#ceurws.models.dblp2","title":"<code>dblp2</code>","text":"<p>Created on 2024-03-16</p> <p>@author: wf</p>"},{"location":"#ceurws.models.dblp2.Authorship","title":"<code>Authorship</code>","text":"<p>               Bases: <code>SQLModel</code></p> <p>Represents the relationship between a scholar and a paper, capturing the authorship details.</p> Source code in <code>ceurws/models/dblp2.py</code> <pre><code>class Authorship(SQLModel, table=True):  # type: ignore\n    \"\"\"\n    Represents the relationship between a scholar and a paper, capturing the authorship details.\n    \"\"\"\n\n    paper: str = Field(foreign_key=\"paper.paper\", primary_key=True)\n    dblp_author_id: str = Field(foreign_key=\"scholar.dblp_author_id\", primary_key=True)\n</code></pre>"},{"location":"#ceurws.models.dblp2.Editorship","title":"<code>Editorship</code>","text":"<p>               Bases: <code>SQLModel</code></p> <p>Represents the relationship between a scholar and a proceeding, indicating the scholar's role as an editor.</p> Source code in <code>ceurws/models/dblp2.py</code> <pre><code>class Editorship(SQLModel, table=True):  # type: ignore\n    \"\"\"\n    Represents the relationship between a scholar and a proceeding, indicating the scholar's role as an editor.\n    \"\"\"\n\n    volume_number: int = Field(foreign_key=\"proceeding.volume_number\", primary_key=True)\n    dblp_author_id: str = Field(foreign_key=\"scholar.dblp_author_id\", primary_key=True)\n</code></pre>"},{"location":"#ceurws.models.dblp2.Paper","title":"<code>Paper</code>","text":"<p>               Bases: <code>SQLModel</code></p> <p>A paper indexed in DBLP with additional details. The paper URL is used as the unique identifier.</p> Source code in <code>ceurws/models/dblp2.py</code> <pre><code>class Paper(SQLModel, table=True):  # type: ignore\n    \"\"\"\n    A paper indexed in DBLP with additional details. The paper URL is used as the unique identifier.\n    \"\"\"\n\n    paper: str = Field(primary_key=True)\n    proceeding: str | None = Field(foreign_key=\"proceeding.proceeding\")\n    volume_number: str = Field(index=True)\n    title: str\n    pdf_url: str | None = None\n</code></pre>"},{"location":"#ceurws.models.dblp2.Proceeding","title":"<code>Proceeding</code>","text":"<p>               Bases: <code>SQLModel</code></p> <p>A proceeding indexed in DBLP with additional details.</p> Source code in <code>ceurws/models/dblp2.py</code> <pre><code>class Proceeding(SQLModel, table=True):  # type: ignore\n    \"\"\"\n    A proceeding indexed in DBLP with additional details.\n    \"\"\"\n\n    proceeding: str = Field(primary_key=True)\n    volume_number: int = Field(index=True)\n    title: str\n    dblp_event_id: str | None = None\n</code></pre>"},{"location":"#ceurws.models.dblp2.Scholar","title":"<code>Scholar</code>","text":"<p>               Bases: <code>SQLModel</code></p> <p>Represents a scholar with information fetched from DBLP and possibly other sources.</p> Source code in <code>ceurws/models/dblp2.py</code> <pre><code>class Scholar(SQLModel, table=True):  # type: ignore\n    \"\"\"\n    Represents a scholar with information fetched from DBLP and possibly other sources.\n    \"\"\"\n\n    dblp_author_id: str = Field(primary_key=True)\n    label: str | None = None\n    wikidata_id: str | None = None\n    orcid_id: str | None = None\n    gnd_id: str | None = None\n</code></pre>"},{"location":"#ceurws.namedqueries","title":"<code>namedqueries</code>","text":"<p>Created on 2023-03-21</p> <p>@author: wf</p>"},{"location":"#ceurws.namedqueries.NamedQueries","title":"<code>NamedQueries</code>","text":"<p>get named queries</p> Source code in <code>ceurws/namedqueries.py</code> <pre><code>class NamedQueries:\n    \"\"\"\n    get named queries\n    \"\"\"\n\n    def __init__(self, wikiId: str = \"cr\"):\n        \"\"\" \"\"\"\n        self.wikiId = wikiId\n        self.wikiClient = WikiClient.ofWikiId(wikiId)\n        if self.wikiClient.needsLogin():\n            self.wikiClient.login()\n        self.smw = SMWClient(self.wikiClient.getSite())\n        self.qm: QueryManager | None = None\n\n    def query(self):\n        \"\"\"\n        run query\n        \"\"\"\n        ask_query = \"\"\"\n        {{#ask: [[Concept:Query]]\n|mainlabel=Query\n|?Query id = id\n|?Query name=name\n|?Query title = title\n|?Query tryiturl = tryiturl\n|?Query wdqsurl = wdqsurl\n|?Query sparql=sparql\n|?Query relevance = relevance\n|?Query task = task\n|limit=200\n|sort=Query task,Query id\n|order=ascending\n}}\"\"\"\n        self.q_records = self.smw.query(ask_query)\n\n    def toQueryManager(self) -&gt; QueryManager:\n        \"\"\"\n        convert me to a QueryManager\n        \"\"\"\n        self.qm = QueryManager(lang=\"sparql\")\n        self.qm.queriesByName = {}\n        for q_record in self.q_records.values():\n            name = q_record[\"name\"]\n            sparql = q_record[\"sparql\"]\n            if name and sparql:\n                query = Query(name, query=sparql)\n                self.qm.queriesByName[name] = query\n        return self.qm\n\n    def toYaml(self) -&gt; str:\n        if self.qm is None:\n            self.query()\n            qm = self.toQueryManager()\n        else:\n            qm = self.qm\n        yaml_str = \"# named queries\\n\"\n        for query in qm.queriesByName.values():\n            yaml_str += f\"\"\"'{query.name}':\n    sparql: |\n\"\"\"\n            for line in query.query.split(\"\\n\"):\n                yaml_str += f\"      {line}\\n\"\n        return yaml_str\n</code></pre>"},{"location":"#ceurws.namedqueries.NamedQueries.__init__","title":"<code>__init__(wikiId='cr')</code>","text":"Source code in <code>ceurws/namedqueries.py</code> <pre><code>def __init__(self, wikiId: str = \"cr\"):\n    \"\"\" \"\"\"\n    self.wikiId = wikiId\n    self.wikiClient = WikiClient.ofWikiId(wikiId)\n    if self.wikiClient.needsLogin():\n        self.wikiClient.login()\n    self.smw = SMWClient(self.wikiClient.getSite())\n    self.qm: QueryManager | None = None\n</code></pre>"},{"location":"#ceurws.namedqueries.NamedQueries.query","title":"<code>query()</code>","text":"<p>run query</p> Source code in <code>ceurws/namedqueries.py</code> <pre><code>    def query(self):\n        \"\"\"\n        run query\n        \"\"\"\n        ask_query = \"\"\"\n        {{#ask: [[Concept:Query]]\n|mainlabel=Query\n|?Query id = id\n|?Query name=name\n|?Query title = title\n|?Query tryiturl = tryiturl\n|?Query wdqsurl = wdqsurl\n|?Query sparql=sparql\n|?Query relevance = relevance\n|?Query task = task\n|limit=200\n|sort=Query task,Query id\n|order=ascending\n}}\"\"\"\n        self.q_records = self.smw.query(ask_query)\n</code></pre>"},{"location":"#ceurws.namedqueries.NamedQueries.toQueryManager","title":"<code>toQueryManager()</code>","text":"<p>convert me to a QueryManager</p> Source code in <code>ceurws/namedqueries.py</code> <pre><code>def toQueryManager(self) -&gt; QueryManager:\n    \"\"\"\n    convert me to a QueryManager\n    \"\"\"\n    self.qm = QueryManager(lang=\"sparql\")\n    self.qm.queriesByName = {}\n    for q_record in self.q_records.values():\n        name = q_record[\"name\"]\n        sparql = q_record[\"sparql\"]\n        if name and sparql:\n            query = Query(name, query=sparql)\n            self.qm.queriesByName[name] = query\n    return self.qm\n</code></pre>"},{"location":"#ceurws.papertocparser","title":"<code>papertocparser</code>","text":"<p>Created on 2023-03-22</p> <p>@author: wf</p>"},{"location":"#ceurws.papertocparser.PaperTocParser","title":"<code>PaperTocParser</code>","text":"<p>               Bases: <code>Textparser</code></p> <p>parser for paper table of contents</p> Source code in <code>ceurws/papertocparser.py</code> <pre><code>class PaperTocParser(Textparser):\n    \"\"\"\n    parser for paper table of contents\n    \"\"\"\n\n    def __init__(self, number: str, soup: BeautifulSoup, debug: bool = False):\n        \"\"\"\n        constructor\n\n        Args:\n            number(str): the volume number\n            soup(BeautifulSoup): the parser input\n            debug(bool): if True print out debug info\n        \"\"\"\n        Textparser.__init__(self, debug=debug)\n        self.number = number\n        self.soup = soup\n        self.scrape = WebScrape()\n        self.scrapeDescr = [\n            ScrapeDescription(key=\"title\", tag=\"span\", attribute=\"class\", value=\"CEURTITLE\"),\n            ScrapeDescription(\n                key=\"authors\",\n                tag=\"span\",\n                attribute=\"class\",\n                value=\"CEURAUTHOR\",\n                multi=True,\n            ),\n            ScrapeDescription(key=\"pages\", tag=\"span\", attribute=\"class\", value=\"CEURPAGES\"),\n            # ScrapeDescription(key='submitted_papers', tag='span', attribute='class', value='CEURSUBMITTEDPAPERS'),\n            # ScrapeDescription(key='accepted_papers', tag='span', attribute='class', value='CEURACCEPTEDPAPERS'),\n        ]\n\n    def parsePapers(self):\n        \"\"\"\n        parse the toc to papers\n        \"\"\"\n        paper_records = []\n        toc = self.soup.find(attrs={\"class\": \"CEURTOC\"})\n        if toc:\n            paper_ids = []\n            for index, paper_li in enumerate(toc.findAll(\"li\")):\n                paper_record = self.scrape.parseWithScrapeDescription(paper_li, self.scrapeDescr)\n                paper_record[\"vol_number\"] = self.number\n                href_node = paper_li.find(\"a\", href=True)\n                if href_node:\n                    href = href_node.attrs[\"href\"]\n                    href = Textparser.sanitize(href)\n                    paper_record[\"pdf_name\"] = href\n                if \"id\" in paper_li.attrs:\n                    paper_id = paper_li.attrs[\"id\"]\n                    if paper_id in paper_ids:\n                        paper_id = f\"{paper_id}-duplicate-{index}\"\n                    paper_ids.append(paper_id)\n                    key = f\"Vol-{self.number}/{paper_id}\"\n                    paper_record[\"id\"] = key\n                paper_records.append(paper_record)\n                pass\n        else:\n            toc = self.soup.find(\"h2\", string=re.compile(\".*Contents.*\"))\n            if toc:\n                index = 0\n                for paper_li in self.soup.find_all(\"li\", recursive=True):\n                    href_node = paper_li.find(\"a\", href=True)\n                    if href_node:\n                        href = href_node.attrs[\"href\"]\n                        href = Textparser.sanitize(href)\n                        if \".pdf\" in href:\n                            title = Textparser.sanitize(href_node.text)\n                            index += 1\n                            key = f\"Vol-{self.number}/paper-{index}\"\n                            paper_record = {\n                                \"vol_number\": self.number,\n                                \"title\": title,\n                                \"pdf_name\": href,\n                                \"id\": key,\n                            }\n                            authors = \"\"\n                            # authors are after next br tag\n                            br = paper_li.find(\"br\")\n                            if not br:\n                                paper_record[\"fail\"] = \"authors br not found\"\n                            else:\n                                author_part = br.next_sibling\n                                if not author_part:\n                                    paper_record[\"fail\"] = \"authors br not found\"\n                                else:\n                                    authors = author_part.text\n                            authors = Textparser.sanitize(authors)\n                            author_list = authors.split(\",\")\n                            for i, author in enumerate(author_list):\n                                author_list[i] = author.strip()\n                            paper_record[\"authors\"] = author_list\n                            paper_records.append(paper_record)\n            else:\n                if self.debug:\n                    print(f\"no toc for {self.number}\")\n        return paper_records\n</code></pre>"},{"location":"#ceurws.papertocparser.PaperTocParser.__init__","title":"<code>__init__(number, soup, debug=False)</code>","text":"<p>constructor</p> <p>Parameters:</p> Name Type Description Default <code>number(str)</code> <p>the volume number</p> required <code>soup(BeautifulSoup)</code> <p>the parser input</p> required <code>debug(bool)</code> <p>if True print out debug info</p> required Source code in <code>ceurws/papertocparser.py</code> <pre><code>def __init__(self, number: str, soup: BeautifulSoup, debug: bool = False):\n    \"\"\"\n    constructor\n\n    Args:\n        number(str): the volume number\n        soup(BeautifulSoup): the parser input\n        debug(bool): if True print out debug info\n    \"\"\"\n    Textparser.__init__(self, debug=debug)\n    self.number = number\n    self.soup = soup\n    self.scrape = WebScrape()\n    self.scrapeDescr = [\n        ScrapeDescription(key=\"title\", tag=\"span\", attribute=\"class\", value=\"CEURTITLE\"),\n        ScrapeDescription(\n            key=\"authors\",\n            tag=\"span\",\n            attribute=\"class\",\n            value=\"CEURAUTHOR\",\n            multi=True,\n        ),\n        ScrapeDescription(key=\"pages\", tag=\"span\", attribute=\"class\", value=\"CEURPAGES\"),\n        # ScrapeDescription(key='submitted_papers', tag='span', attribute='class', value='CEURSUBMITTEDPAPERS'),\n        # ScrapeDescription(key='accepted_papers', tag='span', attribute='class', value='CEURACCEPTEDPAPERS'),\n    ]\n</code></pre>"},{"location":"#ceurws.papertocparser.PaperTocParser.parsePapers","title":"<code>parsePapers()</code>","text":"<p>parse the toc to papers</p> Source code in <code>ceurws/papertocparser.py</code> <pre><code>def parsePapers(self):\n    \"\"\"\n    parse the toc to papers\n    \"\"\"\n    paper_records = []\n    toc = self.soup.find(attrs={\"class\": \"CEURTOC\"})\n    if toc:\n        paper_ids = []\n        for index, paper_li in enumerate(toc.findAll(\"li\")):\n            paper_record = self.scrape.parseWithScrapeDescription(paper_li, self.scrapeDescr)\n            paper_record[\"vol_number\"] = self.number\n            href_node = paper_li.find(\"a\", href=True)\n            if href_node:\n                href = href_node.attrs[\"href\"]\n                href = Textparser.sanitize(href)\n                paper_record[\"pdf_name\"] = href\n            if \"id\" in paper_li.attrs:\n                paper_id = paper_li.attrs[\"id\"]\n                if paper_id in paper_ids:\n                    paper_id = f\"{paper_id}-duplicate-{index}\"\n                paper_ids.append(paper_id)\n                key = f\"Vol-{self.number}/{paper_id}\"\n                paper_record[\"id\"] = key\n            paper_records.append(paper_record)\n            pass\n    else:\n        toc = self.soup.find(\"h2\", string=re.compile(\".*Contents.*\"))\n        if toc:\n            index = 0\n            for paper_li in self.soup.find_all(\"li\", recursive=True):\n                href_node = paper_li.find(\"a\", href=True)\n                if href_node:\n                    href = href_node.attrs[\"href\"]\n                    href = Textparser.sanitize(href)\n                    if \".pdf\" in href:\n                        title = Textparser.sanitize(href_node.text)\n                        index += 1\n                        key = f\"Vol-{self.number}/paper-{index}\"\n                        paper_record = {\n                            \"vol_number\": self.number,\n                            \"title\": title,\n                            \"pdf_name\": href,\n                            \"id\": key,\n                        }\n                        authors = \"\"\n                        # authors are after next br tag\n                        br = paper_li.find(\"br\")\n                        if not br:\n                            paper_record[\"fail\"] = \"authors br not found\"\n                        else:\n                            author_part = br.next_sibling\n                            if not author_part:\n                                paper_record[\"fail\"] = \"authors br not found\"\n                            else:\n                                authors = author_part.text\n                        authors = Textparser.sanitize(authors)\n                        author_list = authors.split(\",\")\n                        for i, author in enumerate(author_list):\n                            author_list[i] = author.strip()\n                        paper_record[\"authors\"] = author_list\n                        paper_records.append(paper_record)\n        else:\n            if self.debug:\n                print(f\"no toc for {self.number}\")\n    return paper_records\n</code></pre>"},{"location":"#ceurws.services","title":"<code>services</code>","text":""},{"location":"#ceurws.services.entity_fishing","title":"<code>entity_fishing</code>","text":""},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing","title":"<code>CeurEntityFishing</code>","text":"<p>EntityFishing component for spaCy pipeline. modified version of https://github.com/Lucaterre/spacyfishing/blob/main/spacyfishing/entity_fishing_linker.py</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>@Language.factory(\n    name=ENTITY_FISHING_PIPELINE,\n    default_config={\n        \"api_ef_base\": f\"{ENTITY_FISHING_ENDPOINT}/service\",\n        \"language\": \"en\",\n        \"extra_info\": False,\n        \"filter_statements\": [],\n        \"verbose\": False,\n    },\n)\nclass CeurEntityFishing:\n    \"\"\"\n    EntityFishing component for spaCy pipeline.\n    modified version of https://github.com/Lucaterre/spacyfishing/blob/main/spacyfishing/entity_fishing_linker.py\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str,\n        api_ef_base: str,\n        language: str,\n        extra_info: bool,\n        filter_statements: list,\n        verbose: bool,\n    ):\n        \"\"\"\n        `EntityFishing` main class component.\n\n        Note:\n            Show default config for default attributes values.\n\n        Parameters:\n            api_ef_base (str): describes url of the entity-fishing API used.\n            language (str): matches the language of the resources to\n            be disambiguated (matches the language model for the NER task).\n            extra_info (bool): attach extra information to spans as normalised term,\n            description, others knowledge base ids.\n            filter_statements (list): filter others KB ids\n            that relies on QID  eg. ['P214', 'P244'].\n            verbose (bool): display logging messages.\n\n        Attributes:\n            api_ef_base (str): cf. `api_ef_base` in parameters section.\n            language (dict): cf. `language` in parameters section.\n            prepare the language argument for the query.\n            wikidata_url_base (str): wikidata base url (to concatenate QID identifiers).\n            flag_extra (bool): cf. `extra_info` in parameters section.\n            filter_statements (list): cf. `filter_statements` in parameters section.\n            verbose (bool): cf. `verbose` in parameters section.\n        \"\"\"\n        if not api_ef_base.endswith(\"/\"):\n            api_ef_base += \"/\"\n        self.api_ef_base = api_ef_base\n        self.language = dict(lang=language)\n        self.wikidata_url_base = \"https://www.wikidata.org/wiki/\"\n\n        self.flag_extra = extra_info\n        self.filter_statements = filter_statements\n        self.verbose = verbose\n\n        # Set doc extensions to attaches raw response from Entity-Fishing API to doc\n        Doc.set_extension(\"annotations\", default={}, force=True)\n        Doc.set_extension(\"metadata\", default={}, force=True)\n\n        # Set spans extensions to enhance spans with new information\n        # come from Wikidata knowledge base.\n        # default spans :\n        Span.set_extension(\"kb_qid\", default=None, force=True)\n        Span.set_extension(\"wikipedia_page_ref\", default=None, force=True)\n        Span.set_extension(\"url_wikidata\", default=None, force=True)\n        Span.set_extension(\"nerd_score\", default=None, force=True)\n\n        # spans if extra_info set to True\n        Span.set_extension(\"normal_term\", default=None, force=True)\n        Span.set_extension(\"description\", default=None, force=True)\n        Span.set_extension(\"src_description\", default=None, force=True)\n        Span.set_extension(\"other_ids\", default=None, force=True)\n\n    @staticmethod\n    def generic_client_batch(\n        method: str,\n        url_batch: list[str],\n        verbose: bool,\n        params: dict | None = None,\n        files_batch: list[dict] | None = None,\n    ) -&gt; list[requests.Response]:\n        \"\"\"\n        It takes a list of urls and a list of files, and it sends a request to each url with the\n        corresponding file\n\n        :param method: str,\n        :type method: str\n        :param url_batch: a list of urls to send requests to\n        :type url_batch: list[str]\n        :param verbose: if True, the client will print out the status of each request\n        :type verbose: bool\n        :param params: dict = None,\n        :type params: dict\n        :param files_batch: a list of dictionaries, each dictionary containing the file to be annotated\n        :type files_batch: list[dict]\n        :return: A list of responses.\n        \"\"\"\n        if params is None:\n            params = {}\n        if files_batch is None:\n            files_batch = [{} for url in url_batch]\n\n        def load_url(type_url, type_files):\n            if method == \"POST\":\n                return requests.post(\n                    url=type_url, headers={\"Accept\": \"application/json\"}, files=type_files, params=params\n                )\n            else:\n                return requests.get(\n                    url=type_url, headers={\"Accept\": \"application/json\"}, files=type_files, params=params\n                )\n\n        response_batch = []\n        resp_err, resp_ok = 0, 0\n        with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n            future_to_url = {\n                executor.submit(load_url, type_url, type_files): (type_url, type_files)\n                for type_url, type_files in zip(url_batch, files_batch, strict=False)\n            }\n            for future in concurrent.futures.as_completed(future_to_url):\n                # url = future_to_url[future]\n                try:\n                    response_batch.append(future.result())\n                except Exception:\n                    resp_err = resp_err + 1\n                else:\n                    resp_ok = resp_ok + 1\n\n        def client_log(msg: str) -&gt; None:\n            if verbose:\n                logging.warning(msg)\n\n        # Manage response status code :\n        # cf. https://nerd.readthedocs.io/en/latest/restAPI.html#response-status-codes\n        for idx, response in enumerate(response_batch):\n            if response.status_code == 400:\n                client_log(\n                    f\"Request {idx}. Wrong request, missing parameters, \"\n                    \"missing header, text too short (&lt;= 5 characters). (400)\"\n                )\n            elif response.status_code == 500:\n                client_log(f\"Request {idx}. Entity-Fishing API service seems broken. (500)\")\n            elif response.status_code == 404:\n                client_log(f\"Request {idx}. Property was not found in request body. (404)\")\n            elif response.status_code == 406:\n                client_log(f\"Request {idx}. Language is not supported by Entity-Fishing. (406)\")\n\n        return response_batch\n\n    @staticmethod\n    def process_response(response: requests.models.Response) -&gt; tuple[dict, dict]:\n        \"\"\"\n        It takes a response object from the `requests` library and returns a tuple of two dictionaries.\n        The first dictionary is the JSON response from the API, and the second dictionary contains\n        metadata about the response\n\n        :param response: The response object returned by the requests library\n        :type response: requests.models.Response\n        :return: A tuple of two dictionaries.\n        \"\"\"\n        try:\n            res_json = response.json()\n        except json.decoder.JSONDecodeError:\n            res_json = {}\n\n        metadata = {\n            \"status_code\": response.status_code,\n            \"reason\": response.reason,\n            \"ok\": response.ok,\n            \"encoding\": response.encoding,\n        }\n\n        return res_json, metadata\n\n    @staticmethod\n    def prepare_data(text: str, terms: str, entities: list, language: dict, full: bool = False) -&gt; dict:\n        \"\"\"\n        &gt; The function takes in a text, a list of entities, a language dictionary and a boolean value.\n        It then returns a dictionary with a key called \"query\" and a value that is a JSON object\n\n        :param text: The text to be analyzed\n        :type text: str\n        :param terms: the terms to be searched for\n        :type terms: str\n        :param entities: list of entities in the text\n        :type entities: list\n        :param language: the language of the text\n        :type language: dict\n        :param full: if True, the response will contain the full text of the article, defaults to False\n        :type full: bool (optional)\n        :return: A dictionary with a key of \"query\" and a value of a json object.\n        \"\"\"\n        return {\n            \"query\": json.dumps(\n                {\n                    \"text\": text,\n                    \"shortText\": terms,\n                    \"language\": language,\n                    \"entities\": [\n                        {\n                            \"rawName\": ent.text,\n                            \"offsetStart\": ent.start_char,\n                            \"offsetEnd\": ent.end_char,\n                        }\n                        for ent in entities\n                    ],\n                    \"mentions\": [],\n                    \"customisation\": \"generic\",\n                    \"full\": \"true\" if full else \"false\",\n                },\n                ensure_ascii=False,\n            )\n        }\n\n    def updated_entities(self, doc: Doc, response: list) -&gt; None:\n        \"\"\"\n        &gt; The function `updated_entities` takes a `Doc` object and a list of entities as input. It then\n        iterates over the list of entities and updates the `Doc` object with the information contained\n        in the list of entities\n\n        :param doc: the document to be processed\n        :type doc: Doc\n        :param response: the response from the NERD API\n        :type response: list\n        \"\"\"\n        for entity in response:\n            with contextlib.suppress(AttributeError):\n                span = doc.char_span(start_idx=entity[\"offsetStart\"], end_idx=entity[\"offsetEnd\"])\n                with contextlib.suppress(KeyError):\n                    span._.kb_qid = str(entity[\"wikidataId\"])\n                    span._.url_wikidata = self.wikidata_url_base + span._.kb_qid\n                with contextlib.suppress(KeyError):\n                    span._.wikipedia_page_ref = str(entity[\"wikipediaExternalRef\"])\n                    # if flag_extra : search other info on entity\n                    # =&gt; attach extra entity info to span\n                    if self.flag_extra:\n                        self.look_extra_informations_on_entity(span, entity)\n                with contextlib.suppress(KeyError):\n                    span._.nerd_score = entity[\"confidence_score\"]\n\n    # ~ Entity-fishing call service methods ~:\n    def concept_look_up_batch(self, wiki_id_batch: str) -&gt; list[requests.Response]:\n        \"\"\"\n        &gt; This function takes a list of wikipedia ids and returns a list of responses from the API\n\n        :param wiki_id_batch: a list of wikipedia ids\n        :type wiki_id_batch: str\n        :return: A list of requests.Response objects.\n        \"\"\"\n        url_concept_lookup_batch = [self.api_ef_base + \"kb/concept/\" + wiki_id for wiki_id in wiki_id_batch]\n        return self.generic_client_batch(\n            method=\"GET\", url_batch=url_concept_lookup_batch, params=self.language, verbose=self.verbose\n        )\n\n    def disambiguate_text_batch(self, files_batch: list[dict]) -&gt; list[requests.Response]:\n        \"\"\"\n        &gt; The function `disambiguate_text_batch` takes a list of dictionaries as input, where each\n        dictionary contains the text to be disambiguated and the corresponding language. The function\n        returns a list of responses, where each response contains the disambiguated text\n\n        :param files_batch: a list of dictionaries, each dictionary containing the following keys:\n        :type files_batch: list[dict]\n        :return: A list of responses.\n        \"\"\"\n        url_disambiguate = self.api_ef_base + \"disambiguate\"\n        url_disambiguate_batch = [url_disambiguate for file in files_batch]\n        return self.generic_client_batch(\n            method=\"POST\", url_batch=url_disambiguate_batch, files_batch=files_batch, verbose=self.verbose\n        )\n\n    def look_extra_informations_on_entity(self, span: Span, res_desc: dict) -&gt; None:\n        \"\"\"\n        It takes a span and a dictionary of information about the entity, and adds the information to\n        the span\n\n        :param span: The Span object that the extension is being applied to\n        :type span: Span\n        :param res_desc: the result of the query to Wikidata\n        :type res_desc: dict\n        \"\"\"\n        # normalised term name\n        with contextlib.suppress(KeyError):\n            span._.normal_term = res_desc[\"preferredTerm\"]\n        # description and source description (filter by language)\n        with contextlib.suppress(KeyError, IndexError):\n            span._.description = res_desc[\"definitions\"][0][\"definition\"]\n            span._.src_description = res_desc[\"definitions\"][0][\"source\"]\n        # others identifiers attach to QID\n        # in Wikidata KB with filter properties or not\n        try:\n            ids = []\n            for content in res_desc[\"statements\"]:\n                new_id = {k: content[k] for k in [\"propertyName\", \"propertyId\", \"value\"]}\n                if len(self.filter_statements) != 0:\n                    if content[\"propertyId\"] in self.filter_statements:\n                        ids.append(new_id)\n                else:\n                    ids.append(new_id)\n\n            span._.other_ids = ids\n        except KeyError:\n            pass\n        except json.decoder.JSONDecodeError:\n            pass\n\n    def main_disambiguation_process_batch(\n        self, text_batch: list[str], terms_batch: list[str], entities_batch: list[list]\n    ) -&gt; list[tuple[dict, dict, list]]:\n        \"\"\"\n        It takes a batch of text, terms and entities, and returns a batch of disambiguated entities\n\n        :param text_batch: a list of strings, each string is a text to be disambiguated\n        :type text_batch: list[str]\n        :param terms_batch: a list of strings, each string is a list of terms separated by a space\n        :type terms_batch: list[str]\n        :param entities_batch: a list of lists of entities, where each entity is a dictionary with the\n        following keys:\n        :type entities_batch: list[list]\n        :return: A list of tuples, each tuple containing the response, metadata, and entities_enhanced.\n        \"\"\"\n        data_to_post_batch = [\n            self.prepare_data(text=text, terms=terms, entities=entities, language=self.language, full=self.flag_extra)\n            for text, terms, entities in zip(text_batch, terms_batch, entities_batch, strict=False)\n        ]\n        reqs = self.disambiguate_text_batch(files_batch=data_to_post_batch)\n\n        response_tuples = []\n        for req in reqs:\n            res, metadata = self.process_response(response=req)\n            try:\n                entities_enhanced = res[\"entities\"]\n            except KeyError:\n                entities_enhanced = []\n            response_tuples.append((res, metadata, entities_enhanced))\n        return response_tuples\n\n    def process_single_doc_after_call(self, doc: Doc, result_from_ef_text) -&gt; Doc:\n        \"\"\"\n        - The function takes a document and a list of entities from the Entity-Fishing service.\n        - It then checks if there are any entities in the document that were not disambiguated by the\n        Entity-Fishing service.\n        - If there are, it passes the text of these entities to the Entity-Fishing service again, but\n        this time without the text of the document.\n        - It then merges the results of the two calls to the Entity-Fishing service and attaches the\n        information from the Entity-Fishing service to the entities in the document\n\n        :param doc: The document to be processed\n        :type doc: Doc\n        :param result_from_ef_text: a list of three elements:\n        :return: A list of dictionaries, each dictionary contains the information of a single entity.\n        \"\"\"\n        entities_from_text = result_from_ef_text[2]\n\n        # 1a. Attach raw response (with text method in Entity-Fishing service) to doc\n        if len(result_from_ef_text[0]) &gt; 0:\n            doc._.annotations[\"disambiguation_text_service\"] = result_from_ef_text[0]\n\n        doc._.metadata[\"disambiguation_text_service\"] = result_from_ef_text[1]\n\n        # 2 .Because some named entities have not been disambiguated,\n        # create a list with these unrelated entities (\"nil clustering\").\n        # Pass them back in Entity-fishing without the text but with all\n        # the named entities surrounding these entities, to create a context\n        # of neighboring terms.\n        # nil_clustering = named entities in doc - actual disambiguated entities by EF\n        nil_clustering = []\n        if len(result_from_ef_text[0]) &gt; 0:\n            with contextlib.suppress(KeyError):\n                nil_clustering = [\n                    doc.char_span(start_idx=ent[1], end_idx=ent[2])\n                    for ent in [(ent.text, ent.start_char, ent.end_char) for ent in doc.ents]\n                    if ent\n                    not in [\n                        (ent_ef[\"rawName\"], ent_ef[\"offsetStart\"], ent_ef[\"offsetEnd\"])\n                        for ent_ef in result_from_ef_text[0][\"entities\"]\n                    ]\n                ]\n        entities_from_terms = []\n        if len(nil_clustering) != 0:\n            # prepare query for Entity-Fishing terms disambiguation\n            terms = \" \".join([ent.text for ent in doc.ents])\n            result_from_ef_terms = self.main_disambiguation_process_batch(\n                text_batch=[\"\"], terms_batch=[terms], entities_batch=[nil_clustering]\n            )[0]\n\n            entities_from_terms = result_from_ef_terms[2]\n\n            # 2b. Attach raw response (with terms method in Entity-Fishing service) to doc\n            if len(result_from_ef_terms[0]) &gt; 0:\n                doc._.annotations[\"disambiguation_terms_service\"] = result_from_ef_terms[0]\n            doc._.metadata[\"disambiguation_terms_service\"] = result_from_ef_terms[1]\n\n        # 3. Merge two list of entities (first and second pass in EF service)\n        # and attach information from Entity-Fishing to spans\n        result = (\n            entities_from_text\n            + [entity_term for entity_term in entities_from_terms if entity_term not in entities_from_text]\n            if len(entities_from_terms) &gt; 0\n            else entities_from_text\n        )\n\n        if len(result) &gt; 0:\n            with contextlib.suppress(KeyError):\n                self.updated_entities(doc, result)\n        return doc\n\n    def __call__(self, doc: Doc) -&gt; Doc:\n        \"\"\"\n        &gt; The function takes a spaCy Doc object, and returns a Doc object with the entities\n        disambiguated and linked\n\n        :param doc: Doc\n        :type doc: Doc\n        :return: A Doc object with the entities linked to the corresponding Wikipedia page.\n        \"\"\"\n        # 1. Disambiguate and linking named entities in Doc object with Entity-Fishing\n        result_from_ef_text = self.main_disambiguation_process_batch(\n            text_batch=[doc.text], terms_batch=[\"\"], entities_batch=[doc.ents]\n        )[0]\n        return self.process_single_doc_after_call(doc, result_from_ef_text)\n\n    def pipe(self, stream: Iterable, batch_size: int = 128) -&gt; Doc:\n        \"\"\"\n        For each batch of documents, we disambiguate the named entities in the documents, and then yield\n        the results\n\n        :param stream: a generator that yields Doc objects\n        :type stream: iterator\n        :param batch_size: The number of documents to process at a time, defaults to 128 (optional)\n        :type batch_size: int\n        \"\"\"\n        for docs in util.minibatch(stream, size=batch_size):\n            text_batch = [doc.text for doc in docs]\n            entities_batch = [doc.ents for doc in docs]\n            terms_batch = [\"\" for _ in text_batch]\n\n            # 1. Disambiguate and linking named entities in Doc object with Entity-Fishing\n            result_from_ef_text_batch = self.main_disambiguation_process_batch(\n                text_batch=text_batch, terms_batch=terms_batch, entities_batch=entities_batch\n            )\n\n            for doc, result_from_ef_text in zip(docs, result_from_ef_text_batch, strict=False):\n                yield self.process_single_doc_after_call(doc, result_from_ef_text)\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.__call__","title":"<code>__call__(doc)</code>","text":"<p>The function takes a spaCy Doc object, and returns a Doc object with the entities disambiguated and linked</p> <p>:param doc: Doc :type doc: Doc :return: A Doc object with the entities linked to the corresponding Wikipedia page.</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; Doc:\n    \"\"\"\n    &gt; The function takes a spaCy Doc object, and returns a Doc object with the entities\n    disambiguated and linked\n\n    :param doc: Doc\n    :type doc: Doc\n    :return: A Doc object with the entities linked to the corresponding Wikipedia page.\n    \"\"\"\n    # 1. Disambiguate and linking named entities in Doc object with Entity-Fishing\n    result_from_ef_text = self.main_disambiguation_process_batch(\n        text_batch=[doc.text], terms_batch=[\"\"], entities_batch=[doc.ents]\n    )[0]\n    return self.process_single_doc_after_call(doc, result_from_ef_text)\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.__init__","title":"<code>__init__(nlp, name, api_ef_base, language, extra_info, filter_statements, verbose)</code>","text":"<p><code>EntityFishing</code> main class component.</p> Note <p>Show default config for default attributes values.</p> <p>Parameters:</p> Name Type Description Default <code>api_ef_base</code> <code>str</code> <p>describes url of the entity-fishing API used.</p> required <code>language</code> <code>str</code> <p>matches the language of the resources to</p> required <code>extra_info</code> <code>bool</code> <p>attach extra information to spans as normalised term,</p> required <code>filter_statements</code> <code>list</code> <p>filter others KB ids</p> required <code>verbose</code> <code>bool</code> <p>display logging messages.</p> required <p>Attributes:</p> Name Type Description <code>api_ef_base</code> <code>str</code> <p>cf. <code>api_ef_base</code> in parameters section.</p> <code>language</code> <code>dict</code> <p>cf. <code>language</code> in parameters section.</p> <code>wikidata_url_base</code> <code>str</code> <p>wikidata base url (to concatenate QID identifiers).</p> <code>flag_extra</code> <code>bool</code> <p>cf. <code>extra_info</code> in parameters section.</p> <code>filter_statements</code> <code>list</code> <p>cf. <code>filter_statements</code> in parameters section.</p> <code>verbose</code> <code>bool</code> <p>cf. <code>verbose</code> in parameters section.</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str,\n    api_ef_base: str,\n    language: str,\n    extra_info: bool,\n    filter_statements: list,\n    verbose: bool,\n):\n    \"\"\"\n    `EntityFishing` main class component.\n\n    Note:\n        Show default config for default attributes values.\n\n    Parameters:\n        api_ef_base (str): describes url of the entity-fishing API used.\n        language (str): matches the language of the resources to\n        be disambiguated (matches the language model for the NER task).\n        extra_info (bool): attach extra information to spans as normalised term,\n        description, others knowledge base ids.\n        filter_statements (list): filter others KB ids\n        that relies on QID  eg. ['P214', 'P244'].\n        verbose (bool): display logging messages.\n\n    Attributes:\n        api_ef_base (str): cf. `api_ef_base` in parameters section.\n        language (dict): cf. `language` in parameters section.\n        prepare the language argument for the query.\n        wikidata_url_base (str): wikidata base url (to concatenate QID identifiers).\n        flag_extra (bool): cf. `extra_info` in parameters section.\n        filter_statements (list): cf. `filter_statements` in parameters section.\n        verbose (bool): cf. `verbose` in parameters section.\n    \"\"\"\n    if not api_ef_base.endswith(\"/\"):\n        api_ef_base += \"/\"\n    self.api_ef_base = api_ef_base\n    self.language = dict(lang=language)\n    self.wikidata_url_base = \"https://www.wikidata.org/wiki/\"\n\n    self.flag_extra = extra_info\n    self.filter_statements = filter_statements\n    self.verbose = verbose\n\n    # Set doc extensions to attaches raw response from Entity-Fishing API to doc\n    Doc.set_extension(\"annotations\", default={}, force=True)\n    Doc.set_extension(\"metadata\", default={}, force=True)\n\n    # Set spans extensions to enhance spans with new information\n    # come from Wikidata knowledge base.\n    # default spans :\n    Span.set_extension(\"kb_qid\", default=None, force=True)\n    Span.set_extension(\"wikipedia_page_ref\", default=None, force=True)\n    Span.set_extension(\"url_wikidata\", default=None, force=True)\n    Span.set_extension(\"nerd_score\", default=None, force=True)\n\n    # spans if extra_info set to True\n    Span.set_extension(\"normal_term\", default=None, force=True)\n    Span.set_extension(\"description\", default=None, force=True)\n    Span.set_extension(\"src_description\", default=None, force=True)\n    Span.set_extension(\"other_ids\", default=None, force=True)\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.concept_look_up_batch","title":"<code>concept_look_up_batch(wiki_id_batch)</code>","text":"<p>This function takes a list of wikipedia ids and returns a list of responses from the API</p> <p>:param wiki_id_batch: a list of wikipedia ids :type wiki_id_batch: str :return: A list of requests.Response objects.</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>def concept_look_up_batch(self, wiki_id_batch: str) -&gt; list[requests.Response]:\n    \"\"\"\n    &gt; This function takes a list of wikipedia ids and returns a list of responses from the API\n\n    :param wiki_id_batch: a list of wikipedia ids\n    :type wiki_id_batch: str\n    :return: A list of requests.Response objects.\n    \"\"\"\n    url_concept_lookup_batch = [self.api_ef_base + \"kb/concept/\" + wiki_id for wiki_id in wiki_id_batch]\n    return self.generic_client_batch(\n        method=\"GET\", url_batch=url_concept_lookup_batch, params=self.language, verbose=self.verbose\n    )\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.disambiguate_text_batch","title":"<code>disambiguate_text_batch(files_batch)</code>","text":"<p>The function <code>disambiguate_text_batch</code> takes a list of dictionaries as input, where each dictionary contains the text to be disambiguated and the corresponding language. The function returns a list of responses, where each response contains the disambiguated text</p> <p>:param files_batch: a list of dictionaries, each dictionary containing the following keys: :type files_batch: list[dict] :return: A list of responses.</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>def disambiguate_text_batch(self, files_batch: list[dict]) -&gt; list[requests.Response]:\n    \"\"\"\n    &gt; The function `disambiguate_text_batch` takes a list of dictionaries as input, where each\n    dictionary contains the text to be disambiguated and the corresponding language. The function\n    returns a list of responses, where each response contains the disambiguated text\n\n    :param files_batch: a list of dictionaries, each dictionary containing the following keys:\n    :type files_batch: list[dict]\n    :return: A list of responses.\n    \"\"\"\n    url_disambiguate = self.api_ef_base + \"disambiguate\"\n    url_disambiguate_batch = [url_disambiguate for file in files_batch]\n    return self.generic_client_batch(\n        method=\"POST\", url_batch=url_disambiguate_batch, files_batch=files_batch, verbose=self.verbose\n    )\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.generic_client_batch","title":"<code>generic_client_batch(method, url_batch, verbose, params=None, files_batch=None)</code>  <code>staticmethod</code>","text":"<p>It takes a list of urls and a list of files, and it sends a request to each url with the corresponding file</p> <p>:param method: str, :type method: str :param url_batch: a list of urls to send requests to :type url_batch: list[str] :param verbose: if True, the client will print out the status of each request :type verbose: bool :param params: dict = None, :type params: dict :param files_batch: a list of dictionaries, each dictionary containing the file to be annotated :type files_batch: list[dict] :return: A list of responses.</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>@staticmethod\ndef generic_client_batch(\n    method: str,\n    url_batch: list[str],\n    verbose: bool,\n    params: dict | None = None,\n    files_batch: list[dict] | None = None,\n) -&gt; list[requests.Response]:\n    \"\"\"\n    It takes a list of urls and a list of files, and it sends a request to each url with the\n    corresponding file\n\n    :param method: str,\n    :type method: str\n    :param url_batch: a list of urls to send requests to\n    :type url_batch: list[str]\n    :param verbose: if True, the client will print out the status of each request\n    :type verbose: bool\n    :param params: dict = None,\n    :type params: dict\n    :param files_batch: a list of dictionaries, each dictionary containing the file to be annotated\n    :type files_batch: list[dict]\n    :return: A list of responses.\n    \"\"\"\n    if params is None:\n        params = {}\n    if files_batch is None:\n        files_batch = [{} for url in url_batch]\n\n    def load_url(type_url, type_files):\n        if method == \"POST\":\n            return requests.post(\n                url=type_url, headers={\"Accept\": \"application/json\"}, files=type_files, params=params\n            )\n        else:\n            return requests.get(\n                url=type_url, headers={\"Accept\": \"application/json\"}, files=type_files, params=params\n            )\n\n    response_batch = []\n    resp_err, resp_ok = 0, 0\n    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n        future_to_url = {\n            executor.submit(load_url, type_url, type_files): (type_url, type_files)\n            for type_url, type_files in zip(url_batch, files_batch, strict=False)\n        }\n        for future in concurrent.futures.as_completed(future_to_url):\n            # url = future_to_url[future]\n            try:\n                response_batch.append(future.result())\n            except Exception:\n                resp_err = resp_err + 1\n            else:\n                resp_ok = resp_ok + 1\n\n    def client_log(msg: str) -&gt; None:\n        if verbose:\n            logging.warning(msg)\n\n    # Manage response status code :\n    # cf. https://nerd.readthedocs.io/en/latest/restAPI.html#response-status-codes\n    for idx, response in enumerate(response_batch):\n        if response.status_code == 400:\n            client_log(\n                f\"Request {idx}. Wrong request, missing parameters, \"\n                \"missing header, text too short (&lt;= 5 characters). (400)\"\n            )\n        elif response.status_code == 500:\n            client_log(f\"Request {idx}. Entity-Fishing API service seems broken. (500)\")\n        elif response.status_code == 404:\n            client_log(f\"Request {idx}. Property was not found in request body. (404)\")\n        elif response.status_code == 406:\n            client_log(f\"Request {idx}. Language is not supported by Entity-Fishing. (406)\")\n\n    return response_batch\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.look_extra_informations_on_entity","title":"<code>look_extra_informations_on_entity(span, res_desc)</code>","text":"<p>It takes a span and a dictionary of information about the entity, and adds the information to the span</p> <p>:param span: The Span object that the extension is being applied to :type span: Span :param res_desc: the result of the query to Wikidata :type res_desc: dict</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>def look_extra_informations_on_entity(self, span: Span, res_desc: dict) -&gt; None:\n    \"\"\"\n    It takes a span and a dictionary of information about the entity, and adds the information to\n    the span\n\n    :param span: The Span object that the extension is being applied to\n    :type span: Span\n    :param res_desc: the result of the query to Wikidata\n    :type res_desc: dict\n    \"\"\"\n    # normalised term name\n    with contextlib.suppress(KeyError):\n        span._.normal_term = res_desc[\"preferredTerm\"]\n    # description and source description (filter by language)\n    with contextlib.suppress(KeyError, IndexError):\n        span._.description = res_desc[\"definitions\"][0][\"definition\"]\n        span._.src_description = res_desc[\"definitions\"][0][\"source\"]\n    # others identifiers attach to QID\n    # in Wikidata KB with filter properties or not\n    try:\n        ids = []\n        for content in res_desc[\"statements\"]:\n            new_id = {k: content[k] for k in [\"propertyName\", \"propertyId\", \"value\"]}\n            if len(self.filter_statements) != 0:\n                if content[\"propertyId\"] in self.filter_statements:\n                    ids.append(new_id)\n            else:\n                ids.append(new_id)\n\n        span._.other_ids = ids\n    except KeyError:\n        pass\n    except json.decoder.JSONDecodeError:\n        pass\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.main_disambiguation_process_batch","title":"<code>main_disambiguation_process_batch(text_batch, terms_batch, entities_batch)</code>","text":"<p>It takes a batch of text, terms and entities, and returns a batch of disambiguated entities</p> <p>:param text_batch: a list of strings, each string is a text to be disambiguated :type text_batch: list[str] :param terms_batch: a list of strings, each string is a list of terms separated by a space :type terms_batch: list[str] :param entities_batch: a list of lists of entities, where each entity is a dictionary with the following keys: :type entities_batch: list[list] :return: A list of tuples, each tuple containing the response, metadata, and entities_enhanced.</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>def main_disambiguation_process_batch(\n    self, text_batch: list[str], terms_batch: list[str], entities_batch: list[list]\n) -&gt; list[tuple[dict, dict, list]]:\n    \"\"\"\n    It takes a batch of text, terms and entities, and returns a batch of disambiguated entities\n\n    :param text_batch: a list of strings, each string is a text to be disambiguated\n    :type text_batch: list[str]\n    :param terms_batch: a list of strings, each string is a list of terms separated by a space\n    :type terms_batch: list[str]\n    :param entities_batch: a list of lists of entities, where each entity is a dictionary with the\n    following keys:\n    :type entities_batch: list[list]\n    :return: A list of tuples, each tuple containing the response, metadata, and entities_enhanced.\n    \"\"\"\n    data_to_post_batch = [\n        self.prepare_data(text=text, terms=terms, entities=entities, language=self.language, full=self.flag_extra)\n        for text, terms, entities in zip(text_batch, terms_batch, entities_batch, strict=False)\n    ]\n    reqs = self.disambiguate_text_batch(files_batch=data_to_post_batch)\n\n    response_tuples = []\n    for req in reqs:\n        res, metadata = self.process_response(response=req)\n        try:\n            entities_enhanced = res[\"entities\"]\n        except KeyError:\n            entities_enhanced = []\n        response_tuples.append((res, metadata, entities_enhanced))\n    return response_tuples\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.pipe","title":"<code>pipe(stream, batch_size=128)</code>","text":"<p>For each batch of documents, we disambiguate the named entities in the documents, and then yield the results</p> <p>:param stream: a generator that yields Doc objects :type stream: iterator :param batch_size: The number of documents to process at a time, defaults to 128 (optional) :type batch_size: int</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>def pipe(self, stream: Iterable, batch_size: int = 128) -&gt; Doc:\n    \"\"\"\n    For each batch of documents, we disambiguate the named entities in the documents, and then yield\n    the results\n\n    :param stream: a generator that yields Doc objects\n    :type stream: iterator\n    :param batch_size: The number of documents to process at a time, defaults to 128 (optional)\n    :type batch_size: int\n    \"\"\"\n    for docs in util.minibatch(stream, size=batch_size):\n        text_batch = [doc.text for doc in docs]\n        entities_batch = [doc.ents for doc in docs]\n        terms_batch = [\"\" for _ in text_batch]\n\n        # 1. Disambiguate and linking named entities in Doc object with Entity-Fishing\n        result_from_ef_text_batch = self.main_disambiguation_process_batch(\n            text_batch=text_batch, terms_batch=terms_batch, entities_batch=entities_batch\n        )\n\n        for doc, result_from_ef_text in zip(docs, result_from_ef_text_batch, strict=False):\n            yield self.process_single_doc_after_call(doc, result_from_ef_text)\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.prepare_data","title":"<code>prepare_data(text, terms, entities, language, full=False)</code>  <code>staticmethod</code>","text":"<p>The function takes in a text, a list of entities, a language dictionary and a boolean value. It then returns a dictionary with a key called \"query\" and a value that is a JSON object</p> <p>:param text: The text to be analyzed :type text: str :param terms: the terms to be searched for :type terms: str :param entities: list of entities in the text :type entities: list :param language: the language of the text :type language: dict :param full: if True, the response will contain the full text of the article, defaults to False :type full: bool (optional) :return: A dictionary with a key of \"query\" and a value of a json object.</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>@staticmethod\ndef prepare_data(text: str, terms: str, entities: list, language: dict, full: bool = False) -&gt; dict:\n    \"\"\"\n    &gt; The function takes in a text, a list of entities, a language dictionary and a boolean value.\n    It then returns a dictionary with a key called \"query\" and a value that is a JSON object\n\n    :param text: The text to be analyzed\n    :type text: str\n    :param terms: the terms to be searched for\n    :type terms: str\n    :param entities: list of entities in the text\n    :type entities: list\n    :param language: the language of the text\n    :type language: dict\n    :param full: if True, the response will contain the full text of the article, defaults to False\n    :type full: bool (optional)\n    :return: A dictionary with a key of \"query\" and a value of a json object.\n    \"\"\"\n    return {\n        \"query\": json.dumps(\n            {\n                \"text\": text,\n                \"shortText\": terms,\n                \"language\": language,\n                \"entities\": [\n                    {\n                        \"rawName\": ent.text,\n                        \"offsetStart\": ent.start_char,\n                        \"offsetEnd\": ent.end_char,\n                    }\n                    for ent in entities\n                ],\n                \"mentions\": [],\n                \"customisation\": \"generic\",\n                \"full\": \"true\" if full else \"false\",\n            },\n            ensure_ascii=False,\n        )\n    }\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.process_response","title":"<code>process_response(response)</code>  <code>staticmethod</code>","text":"<p>It takes a response object from the <code>requests</code> library and returns a tuple of two dictionaries. The first dictionary is the JSON response from the API, and the second dictionary contains metadata about the response</p> <p>:param response: The response object returned by the requests library :type response: requests.models.Response :return: A tuple of two dictionaries.</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>@staticmethod\ndef process_response(response: requests.models.Response) -&gt; tuple[dict, dict]:\n    \"\"\"\n    It takes a response object from the `requests` library and returns a tuple of two dictionaries.\n    The first dictionary is the JSON response from the API, and the second dictionary contains\n    metadata about the response\n\n    :param response: The response object returned by the requests library\n    :type response: requests.models.Response\n    :return: A tuple of two dictionaries.\n    \"\"\"\n    try:\n        res_json = response.json()\n    except json.decoder.JSONDecodeError:\n        res_json = {}\n\n    metadata = {\n        \"status_code\": response.status_code,\n        \"reason\": response.reason,\n        \"ok\": response.ok,\n        \"encoding\": response.encoding,\n    }\n\n    return res_json, metadata\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.process_single_doc_after_call","title":"<code>process_single_doc_after_call(doc, result_from_ef_text)</code>","text":"<ul> <li>The function takes a document and a list of entities from the Entity-Fishing service.</li> <li>It then checks if there are any entities in the document that were not disambiguated by the Entity-Fishing service.</li> <li>If there are, it passes the text of these entities to the Entity-Fishing service again, but this time without the text of the document.</li> <li>It then merges the results of the two calls to the Entity-Fishing service and attaches the information from the Entity-Fishing service to the entities in the document</li> </ul> <p>:param doc: The document to be processed :type doc: Doc :param result_from_ef_text: a list of three elements: :return: A list of dictionaries, each dictionary contains the information of a single entity.</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>def process_single_doc_after_call(self, doc: Doc, result_from_ef_text) -&gt; Doc:\n    \"\"\"\n    - The function takes a document and a list of entities from the Entity-Fishing service.\n    - It then checks if there are any entities in the document that were not disambiguated by the\n    Entity-Fishing service.\n    - If there are, it passes the text of these entities to the Entity-Fishing service again, but\n    this time without the text of the document.\n    - It then merges the results of the two calls to the Entity-Fishing service and attaches the\n    information from the Entity-Fishing service to the entities in the document\n\n    :param doc: The document to be processed\n    :type doc: Doc\n    :param result_from_ef_text: a list of three elements:\n    :return: A list of dictionaries, each dictionary contains the information of a single entity.\n    \"\"\"\n    entities_from_text = result_from_ef_text[2]\n\n    # 1a. Attach raw response (with text method in Entity-Fishing service) to doc\n    if len(result_from_ef_text[0]) &gt; 0:\n        doc._.annotations[\"disambiguation_text_service\"] = result_from_ef_text[0]\n\n    doc._.metadata[\"disambiguation_text_service\"] = result_from_ef_text[1]\n\n    # 2 .Because some named entities have not been disambiguated,\n    # create a list with these unrelated entities (\"nil clustering\").\n    # Pass them back in Entity-fishing without the text but with all\n    # the named entities surrounding these entities, to create a context\n    # of neighboring terms.\n    # nil_clustering = named entities in doc - actual disambiguated entities by EF\n    nil_clustering = []\n    if len(result_from_ef_text[0]) &gt; 0:\n        with contextlib.suppress(KeyError):\n            nil_clustering = [\n                doc.char_span(start_idx=ent[1], end_idx=ent[2])\n                for ent in [(ent.text, ent.start_char, ent.end_char) for ent in doc.ents]\n                if ent\n                not in [\n                    (ent_ef[\"rawName\"], ent_ef[\"offsetStart\"], ent_ef[\"offsetEnd\"])\n                    for ent_ef in result_from_ef_text[0][\"entities\"]\n                ]\n            ]\n    entities_from_terms = []\n    if len(nil_clustering) != 0:\n        # prepare query for Entity-Fishing terms disambiguation\n        terms = \" \".join([ent.text for ent in doc.ents])\n        result_from_ef_terms = self.main_disambiguation_process_batch(\n            text_batch=[\"\"], terms_batch=[terms], entities_batch=[nil_clustering]\n        )[0]\n\n        entities_from_terms = result_from_ef_terms[2]\n\n        # 2b. Attach raw response (with terms method in Entity-Fishing service) to doc\n        if len(result_from_ef_terms[0]) &gt; 0:\n            doc._.annotations[\"disambiguation_terms_service\"] = result_from_ef_terms[0]\n        doc._.metadata[\"disambiguation_terms_service\"] = result_from_ef_terms[1]\n\n    # 3. Merge two list of entities (first and second pass in EF service)\n    # and attach information from Entity-Fishing to spans\n    result = (\n        entities_from_text\n        + [entity_term for entity_term in entities_from_terms if entity_term not in entities_from_text]\n        if len(entities_from_terms) &gt; 0\n        else entities_from_text\n    )\n\n    if len(result) &gt; 0:\n        with contextlib.suppress(KeyError):\n            self.updated_entities(doc, result)\n    return doc\n</code></pre>"},{"location":"#ceurws.services.entity_fishing.CeurEntityFishing.updated_entities","title":"<code>updated_entities(doc, response)</code>","text":"<p>The function <code>updated_entities</code> takes a <code>Doc</code> object and a list of entities as input. It then iterates over the list of entities and updates the <code>Doc</code> object with the information contained in the list of entities</p> <p>:param doc: the document to be processed :type doc: Doc :param response: the response from the NERD API :type response: list</p> Source code in <code>ceurws/services/entity_fishing.py</code> <pre><code>def updated_entities(self, doc: Doc, response: list) -&gt; None:\n    \"\"\"\n    &gt; The function `updated_entities` takes a `Doc` object and a list of entities as input. It then\n    iterates over the list of entities and updates the `Doc` object with the information contained\n    in the list of entities\n\n    :param doc: the document to be processed\n    :type doc: Doc\n    :param response: the response from the NERD API\n    :type response: list\n    \"\"\"\n    for entity in response:\n        with contextlib.suppress(AttributeError):\n            span = doc.char_span(start_idx=entity[\"offsetStart\"], end_idx=entity[\"offsetEnd\"])\n            with contextlib.suppress(KeyError):\n                span._.kb_qid = str(entity[\"wikidataId\"])\n                span._.url_wikidata = self.wikidata_url_base + span._.kb_qid\n            with contextlib.suppress(KeyError):\n                span._.wikipedia_page_ref = str(entity[\"wikipediaExternalRef\"])\n                # if flag_extra : search other info on entity\n                # =&gt; attach extra entity info to span\n                if self.flag_extra:\n                    self.look_extra_informations_on_entity(span, entity)\n            with contextlib.suppress(KeyError):\n                span._.nerd_score = entity[\"confidence_score\"]\n</code></pre>"},{"location":"#ceurws.services.opentapioca","title":"<code>opentapioca</code>","text":"<p>@author: https://github.com/UB-Mannheim/spacyopentapioca/blob/main/spacyopentapioca/entity_linker.py</p>"},{"location":"#ceurws.services.opentapioca.EntityLinker","title":"<code>EntityLinker</code>","text":"<p>Sends raw data to the OpenTapioca API. Attaches entities to the document. Based on: https://github.com/UB-Mannheim/spacyopentapioca/blob/main/spacyopentapioca/entity_linker.py</p> Source code in <code>ceurws/services/opentapioca.py</code> <pre><code>@Language.factory(OPENTAPIOCA_PIPELINE, default_config={\"url\": f\"{OPENTAPIOCA_ENDPOINT}/api/annotate\"})\nclass EntityLinker:\n    \"\"\"\n    Sends raw data to the OpenTapioca API. Attaches entities to the document.\n    Based on: https://github.com/UB-Mannheim/spacyopentapioca/blob/main/spacyopentapioca/entity_linker.py\n    \"\"\"\n\n    def __init__(self, nlp, name, url):\n        \"\"\"Passes url. Registers OpenTapioca extensions for Doc and Span.\"\"\"\n        self.url = url\n        Doc.set_extension(\"annotations\", default=None, force=True)\n        Doc.set_extension(\"metadata\", default=None, force=True)\n        Span.set_extension(\"annotations\", default=None, force=True)\n        Span.set_extension(\"description\", default=None, force=True)\n        Span.set_extension(\"aliases\", default=None, force=True)\n        Span.set_extension(\"rank\", default=None, force=True)\n        Span.set_extension(\"score\", default=None, force=True)\n        Span.set_extension(\"types\", default=None, force=True)\n        Span.set_extension(\"label\", default=None, force=True)\n        Span.set_extension(\"extra_aliases\", default=None, force=True)\n        Span.set_extension(\"nb_sitelinks\", default=None, force=True)\n        Span.set_extension(\"nb_statements\", default=None, force=True)\n\n    def process_single_doc_after_call(self, doc: Doc, r) -&gt; Doc:\n        r.raise_for_status()\n        data = r.json()\n\n        # Attaches raw data to doc\n        doc._.annotations = data.get(\"annotations\")\n        doc._.metadata = {\"status_code\": r.status_code, \"reason\": r.reason, \"ok\": r.ok, \"encoding\": r.encoding}\n\n        # Attaches indexes, label and QID to spans\n        # Processes annotations: if 'best_qid'==None, then no annotation\n        ents = []\n        for ent in data.get(\"annotations\"):\n            start, end = ent[\"start\"], ent[\"end\"]\n            if ent.get(\"best_qid\"):\n                ent_kb_id = ent[\"best_qid\"]\n                try:  # to identify the type of entities\n                    t = ent[\"tags\"][0][\"types\"]\n                    types = {\n                        \"PERSON\": t[\"Q5\"] + t[\"P496\"],\n                        \"ORG\": t[\"Q43229\"] + t[\"P2427\"],\n                        \"LOC\": t[\"Q618123\"] + t[\"P1566\"],\n                    }\n                    m = max(types.values())\n                    etype = \"\".join([k for k, v in types.items() if v == m])\n                except Exception as e:\n                    log.error(e, extra=ent)\n                    etype = \"\"\n                span = doc.char_span(start, end, etype, ent_kb_id)\n            else:\n                etype, ent_kb_id = \"\", \"\"\n                span = doc.char_span(start, end, etype)\n            if not span:\n                span = doc.char_span(start, end, etype, ent_kb_id, alignment_mode=\"expand\")\n                log.warning(\n                    'The OpenTapioca-entity \"%s\" %s does not fit the span \"%s\" %s in spaCy. EXPANDED!',\n                    ent[\"tags\"][0][\"label\"][0],\n                    (start, end),\n                    span.text,\n                    (span.start_char, span.end_char),\n                )\n            span._.annotations = ent\n            span._.description = ent[\"tags\"][0][\"desc\"]\n            span._.aliases = ent[\"tags\"][0][\"aliases\"]\n            span._.rank = ent[\"tags\"][0][\"rank\"]\n            span._.score = ent[\"tags\"][0][\"score\"]\n            span._.types = ent[\"tags\"][0][\"types\"]\n            span._.label = ent[\"tags\"][0][\"label\"]\n            span._.extra_aliases = ent[\"tags\"][0][\"extra_aliases\"]\n            span._.nb_sitelinks = ent[\"tags\"][0][\"nb_sitelinks\"]\n            span._.nb_statements = ent[\"tags\"][0][\"nb_statements\"]\n            ents.append(span)\n\n        # Attach processed entities to doc.ents\n        try:\n            # this works with non-overlapping spans\n            doc.ents = list(doc.ents) + ents\n        except Exception:\n            # filter the overlapping spans, keep the (first) longest one\n            doc.ents = spacy.util.filter_spans(ents)\n        # Attach all entities found by OpenTapioca to spans\n        doc.spans[\"all_entities_opentapioca\"] = ents\n        return doc\n\n    def make_request(self, doc: Doc):\n        return requests.post(url=self.url, data={\"query\": doc.text}, headers={\"User-Agent\": \"spaCyOpenTapioca\"})\n\n    def __call__(self, doc):\n        \"\"\"Requests the OpenTapioca API. Attaches entities to spans and doc.\"\"\"\n\n        # Post request to the OpenTapioca API\n        r = self.make_request(doc)\n\n        return self.process_single_doc_after_call(doc, r)\n\n    def pipe(self, stream, batch_size=128):\n        \"\"\"\n        It takes a stream of documents, and for each batch of documents, it makes a request to the API\n        for each document in the batch, and then yields the processed results of each document\n\n        :param stream: the stream of documents to be processed\n        :param batch_size: The number of documents to send to the API in a single request, defaults to\n        128 (optional)\n        \"\"\"\n        for docs in util.minibatch(stream, size=batch_size):\n            with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n                future_to_url = {executor.submit(self.make_request, doc): doc for doc in docs}\n                for future in concurrent.futures.as_completed(future_to_url):\n                    doc = future_to_url[future]\n                    yield self.process_single_doc_after_call(doc, future.result())\n</code></pre>"},{"location":"#ceurws.services.opentapioca.EntityLinker.__call__","title":"<code>__call__(doc)</code>","text":"<p>Requests the OpenTapioca API. Attaches entities to spans and doc.</p> Source code in <code>ceurws/services/opentapioca.py</code> <pre><code>def __call__(self, doc):\n    \"\"\"Requests the OpenTapioca API. Attaches entities to spans and doc.\"\"\"\n\n    # Post request to the OpenTapioca API\n    r = self.make_request(doc)\n\n    return self.process_single_doc_after_call(doc, r)\n</code></pre>"},{"location":"#ceurws.services.opentapioca.EntityLinker.__init__","title":"<code>__init__(nlp, name, url)</code>","text":"<p>Passes url. Registers OpenTapioca extensions for Doc and Span.</p> Source code in <code>ceurws/services/opentapioca.py</code> <pre><code>def __init__(self, nlp, name, url):\n    \"\"\"Passes url. Registers OpenTapioca extensions for Doc and Span.\"\"\"\n    self.url = url\n    Doc.set_extension(\"annotations\", default=None, force=True)\n    Doc.set_extension(\"metadata\", default=None, force=True)\n    Span.set_extension(\"annotations\", default=None, force=True)\n    Span.set_extension(\"description\", default=None, force=True)\n    Span.set_extension(\"aliases\", default=None, force=True)\n    Span.set_extension(\"rank\", default=None, force=True)\n    Span.set_extension(\"score\", default=None, force=True)\n    Span.set_extension(\"types\", default=None, force=True)\n    Span.set_extension(\"label\", default=None, force=True)\n    Span.set_extension(\"extra_aliases\", default=None, force=True)\n    Span.set_extension(\"nb_sitelinks\", default=None, force=True)\n    Span.set_extension(\"nb_statements\", default=None, force=True)\n</code></pre>"},{"location":"#ceurws.services.opentapioca.EntityLinker.pipe","title":"<code>pipe(stream, batch_size=128)</code>","text":"<p>It takes a stream of documents, and for each batch of documents, it makes a request to the API for each document in the batch, and then yields the processed results of each document</p> <p>:param stream: the stream of documents to be processed :param batch_size: The number of documents to send to the API in a single request, defaults to 128 (optional)</p> Source code in <code>ceurws/services/opentapioca.py</code> <pre><code>def pipe(self, stream, batch_size=128):\n    \"\"\"\n    It takes a stream of documents, and for each batch of documents, it makes a request to the API\n    for each document in the batch, and then yields the processed results of each document\n\n    :param stream: the stream of documents to be processed\n    :param batch_size: The number of documents to send to the API in a single request, defaults to\n    128 (optional)\n    \"\"\"\n    for docs in util.minibatch(stream, size=batch_size):\n        with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n            future_to_url = {executor.submit(self.make_request, doc): doc for doc in docs}\n            for future in concurrent.futures.as_completed(future_to_url):\n                doc = future_to_url[future]\n                yield self.process_single_doc_after_call(doc, future.result())\n</code></pre>"},{"location":"#ceurws.sql_cache","title":"<code>sql_cache</code>","text":"<p>Created on 2024-03-16 @author: wf</p>"},{"location":"#ceurws.sql_cache.Cached","title":"<code>Cached</code>","text":"<p>Manage cached entities.</p> Source code in <code>ceurws/sql_cache.py</code> <pre><code>class Cached:\n    \"\"\"\n    Manage cached entities.\n    \"\"\"\n\n    def __init__(\n        self, clazz: type[Any], sparql: SPARQL, sql_db: SqlDB, query_name: str, max_errors: int = 0, debug: bool = False\n    ):\n        \"\"\"\n        Initializes the Manager with class reference, SPARQL endpoint URL, SQL database connection string,\n        query name, and an optional debug flag.\n        Args:\n            clazz (type[Any]): The class reference for the type of objects managed by this manager.\n            sparql (SPARQL): a SPARQL endpoint.\n            sql_db (SqlDB): SQL database object\n            query_name (str): The name of the query to be executed.\n            debug (bool, optional): Flag to enable debug mode. Defaults to False.\n        \"\"\"\n        self.clazz = clazz\n        self.sparql = sparql\n        self.sql_db = sql_db\n        self.query_name = query_name\n        self.max_errors = max_errors\n        self.debug = debug\n        self.entities: list[object] = []\n        self.errors: list[Exception] = []\n        # Ensure the table for the class exists\n        clazz.metadata.create_all(self.sql_db.engine)\n\n    def fetch_or_query(self, qm, force_query=False):\n        \"\"\"\n        Fetches data from the local cache if available.\n        If the data is not in the cache or if force_query is True,\n        it queries via SPARQL and caches the results.\n\n        Args:\n            qm (QueryManager): The query manager object used for making SPARQL queries.\n            force_query (bool, optional): A flag to force querying via SPARQL even\n                if the data exists in the local cache. Defaults to False.\n        \"\"\"\n        if not force_query and self.check_local_cache():\n            self.fetch_from_local()\n        else:\n            self.get_lod(qm)\n            self.store()\n\n    def check_local_cache(self) -&gt; bool:\n        \"\"\"\n        Checks if there is data in the local cache (SQL database).\n\n        Returns:\n            bool: True if  there is at least one record in the local SQL cache table\n        \"\"\"\n        with self.sql_db.get_session() as session:\n            result = session.exec(select(self.clazz)).first()\n            return result is not None\n\n    def fetch_from_local(self):\n        \"\"\"\n        Fetches data from the local SQL database.\n        \"\"\"\n        profiler = Profiler(f\"fetch {self.query_name} from local\", profile=self.debug)\n        with self.sql_db.get_session() as session:\n            self.entities = session.exec(select(self.clazz)).all()\n            self.lod = [entity.dict() for entity in self.entities]\n            if self.debug:\n                print(f\"Loaded {len(self.entities)} records from local cache\")\n        profiler.time()\n\n    def get_lod(self, qm: QueryManager) -&gt; list[dict]:\n        \"\"\"\n        Fetches data using the SPARQL query specified by my query_name.\n\n        Args:\n            qm (QueryManager): The query manager object used for making SPARQL queries.\n        Returns:\n            list[dict]: A list of dictionaries representing the data fetched.\n        \"\"\"\n        profiler = Profiler(f\"fetch {self.query_name} from SPARQL endpoint {self.sparql.url}\", profile=self.debug)\n        query = qm.queriesByName[self.query_name]\n        self.lod = self.sparql.queryAsListOfDicts(query.query)\n        profiler.time()\n        if self.debug:\n            print(f\"Found {len(self.lod)} records for {self.query_name}\")\n        return self.lod\n\n    def to_entities(self, max_errors: int | None = None) -&gt; list[Any]:\n        \"\"\"\n        Converts records fetched from the LOD into entity instances, applying validation.\n        Args:\n            max_errors (int, optional): Maximum allowed validation errors. Defaults to 0.\n        Returns:\n            list[Any]: A list of entity instances that have passed validation.\n        \"\"\"\n        self.entities = []\n        self.errors = []\n        error_records = []\n        if max_errors is None:\n            max_errors = self.max_errors\n        for record in self.lod:\n            try:\n                entity = self.clazz.model_validate(record)\n                self.entities.append(entity)\n            except Exception as e:\n                self.errors.append(e)\n                error_records.append(record)\n        error_count = len(self.errors)\n        if error_count &gt; max_errors:\n            msg = f\"found {error_count} errors &gt; maximum allowed {max_errors} errors\"\n            if self.debug:\n                print(msg)\n                for i, error in enumerate(self.errors):\n                    print(f\"{i}:{error} for \\n{error_records[i]}\")\n            raise Exception(msg)\n        return self.entities\n\n    def store(self, max_errors: int | None = None) -&gt; list[Any]:\n        \"\"\"\n        Stores the fetched data into the local SQL database.\n\n        Args:\n            max_errors (int, optional): Maximum allowed validation errors. Defaults to 0.\n        Returns:\n            list[Any]: A list of entity instances that were stored in the database.\n\n        \"\"\"\n        profiler = Profiler(f\"store {self.query_name}\", profile=self.debug)\n        self.to_entities(max_errors=max_errors)\n        with self.sql_db.get_session() as session:\n            session.add_all(self.entities)\n            session.commit()\n            if self.debug:\n                print(f\"Stored {len(self.entities)} records in local cache\")\n        profiler.time()\n        return self.entities\n</code></pre>"},{"location":"#ceurws.sql_cache.Cached.__init__","title":"<code>__init__(clazz, sparql, sql_db, query_name, max_errors=0, debug=False)</code>","text":"<p>Initializes the Manager with class reference, SPARQL endpoint URL, SQL database connection string, query name, and an optional debug flag. Args:     clazz (type[Any]): The class reference for the type of objects managed by this manager.     sparql (SPARQL): a SPARQL endpoint.     sql_db (SqlDB): SQL database object     query_name (str): The name of the query to be executed.     debug (bool, optional): Flag to enable debug mode. Defaults to False.</p> Source code in <code>ceurws/sql_cache.py</code> <pre><code>def __init__(\n    self, clazz: type[Any], sparql: SPARQL, sql_db: SqlDB, query_name: str, max_errors: int = 0, debug: bool = False\n):\n    \"\"\"\n    Initializes the Manager with class reference, SPARQL endpoint URL, SQL database connection string,\n    query name, and an optional debug flag.\n    Args:\n        clazz (type[Any]): The class reference for the type of objects managed by this manager.\n        sparql (SPARQL): a SPARQL endpoint.\n        sql_db (SqlDB): SQL database object\n        query_name (str): The name of the query to be executed.\n        debug (bool, optional): Flag to enable debug mode. Defaults to False.\n    \"\"\"\n    self.clazz = clazz\n    self.sparql = sparql\n    self.sql_db = sql_db\n    self.query_name = query_name\n    self.max_errors = max_errors\n    self.debug = debug\n    self.entities: list[object] = []\n    self.errors: list[Exception] = []\n    # Ensure the table for the class exists\n    clazz.metadata.create_all(self.sql_db.engine)\n</code></pre>"},{"location":"#ceurws.sql_cache.Cached.check_local_cache","title":"<code>check_local_cache()</code>","text":"<p>Checks if there is data in the local cache (SQL database).</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if  there is at least one record in the local SQL cache table</p> Source code in <code>ceurws/sql_cache.py</code> <pre><code>def check_local_cache(self) -&gt; bool:\n    \"\"\"\n    Checks if there is data in the local cache (SQL database).\n\n    Returns:\n        bool: True if  there is at least one record in the local SQL cache table\n    \"\"\"\n    with self.sql_db.get_session() as session:\n        result = session.exec(select(self.clazz)).first()\n        return result is not None\n</code></pre>"},{"location":"#ceurws.sql_cache.Cached.fetch_from_local","title":"<code>fetch_from_local()</code>","text":"<p>Fetches data from the local SQL database.</p> Source code in <code>ceurws/sql_cache.py</code> <pre><code>def fetch_from_local(self):\n    \"\"\"\n    Fetches data from the local SQL database.\n    \"\"\"\n    profiler = Profiler(f\"fetch {self.query_name} from local\", profile=self.debug)\n    with self.sql_db.get_session() as session:\n        self.entities = session.exec(select(self.clazz)).all()\n        self.lod = [entity.dict() for entity in self.entities]\n        if self.debug:\n            print(f\"Loaded {len(self.entities)} records from local cache\")\n    profiler.time()\n</code></pre>"},{"location":"#ceurws.sql_cache.Cached.fetch_or_query","title":"<code>fetch_or_query(qm, force_query=False)</code>","text":"<p>Fetches data from the local cache if available. If the data is not in the cache or if force_query is True, it queries via SPARQL and caches the results.</p> <p>Parameters:</p> Name Type Description Default <code>qm</code> <code>QueryManager</code> <p>The query manager object used for making SPARQL queries.</p> required <code>force_query</code> <code>bool</code> <p>A flag to force querying via SPARQL even if the data exists in the local cache. Defaults to False.</p> <code>False</code> Source code in <code>ceurws/sql_cache.py</code> <pre><code>def fetch_or_query(self, qm, force_query=False):\n    \"\"\"\n    Fetches data from the local cache if available.\n    If the data is not in the cache or if force_query is True,\n    it queries via SPARQL and caches the results.\n\n    Args:\n        qm (QueryManager): The query manager object used for making SPARQL queries.\n        force_query (bool, optional): A flag to force querying via SPARQL even\n            if the data exists in the local cache. Defaults to False.\n    \"\"\"\n    if not force_query and self.check_local_cache():\n        self.fetch_from_local()\n    else:\n        self.get_lod(qm)\n        self.store()\n</code></pre>"},{"location":"#ceurws.sql_cache.Cached.get_lod","title":"<code>get_lod(qm)</code>","text":"<p>Fetches data using the SPARQL query specified by my query_name.</p> <p>Parameters:</p> Name Type Description Default <code>qm</code> <code>QueryManager</code> <p>The query manager object used for making SPARQL queries.</p> required <p>Returns:     list[dict]: A list of dictionaries representing the data fetched.</p> Source code in <code>ceurws/sql_cache.py</code> <pre><code>def get_lod(self, qm: QueryManager) -&gt; list[dict]:\n    \"\"\"\n    Fetches data using the SPARQL query specified by my query_name.\n\n    Args:\n        qm (QueryManager): The query manager object used for making SPARQL queries.\n    Returns:\n        list[dict]: A list of dictionaries representing the data fetched.\n    \"\"\"\n    profiler = Profiler(f\"fetch {self.query_name} from SPARQL endpoint {self.sparql.url}\", profile=self.debug)\n    query = qm.queriesByName[self.query_name]\n    self.lod = self.sparql.queryAsListOfDicts(query.query)\n    profiler.time()\n    if self.debug:\n        print(f\"Found {len(self.lod)} records for {self.query_name}\")\n    return self.lod\n</code></pre>"},{"location":"#ceurws.sql_cache.Cached.store","title":"<code>store(max_errors=None)</code>","text":"<p>Stores the fetched data into the local SQL database.</p> <p>Parameters:</p> Name Type Description Default <code>max_errors</code> <code>int</code> <p>Maximum allowed validation errors. Defaults to 0.</p> <code>None</code> <p>Returns:     list[Any]: A list of entity instances that were stored in the database.</p> Source code in <code>ceurws/sql_cache.py</code> <pre><code>def store(self, max_errors: int | None = None) -&gt; list[Any]:\n    \"\"\"\n    Stores the fetched data into the local SQL database.\n\n    Args:\n        max_errors (int, optional): Maximum allowed validation errors. Defaults to 0.\n    Returns:\n        list[Any]: A list of entity instances that were stored in the database.\n\n    \"\"\"\n    profiler = Profiler(f\"store {self.query_name}\", profile=self.debug)\n    self.to_entities(max_errors=max_errors)\n    with self.sql_db.get_session() as session:\n        session.add_all(self.entities)\n        session.commit()\n        if self.debug:\n            print(f\"Stored {len(self.entities)} records in local cache\")\n    profiler.time()\n    return self.entities\n</code></pre>"},{"location":"#ceurws.sql_cache.Cached.to_entities","title":"<code>to_entities(max_errors=None)</code>","text":"<p>Converts records fetched from the LOD into entity instances, applying validation. Args:     max_errors (int, optional): Maximum allowed validation errors. Defaults to 0. Returns:     list[Any]: A list of entity instances that have passed validation.</p> Source code in <code>ceurws/sql_cache.py</code> <pre><code>def to_entities(self, max_errors: int | None = None) -&gt; list[Any]:\n    \"\"\"\n    Converts records fetched from the LOD into entity instances, applying validation.\n    Args:\n        max_errors (int, optional): Maximum allowed validation errors. Defaults to 0.\n    Returns:\n        list[Any]: A list of entity instances that have passed validation.\n    \"\"\"\n    self.entities = []\n    self.errors = []\n    error_records = []\n    if max_errors is None:\n        max_errors = self.max_errors\n    for record in self.lod:\n        try:\n            entity = self.clazz.model_validate(record)\n            self.entities.append(entity)\n        except Exception as e:\n            self.errors.append(e)\n            error_records.append(record)\n    error_count = len(self.errors)\n    if error_count &gt; max_errors:\n        msg = f\"found {error_count} errors &gt; maximum allowed {max_errors} errors\"\n        if self.debug:\n            print(msg)\n            for i, error in enumerate(self.errors):\n                print(f\"{i}:{error} for \\n{error_records[i]}\")\n        raise Exception(msg)\n    return self.entities\n</code></pre>"},{"location":"#ceurws.sql_cache.SqlDB","title":"<code>SqlDB</code>","text":"<p>general SQL database</p> Source code in <code>ceurws/sql_cache.py</code> <pre><code>class SqlDB:\n    \"\"\"\n    general SQL database\n    \"\"\"\n\n    def __init__(self, sqlite_file_path: str, debug: bool = False):\n        debug = debug\n        sqlite_url = f\"sqlite:///{sqlite_file_path}\"\n        connect_args = {\"check_same_thread\": False}\n        self.engine = create_engine(sqlite_url, echo=debug, connect_args=connect_args)\n\n    def get_session(self) -&gt; Session:\n        \"\"\"\n        Provide a session for database operations.\n\n        Returns:\n            Session: A SQLAlchemy Session object bound to the engine for database operations.\n        \"\"\"\n        return Session(bind=self.engine)\n</code></pre>"},{"location":"#ceurws.sql_cache.SqlDB.get_session","title":"<code>get_session()</code>","text":"<p>Provide a session for database operations.</p> <p>Returns:</p> Name Type Description <code>Session</code> <code>Session</code> <p>A SQLAlchemy Session object bound to the engine for database operations.</p> Source code in <code>ceurws/sql_cache.py</code> <pre><code>def get_session(self) -&gt; Session:\n    \"\"\"\n    Provide a session for database operations.\n\n    Returns:\n        Session: A SQLAlchemy Session object bound to the engine for database operations.\n    \"\"\"\n    return Session(bind=self.engine)\n</code></pre>"},{"location":"#ceurws.textparser","title":"<code>textparser</code>","text":"<p>Created on 2022-08-15</p> <p>@author: wf</p>"},{"location":"#ceurws.textparser.Textparser","title":"<code>Textparser</code>","text":"<p>general text parser</p> Source code in <code>ceurws/textparser.py</code> <pre><code>class Textparser:\n    \"\"\"\n    general text parser\n    \"\"\"\n\n    def __init__(self, debug: bool):\n        \"\"\"\n        Constructor\n\n        Args:\n            debug(bool): if TRUE switch debugging on\n        \"\"\"\n        self.debug = debug\n\n    @classmethod\n    def sanitize(cls, text, replaceList=None) -&gt; str:\n        \"\"\"\n        sanitize given text\n\n        Args:\n            text: text to sanitize\n            replaceList: list of strings to remove from the given text\n\n        Returns:\n            str: sanitized string\n        \"\"\"\n        if replaceList is None:\n            replaceList = []\n        if text is not None:\n            sanitizeChars = \"\\n\\t\\r., \"\n            text = text.strip(sanitizeChars)\n            text = text.replace(\"\\n\", \" \")\n            text = text.replace(\"\\r\", \"\")\n            for replace in replaceList:\n                text = text.replace(replace, \"\")\n            # compress multiple spaces\n            text = \" \".join(text.split())\n        return text\n\n    def log(self, msg: str):\n        \"\"\"\n        log the given message if debug is on\n\n        Args:\n            msg(str): the message to log\n        \"\"\"\n        if self.debug:\n            print(msg)\n\n    def hasValue(self, d, key):\n        \"\"\"\n        check that the given attribute in the given dict is available and not none\n\n        Args:\n            d(dict): the dict\n            key(str): the key\n\n        Returns:\n            True: if a not None Value is available\n        \"\"\"\n        result = key in d and d[key] is not None\n        return result\n\n    def getMatch(self, pattern, text, groupNo: int = 1):\n        \"\"\"\n        get the match for the given regular expression for the given text returning the given group number\n\n        Args:\n            regexp(str): the regular expression to check\n            text(str): the text to check\n            groupNo(int): the number of the regular expression group to return\n\n        Returns:\n            str: the matching result or None if no match was found\n        \"\"\"\n        matchResult = pattern.match(text)\n        if matchResult:\n            return matchResult.group(groupNo)\n        else:\n            return None\n</code></pre>"},{"location":"#ceurws.textparser.Textparser.__init__","title":"<code>__init__(debug)</code>","text":"<p>Constructor</p> <p>Parameters:</p> Name Type Description Default <code>debug(bool)</code> <p>if TRUE switch debugging on</p> required Source code in <code>ceurws/textparser.py</code> <pre><code>def __init__(self, debug: bool):\n    \"\"\"\n    Constructor\n\n    Args:\n        debug(bool): if TRUE switch debugging on\n    \"\"\"\n    self.debug = debug\n</code></pre>"},{"location":"#ceurws.textparser.Textparser.getMatch","title":"<code>getMatch(pattern, text, groupNo=1)</code>","text":"<p>get the match for the given regular expression for the given text returning the given group number</p> <p>Parameters:</p> Name Type Description Default <code>regexp(str)</code> <p>the regular expression to check</p> required <code>text(str)</code> <p>the text to check</p> required <code>groupNo(int)</code> <p>the number of the regular expression group to return</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>the matching result or None if no match was found</p> Source code in <code>ceurws/textparser.py</code> <pre><code>def getMatch(self, pattern, text, groupNo: int = 1):\n    \"\"\"\n    get the match for the given regular expression for the given text returning the given group number\n\n    Args:\n        regexp(str): the regular expression to check\n        text(str): the text to check\n        groupNo(int): the number of the regular expression group to return\n\n    Returns:\n        str: the matching result or None if no match was found\n    \"\"\"\n    matchResult = pattern.match(text)\n    if matchResult:\n        return matchResult.group(groupNo)\n    else:\n        return None\n</code></pre>"},{"location":"#ceurws.textparser.Textparser.hasValue","title":"<code>hasValue(d, key)</code>","text":"<p>check that the given attribute in the given dict is available and not none</p> <p>Parameters:</p> Name Type Description Default <code>d(dict)</code> <p>the dict</p> required <code>key(str)</code> <p>the key</p> required <p>Returns:</p> Name Type Description <code>True</code> <p>if a not None Value is available</p> Source code in <code>ceurws/textparser.py</code> <pre><code>def hasValue(self, d, key):\n    \"\"\"\n    check that the given attribute in the given dict is available and not none\n\n    Args:\n        d(dict): the dict\n        key(str): the key\n\n    Returns:\n        True: if a not None Value is available\n    \"\"\"\n    result = key in d and d[key] is not None\n    return result\n</code></pre>"},{"location":"#ceurws.textparser.Textparser.log","title":"<code>log(msg)</code>","text":"<p>log the given message if debug is on</p> <p>Parameters:</p> Name Type Description Default <code>msg(str)</code> <p>the message to log</p> required Source code in <code>ceurws/textparser.py</code> <pre><code>def log(self, msg: str):\n    \"\"\"\n    log the given message if debug is on\n\n    Args:\n        msg(str): the message to log\n    \"\"\"\n    if self.debug:\n        print(msg)\n</code></pre>"},{"location":"#ceurws.textparser.Textparser.sanitize","title":"<code>sanitize(text, replaceList=None)</code>  <code>classmethod</code>","text":"<p>sanitize given text</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>text to sanitize</p> required <code>replaceList</code> <p>list of strings to remove from the given text</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>sanitized string</p> Source code in <code>ceurws/textparser.py</code> <pre><code>@classmethod\ndef sanitize(cls, text, replaceList=None) -&gt; str:\n    \"\"\"\n    sanitize given text\n\n    Args:\n        text: text to sanitize\n        replaceList: list of strings to remove from the given text\n\n    Returns:\n        str: sanitized string\n    \"\"\"\n    if replaceList is None:\n        replaceList = []\n    if text is not None:\n        sanitizeChars = \"\\n\\t\\r., \"\n        text = text.strip(sanitizeChars)\n        text = text.replace(\"\\n\", \" \")\n        text = text.replace(\"\\r\", \"\")\n        for replace in replaceList:\n            text = text.replace(replace, \"\")\n        # compress multiple spaces\n        text = \" \".join(text.split())\n    return text\n</code></pre>"},{"location":"#ceurws.urn","title":"<code>urn</code>","text":"<p>Created on 2023-12-28</p> <p>@author: wf / ChatGPT-4 as instructed</p> <p>Class URN is designed to verify and calculate check digits for URNs (Uniform Resource Names) as used in the DNB URN service. The class provides methods for both verifying a full URN's check digit (check_urn_checksum) and calculating the check digit for a given URN (calc_urn_checksum). It's adapted from PHP and JavaScript sources, following the guidelines and methods outlined by the DNB (German National Library) URN service.</p>"},{"location":"#ceurws.urn.URN","title":"<code>URN</code>","text":"<p>URN check digit calculator for DNB URN service:</p> <p>see https://www.dnb.de/DE/Professionell/Services/URN-Service/urn-service_node.html</p> <p>and     https://d-nb.info/1045320641/34     http://nbn-resolving.de/nbnpruefziffer.php</p> Source code in <code>ceurws/urn.py</code> <pre><code>class URN:\n    \"\"\"\n    URN check digit calculator for DNB URN service:\n\n    see https://www.dnb.de/DE/Professionell/Services/URN-Service/urn-service_node.html\n\n    and\n        https://d-nb.info/1045320641/34\n        http://nbn-resolving.de/nbnpruefziffer.php\n\n    \"\"\"\n\n    @classmethod\n    def check_urn_checksum(cls, urn: str, debug: bool = False) -&gt; bool:\n        urn_check_digit_str = urn[-1]\n        urn_prefix = urn[:-1]\n        check_digit = cls.calc_urn_checksum(urn_prefix, debug)\n        urn_ok = str(check_digit) == urn_check_digit_str\n        return urn_ok\n\n    @classmethod\n    def calc_urn_checksum(cls, test_urn: str, debug: bool = False) -&gt; int:\n        \"\"\"\n        converted from PHP and JavaScript code see\n        see https://github.com/bohnelang/URN-Pruefziffer\n\n        Args:\n            debug(bool) if True show the internal values while calculating\n        \"\"\"\n        # Code string provided in the original PHP function\n        code = \"3947450102030405060708094117############1814191516212223242542262713282931123233113435363738########43\"\n\n        # Initialization of variables\n        _sum = 0\n        pos = 1\n\n        # Iterating through each character in the URN\n        for i, char in enumerate(test_urn.upper()):\n            # Getting the ASCII value and adjusting it based on the character '-' (45 in ASCII)\n            x = ord(char) - 45\n            # Extracting two consecutive values from the code string\n            v1 = int(code[x * 2]) if code[x * 2] != \"#\" else 0\n            v2 = int(code[x * 2 + 1]) if code[x * 2 + 1] != \"#\" else 0\n\n            if v1 == 0:\n                # If v1 is 0, increment pos after multiplying v2 with its current value\n                _sum += v2 * pos\n                pos += 1  # post-increment equivalent in Python\n            else:\n                # If v1 is not 0, use pos for the first term, increment pos,\n                # then use the new value of pos for the second term\n                # This effectively increases pos by 2 in this branch\n                _sum += pos * v1\n                pos += 1  # increment for the first term\n                _sum += v2 * pos  # use incremented pos for the second term\n                pos += 1  # increment for the second term\n\n            if debug:\n                print(f\"i: {i:2} pos: {pos:2} x: {x:2} v1: {v1:2} v2: {v2:2} sum: {_sum:4}\")\n\n        # Assuming v2 is not 0 at the end of your URN calculations\n        check_digit = (_sum // v2) % 10  # Using integer division for floor behavior\n\n        return check_digit\n</code></pre>"},{"location":"#ceurws.urn.URN.calc_urn_checksum","title":"<code>calc_urn_checksum(test_urn, debug=False)</code>  <code>classmethod</code>","text":"<p>converted from PHP and JavaScript code see see https://github.com/bohnelang/URN-Pruefziffer</p> Source code in <code>ceurws/urn.py</code> <pre><code>@classmethod\ndef calc_urn_checksum(cls, test_urn: str, debug: bool = False) -&gt; int:\n    \"\"\"\n    converted from PHP and JavaScript code see\n    see https://github.com/bohnelang/URN-Pruefziffer\n\n    Args:\n        debug(bool) if True show the internal values while calculating\n    \"\"\"\n    # Code string provided in the original PHP function\n    code = \"3947450102030405060708094117############1814191516212223242542262713282931123233113435363738########43\"\n\n    # Initialization of variables\n    _sum = 0\n    pos = 1\n\n    # Iterating through each character in the URN\n    for i, char in enumerate(test_urn.upper()):\n        # Getting the ASCII value and adjusting it based on the character '-' (45 in ASCII)\n        x = ord(char) - 45\n        # Extracting two consecutive values from the code string\n        v1 = int(code[x * 2]) if code[x * 2] != \"#\" else 0\n        v2 = int(code[x * 2 + 1]) if code[x * 2 + 1] != \"#\" else 0\n\n        if v1 == 0:\n            # If v1 is 0, increment pos after multiplying v2 with its current value\n            _sum += v2 * pos\n            pos += 1  # post-increment equivalent in Python\n        else:\n            # If v1 is not 0, use pos for the first term, increment pos,\n            # then use the new value of pos for the second term\n            # This effectively increases pos by 2 in this branch\n            _sum += pos * v1\n            pos += 1  # increment for the first term\n            _sum += v2 * pos  # use incremented pos for the second term\n            pos += 1  # increment for the second term\n\n        if debug:\n            print(f\"i: {i:2} pos: {pos:2} x: {x:2} v1: {v1:2} v2: {v2:2} sum: {_sum:4}\")\n\n    # Assuming v2 is not 0 at the end of your URN calculations\n    check_digit = (_sum // v2) % 10  # Using integer division for floor behavior\n\n    return check_digit\n</code></pre>"},{"location":"#ceurws.utils","title":"<code>utils</code>","text":""},{"location":"#ceurws.utils.download","title":"<code>download</code>","text":"<p>Created on 2021-08-21</p> <p>this is a redundant copy see e.g. https://github.com/WolfgangFahl/ConferenceCorpus/blob/main/corpus/utils/download.py</p> <p>@author: wf</p>"},{"location":"#ceurws.utils.download.Download","title":"<code>Download</code>","text":"<p>Utility functions for downloading data</p> Source code in <code>ceurws/utils/download.py</code> <pre><code>class Download:\n    \"\"\"\n    Utility functions for downloading data\n    \"\"\"\n\n    @staticmethod\n    def getURLContent(url: str):\n        with urllib.request.urlopen(url) as urlResponse:\n            content = urlResponse.read().decode()\n            return content\n\n    @staticmethod\n    def getFileContent(path: str):\n        with open(path) as file:\n            content = file.read()\n            return content\n\n    @staticmethod\n    def needsDownload(filePath: Path, force: bool = False) -&gt; bool:\n        \"\"\"\n        check if a download of the given filePath is necessary that is the file\n        does not exist has a size of zero or the download should be forced\n\n        Args:\n            filePath(str): the path of the file to be checked\n            force(bool): True if the result should be forced to True\n\n        Return:\n            bool: True if  a download for this file needed\n        \"\"\"\n        if not filePath.is_file():\n            result = True\n        else:\n            stats = filePath.stat()\n            size = stats.st_size\n            result = force or size == 0\n        return result\n\n    @staticmethod\n    def downloadBackupFile(\n        url: str,\n        fileName: str,\n        targetDirectory: Path,\n        force: bool = False,\n        profile: bool = True,\n    ):\n        \"\"\"\n        Downloads from the given url the zip-file and extracts the file corresponding to the given fileName.\n\n        Args:\n            url: url linking to a downloadable gzip file\n            fileName: Name of the file that should be extracted from gzip file\n            targetDirectory(str): download the file to this directory\n            force (bool): True if the download should be forced\n            profile(bool): if True show profiling information\n\n        Returns:\n            Name of the extracted file with path to the backup directory\n        \"\"\"\n        extractTo = targetDirectory.joinpath(fileName)\n        zipped = targetDirectory.joinpath(f\"{fileName}.gz\")\n        # we might want to check whether a new version is available\n        if Download.needsDownload(extractTo, force=force):\n            if not targetDirectory.is_dir():\n                targetDirectory.parent.mkdir(parents=True, exist_ok=True)\n            msg = f\"Downloading {zipped} from {url} ... this might take a few seconds ...\"\n            profiler = Profiler(msg=msg, profile=profile)\n            urllib.request.urlretrieve(url, zipped)\n            profiler.time(extraMsg=f\" unzipping {extractTo} from {zipped}\")\n            with gzip.open(zipped, \"rb\") as gzipped, open(extractTo, \"wb\") as unzipped:\n                shutil.copyfileobj(gzipped, unzipped)\n            if not extractTo.is_file():\n                raise Exception(f\"could not extract {fileName} from {zipped}\")\n        return extractTo\n</code></pre>"},{"location":"#ceurws.utils.download.Download.downloadBackupFile","title":"<code>downloadBackupFile(url, fileName, targetDirectory, force=False, profile=True)</code>  <code>staticmethod</code>","text":"<p>Downloads from the given url the zip-file and extracts the file corresponding to the given fileName.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>url linking to a downloadable gzip file</p> required <code>fileName</code> <code>str</code> <p>Name of the file that should be extracted from gzip file</p> required <code>targetDirectory(str)</code> <p>download the file to this directory</p> required <code>force</code> <code>bool</code> <p>True if the download should be forced</p> <code>False</code> <code>profile(bool)</code> <p>if True show profiling information</p> required <p>Returns:</p> Type Description <p>Name of the extracted file with path to the backup directory</p> Source code in <code>ceurws/utils/download.py</code> <pre><code>@staticmethod\ndef downloadBackupFile(\n    url: str,\n    fileName: str,\n    targetDirectory: Path,\n    force: bool = False,\n    profile: bool = True,\n):\n    \"\"\"\n    Downloads from the given url the zip-file and extracts the file corresponding to the given fileName.\n\n    Args:\n        url: url linking to a downloadable gzip file\n        fileName: Name of the file that should be extracted from gzip file\n        targetDirectory(str): download the file to this directory\n        force (bool): True if the download should be forced\n        profile(bool): if True show profiling information\n\n    Returns:\n        Name of the extracted file with path to the backup directory\n    \"\"\"\n    extractTo = targetDirectory.joinpath(fileName)\n    zipped = targetDirectory.joinpath(f\"{fileName}.gz\")\n    # we might want to check whether a new version is available\n    if Download.needsDownload(extractTo, force=force):\n        if not targetDirectory.is_dir():\n            targetDirectory.parent.mkdir(parents=True, exist_ok=True)\n        msg = f\"Downloading {zipped} from {url} ... this might take a few seconds ...\"\n        profiler = Profiler(msg=msg, profile=profile)\n        urllib.request.urlretrieve(url, zipped)\n        profiler.time(extraMsg=f\" unzipping {extractTo} from {zipped}\")\n        with gzip.open(zipped, \"rb\") as gzipped, open(extractTo, \"wb\") as unzipped:\n            shutil.copyfileobj(gzipped, unzipped)\n        if not extractTo.is_file():\n            raise Exception(f\"could not extract {fileName} from {zipped}\")\n    return extractTo\n</code></pre>"},{"location":"#ceurws.utils.download.Download.needsDownload","title":"<code>needsDownload(filePath, force=False)</code>  <code>staticmethod</code>","text":"<p>check if a download of the given filePath is necessary that is the file does not exist has a size of zero or the download should be forced</p> <p>Parameters:</p> Name Type Description Default <code>filePath(str)</code> <p>the path of the file to be checked</p> required <code>force(bool)</code> <p>True if the result should be forced to True</p> required Return <p>bool: True if  a download for this file needed</p> Source code in <code>ceurws/utils/download.py</code> <pre><code>@staticmethod\ndef needsDownload(filePath: Path, force: bool = False) -&gt; bool:\n    \"\"\"\n    check if a download of the given filePath is necessary that is the file\n    does not exist has a size of zero or the download should be forced\n\n    Args:\n        filePath(str): the path of the file to be checked\n        force(bool): True if the result should be forced to True\n\n    Return:\n        bool: True if  a download for this file needed\n    \"\"\"\n    if not filePath.is_file():\n        result = True\n    else:\n        stats = filePath.stat()\n        size = stats.st_size\n        result = force or size == 0\n    return result\n</code></pre>"},{"location":"#ceurws.utils.download.Profiler","title":"<code>Profiler</code>","text":"<p>simple profiler</p> Source code in <code>ceurws/utils/download.py</code> <pre><code>class Profiler:\n    \"\"\"\n    simple profiler\n    \"\"\"\n\n    def __init__(self, msg: str | None = None, profile: bool = True):\n        \"\"\"\n        construct me with the given msg and profile active flag\n\n        Args:\n            msg(str): the message to show if profiling is active\n            profile(bool): True if messages should be shown\n        \"\"\"\n        if msg is not None:\n            self.msg = msg\n        else:\n            self.msg = \"\"\n        self.profile = profile\n        self.starttime = time.time()\n        if profile:\n            print(f\"Starting {msg} ...\")\n\n    def time(self, extraMsg=\"\"):\n        \"\"\"\n        time the action and print if profile is active\n        \"\"\"\n        elapsed = time.time() - self.starttime\n        if self.profile:\n            print(f\"{self.msg}{extraMsg} took {elapsed:5.1f} s\")\n        return elapsed\n</code></pre>"},{"location":"#ceurws.utils.download.Profiler.__init__","title":"<code>__init__(msg=None, profile=True)</code>","text":"<p>construct me with the given msg and profile active flag</p> <p>Parameters:</p> Name Type Description Default <code>msg(str)</code> <p>the message to show if profiling is active</p> required <code>profile(bool)</code> <p>True if messages should be shown</p> required Source code in <code>ceurws/utils/download.py</code> <pre><code>def __init__(self, msg: str | None = None, profile: bool = True):\n    \"\"\"\n    construct me with the given msg and profile active flag\n\n    Args:\n        msg(str): the message to show if profiling is active\n        profile(bool): True if messages should be shown\n    \"\"\"\n    if msg is not None:\n        self.msg = msg\n    else:\n        self.msg = \"\"\n    self.profile = profile\n    self.starttime = time.time()\n    if profile:\n        print(f\"Starting {msg} ...\")\n</code></pre>"},{"location":"#ceurws.utils.download.Profiler.time","title":"<code>time(extraMsg='')</code>","text":"<p>time the action and print if profile is active</p> Source code in <code>ceurws/utils/download.py</code> <pre><code>def time(self, extraMsg=\"\"):\n    \"\"\"\n    time the action and print if profile is active\n    \"\"\"\n    elapsed = time.time() - self.starttime\n    if self.profile:\n        print(f\"{self.msg}{extraMsg} took {elapsed:5.1f} s\")\n    return elapsed\n</code></pre>"},{"location":"#ceurws.utils.webscrape","title":"<code>webscrape</code>","text":"<p>Created on 2020-08-20</p> <p>@author: wf</p> <p>this is a redundant copy of the sources at https://github.com/WolfgangFahl/ConferenceCorpus/blob/main/corpus/datasources/webscrape.py</p>"},{"location":"#ceurws.utils.webscrape.ScrapeDescription","title":"<code>ScrapeDescription</code>  <code>dataclass</code>","text":"<p>Description of rdfa elements to scrape</p> Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>@dataclass\nclass ScrapeDescription:\n    \"\"\"\n    Description of rdfa elements to scrape\n    \"\"\"\n\n    key: str\n    tag: str  # the tag to search\n    attribute: str  # the attribute to expect\n    value: str  # the value to expect\n    multi: bool = False  # do we expect multiple elements?\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape","title":"<code>WebScrape</code>","text":"<p>WebScraper with a rudimentary Parser for https://en.wikipedia.org/wiki/RDFa extended for CEUR-WS and WikiCFP specific scraping</p> <p>https://stackoverflow.com/questions/21876602/what-does-the-html-typeof-attribute-do https://de.wikipedia.org/wiki/RDFa https://stackoverflow.com/questions/20767903/parsing-rdfa-in-html-xhtml https://www.w3.org/MarkUp/2009/rdfa-for-html-authors</p> Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>class WebScrape:\n    \"\"\"\n    WebScraper\n    with a rudimentary Parser for https://en.wikipedia.org/wiki/RDFa\n    extended for CEUR-WS and WikiCFP specific scraping\n\n    https://stackoverflow.com/questions/21876602/what-does-the-html-typeof-attribute-do\n    https://de.wikipedia.org/wiki/RDFa\n    https://stackoverflow.com/questions/20767903/parsing-rdfa-in-html-xhtml\n    https://www.w3.org/MarkUp/2009/rdfa-for-html-authors\n    \"\"\"\n\n    def __init__(\n        self,\n        debug: bool = False,\n        showHtml: bool = False,\n        timeout: float = 20,\n        agent: str = \"Mozilla/5.0\",\n    ):\n        \"\"\"\n        Constructor\n\n        Args:\n            debug(bool): if True show debugging information\n            showHtml(bool): if True show the HTML retrieved\n            timeout(float): the default timeout\n            agent(str): the agent to mimic\n        \"\"\"\n        self.err: Exception | None = None\n        self.valid = False\n        self.debug = debug\n        self.showHtml = showHtml\n        self.timeout = timeout\n        self.agent = agent\n\n    def findLinkForRegexp(self, regex: str):\n        \"\"\"\n        find a link for the given regular expression\n\n        Args:\n            regex(str): the regular expression to find a link for\n\n        Return:\n            m(object),text(str): the match/text tuple or None,None\n        \"\"\"\n        m = None\n        text = None\n        link = self.soup.find(\"a\", href=re.compile(regex))\n        if link:\n            href = link[\"href\"]\n            m = re.match(regex, href)\n            if hasattr(link, \"text\"):\n                text = link.text\n        return m, text\n\n    def fromTag(\n        self,\n        soup: BeautifulSoup,\n        tag: str,\n        attr: str | None = None,\n        value: str | None = None,\n        multi: bool = False,\n    ):\n        \"\"\"\n        get metadata from a given tag, attribute and value\n        e.g. &lt;span class=\"CEURVOLACRONYM\"&gt;DL4KG2020&lt;/span&gt;\n\n        tag=span, attr=class, value=CEURVOLACRONYM\n\n        Args:\n           soup(BeautifulSoup): the parser to work with\n           tag(string): the tag to search\n           attr(string): the attribute to expect\n           value(string): the value to expect\n           multi(bool): if True - return multiple values\n        \"\"\"\n        # https://stackoverflow.com/a/16248908/1497139\n        # find a list of all tag elements\n        if attr is not None and value is not None:\n            nodes = soup.find_all(tag, {attr: value})\n        else:\n            nodes = soup.find_all(tag)\n        lines = [node.get_text() for node in nodes]\n        if multi:\n            return lines\n        if len(lines) &gt; 0:\n            return lines[0]\n        else:\n            return None\n\n    def getSoup(self, url: str, showHtml: bool = False, debug: bool = False) -&gt; BeautifulSoup | None:\n        \"\"\"\n        get the beautiful Soup parser\n\n        Args:\n           url(str): the url to open\n           showHtml(bool): if True  the html code should be pretty printed and shown\n           debug(bool): if True debug info should be printed\n        Return:\n            BeautifulSoup: the html parser\n        \"\"\"\n        html = self.get_html_from_url(url, debug=debug)\n        soup = self.get_soup_from_string(html, show_html=showHtml) if html is not None else None\n        return soup\n\n    def get_soup_from_string(self, html: str | bytes, show_html: bool = False) -&gt; BeautifulSoup:\n        \"\"\"\n        get the beautiful Soup parser for the given html string\n\n        Args:\n            html: html content to parse\n            show_html: True if the html code should be pretty printed and shown\n\n        Returns:\n            BeautifulSoup: the html parser\n        \"\"\"\n        soup = BeautifulSoup(html, \"html.parser\")\n        if show_html:\n            self.printPrettyHtml(soup)\n        return soup\n\n    def printPrettyHtml(self, soup):\n        \"\"\"\n        print the prettified html for the given soup\n\n        Args:\n            soup(BeuatifulSoup): the parsed html to print\n        \"\"\"\n        prettyHtml = soup.prettify()\n        print(prettyHtml)\n\n    def parseWithScrapeDescription(\n        self,\n        soup: BeautifulSoup,\n        scrapeDescr: list[\"ScrapeDescription\"] | None = None,\n    ) -&gt; dict:\n        \"\"\"\n        parse the given url with the given encoding\n        Args:\n            soup: html parser to parse the content from\n            scrapeDescr: description of the\n\n        Return:\n             a dict with the results\n        \"\"\"\n        scrapeDict = dict()\n        if isinstance(scrapeDescr, list):\n            for scrapeItem in scrapeDescr:\n                value = self.fromTag(\n                    soup,\n                    scrapeItem.tag,\n                    scrapeItem.attribute,\n                    scrapeItem.value,\n                    multi=scrapeItem.multi,\n                )\n                scrapeDict[scrapeItem.key] = value\n        self.valid = True\n        return scrapeDict\n\n    def parseRDFa(self, url):\n        \"\"\"\n        rudimentary RDFa parsing\n        \"\"\"\n        triples = []\n        try:\n            self.soup = self.getSoup(url, self.showHtml)\n            subjectNodes = self.soup.find_all(True, {\"typeof\": True})\n            for subjectNode in subjectNodes:\n                subject = subjectNode.attrs[\"typeof\"]\n                if self.debug:\n                    print(subjectNode)\n                for predicateNode in subjectNode.find_all():\n                    value = None\n                    name = None\n                    if \"content\" in predicateNode.attrs:\n                        value = predicateNode.attrs[\"content\"]\n                    else:\n                        value = predicateNode.get_text()\n                    if \"property\" in predicateNode.attrs:\n                        name = predicateNode.attrs[\"property\"]\n                    if name is not None and value is not None:\n                        triples.append((subject, name, value))\n            self.valid = True\n        except HTTPError as herr:\n            self.err = herr\n        except urllib.error.URLError as terr:\n            self.err = terr\n        return triples\n\n    def get_html_from_url(self, url: str, debug: bool = False) -&gt; str | bytes | None:\n        \"\"\"\n        Get the html response from the given url\n        Args:\n            url: url to the get the content from\n            debug(bool): if True show non available volumes\n\n        Returns:\n            str: content of the url as string\n            bytes: If the content of the url contains encoding errors\n            None: If the url is not reachable\n        \"\"\"\n        req = urllib.request.Request(url, headers={\"User-Agent\": f\"{self.agent}\"})\n        # handle cookies\n        opener = build_opener(HTTPCookieProcessor())\n        try:\n            response = opener.open(req, timeout=self.timeout)\n        except HTTPError as herr:\n            self.err = herr\n            if debug:\n                print(f\"{url.split('/')[-1]} not available\")\n            return None\n        html = response.read()\n        try:\n            html = html.decode(response.headers.get_content_charset())\n        except UnicodeDecodeError as ex:\n            print(f\"ERROR: Could not properly decode the html code of &lt;{url}&gt;\")\n            print(ex)\n        return html\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape.__init__","title":"<code>__init__(debug=False, showHtml=False, timeout=20, agent='Mozilla/5.0')</code>","text":"<p>Constructor</p> <p>Parameters:</p> Name Type Description Default <code>debug(bool)</code> <p>if True show debugging information</p> required <code>showHtml(bool)</code> <p>if True show the HTML retrieved</p> required <code>timeout(float)</code> <p>the default timeout</p> required <code>agent(str)</code> <p>the agent to mimic</p> required Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>def __init__(\n    self,\n    debug: bool = False,\n    showHtml: bool = False,\n    timeout: float = 20,\n    agent: str = \"Mozilla/5.0\",\n):\n    \"\"\"\n    Constructor\n\n    Args:\n        debug(bool): if True show debugging information\n        showHtml(bool): if True show the HTML retrieved\n        timeout(float): the default timeout\n        agent(str): the agent to mimic\n    \"\"\"\n    self.err: Exception | None = None\n    self.valid = False\n    self.debug = debug\n    self.showHtml = showHtml\n    self.timeout = timeout\n    self.agent = agent\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape.findLinkForRegexp","title":"<code>findLinkForRegexp(regex)</code>","text":"<p>find a link for the given regular expression</p> <p>Parameters:</p> Name Type Description Default <code>regex(str)</code> <p>the regular expression to find a link for</p> required Return <p>m(object),text(str): the match/text tuple or None,None</p> Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>def findLinkForRegexp(self, regex: str):\n    \"\"\"\n    find a link for the given regular expression\n\n    Args:\n        regex(str): the regular expression to find a link for\n\n    Return:\n        m(object),text(str): the match/text tuple or None,None\n    \"\"\"\n    m = None\n    text = None\n    link = self.soup.find(\"a\", href=re.compile(regex))\n    if link:\n        href = link[\"href\"]\n        m = re.match(regex, href)\n        if hasattr(link, \"text\"):\n            text = link.text\n    return m, text\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape.fromTag","title":"<code>fromTag(soup, tag, attr=None, value=None, multi=False)</code>","text":"<p>get metadata from a given tag, attribute and value e.g. DL4KG2020</p> <p>tag=span, attr=class, value=CEURVOLACRONYM</p> <p>Parameters:</p> Name Type Description Default <code>soup(BeautifulSoup)</code> <p>the parser to work with</p> required <code>tag(string)</code> <p>the tag to search</p> required <code>attr(string)</code> <p>the attribute to expect</p> required <code>value(string)</code> <p>the value to expect</p> required <code>multi(bool)</code> <p>if True - return multiple values</p> required Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>def fromTag(\n    self,\n    soup: BeautifulSoup,\n    tag: str,\n    attr: str | None = None,\n    value: str | None = None,\n    multi: bool = False,\n):\n    \"\"\"\n    get metadata from a given tag, attribute and value\n    e.g. &lt;span class=\"CEURVOLACRONYM\"&gt;DL4KG2020&lt;/span&gt;\n\n    tag=span, attr=class, value=CEURVOLACRONYM\n\n    Args:\n       soup(BeautifulSoup): the parser to work with\n       tag(string): the tag to search\n       attr(string): the attribute to expect\n       value(string): the value to expect\n       multi(bool): if True - return multiple values\n    \"\"\"\n    # https://stackoverflow.com/a/16248908/1497139\n    # find a list of all tag elements\n    if attr is not None and value is not None:\n        nodes = soup.find_all(tag, {attr: value})\n    else:\n        nodes = soup.find_all(tag)\n    lines = [node.get_text() for node in nodes]\n    if multi:\n        return lines\n    if len(lines) &gt; 0:\n        return lines[0]\n    else:\n        return None\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape.getSoup","title":"<code>getSoup(url, showHtml=False, debug=False)</code>","text":"<p>get the beautiful Soup parser</p> <p>Parameters:</p> Name Type Description Default <code>url(str)</code> <p>the url to open</p> required <code>showHtml(bool)</code> <p>if True  the html code should be pretty printed and shown</p> required <code>debug(bool)</code> <p>if True debug info should be printed</p> required <p>Return:     BeautifulSoup: the html parser</p> Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>def getSoup(self, url: str, showHtml: bool = False, debug: bool = False) -&gt; BeautifulSoup | None:\n    \"\"\"\n    get the beautiful Soup parser\n\n    Args:\n       url(str): the url to open\n       showHtml(bool): if True  the html code should be pretty printed and shown\n       debug(bool): if True debug info should be printed\n    Return:\n        BeautifulSoup: the html parser\n    \"\"\"\n    html = self.get_html_from_url(url, debug=debug)\n    soup = self.get_soup_from_string(html, show_html=showHtml) if html is not None else None\n    return soup\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape.get_html_from_url","title":"<code>get_html_from_url(url, debug=False)</code>","text":"<p>Get the html response from the given url Args:     url: url to the get the content from     debug(bool): if True show non available volumes</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str | bytes | None</code> <p>content of the url as string</p> <code>bytes</code> <code>str | bytes | None</code> <p>If the content of the url contains encoding errors</p> <code>None</code> <code>str | bytes | None</code> <p>If the url is not reachable</p> Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>def get_html_from_url(self, url: str, debug: bool = False) -&gt; str | bytes | None:\n    \"\"\"\n    Get the html response from the given url\n    Args:\n        url: url to the get the content from\n        debug(bool): if True show non available volumes\n\n    Returns:\n        str: content of the url as string\n        bytes: If the content of the url contains encoding errors\n        None: If the url is not reachable\n    \"\"\"\n    req = urllib.request.Request(url, headers={\"User-Agent\": f\"{self.agent}\"})\n    # handle cookies\n    opener = build_opener(HTTPCookieProcessor())\n    try:\n        response = opener.open(req, timeout=self.timeout)\n    except HTTPError as herr:\n        self.err = herr\n        if debug:\n            print(f\"{url.split('/')[-1]} not available\")\n        return None\n    html = response.read()\n    try:\n        html = html.decode(response.headers.get_content_charset())\n    except UnicodeDecodeError as ex:\n        print(f\"ERROR: Could not properly decode the html code of &lt;{url}&gt;\")\n        print(ex)\n    return html\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape.get_soup_from_string","title":"<code>get_soup_from_string(html, show_html=False)</code>","text":"<p>get the beautiful Soup parser for the given html string</p> <p>Parameters:</p> Name Type Description Default <code>html</code> <code>str | bytes</code> <p>html content to parse</p> required <code>show_html</code> <code>bool</code> <p>True if the html code should be pretty printed and shown</p> <code>False</code> <p>Returns:</p> Name Type Description <code>BeautifulSoup</code> <code>BeautifulSoup</code> <p>the html parser</p> Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>def get_soup_from_string(self, html: str | bytes, show_html: bool = False) -&gt; BeautifulSoup:\n    \"\"\"\n    get the beautiful Soup parser for the given html string\n\n    Args:\n        html: html content to parse\n        show_html: True if the html code should be pretty printed and shown\n\n    Returns:\n        BeautifulSoup: the html parser\n    \"\"\"\n    soup = BeautifulSoup(html, \"html.parser\")\n    if show_html:\n        self.printPrettyHtml(soup)\n    return soup\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape.parseRDFa","title":"<code>parseRDFa(url)</code>","text":"<p>rudimentary RDFa parsing</p> Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>def parseRDFa(self, url):\n    \"\"\"\n    rudimentary RDFa parsing\n    \"\"\"\n    triples = []\n    try:\n        self.soup = self.getSoup(url, self.showHtml)\n        subjectNodes = self.soup.find_all(True, {\"typeof\": True})\n        for subjectNode in subjectNodes:\n            subject = subjectNode.attrs[\"typeof\"]\n            if self.debug:\n                print(subjectNode)\n            for predicateNode in subjectNode.find_all():\n                value = None\n                name = None\n                if \"content\" in predicateNode.attrs:\n                    value = predicateNode.attrs[\"content\"]\n                else:\n                    value = predicateNode.get_text()\n                if \"property\" in predicateNode.attrs:\n                    name = predicateNode.attrs[\"property\"]\n                if name is not None and value is not None:\n                    triples.append((subject, name, value))\n        self.valid = True\n    except HTTPError as herr:\n        self.err = herr\n    except urllib.error.URLError as terr:\n        self.err = terr\n    return triples\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape.parseWithScrapeDescription","title":"<code>parseWithScrapeDescription(soup, scrapeDescr=None)</code>","text":"<p>parse the given url with the given encoding Args:     soup: html parser to parse the content from     scrapeDescr: description of the</p> Return <p>a dict with the results</p> Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>def parseWithScrapeDescription(\n    self,\n    soup: BeautifulSoup,\n    scrapeDescr: list[\"ScrapeDescription\"] | None = None,\n) -&gt; dict:\n    \"\"\"\n    parse the given url with the given encoding\n    Args:\n        soup: html parser to parse the content from\n        scrapeDescr: description of the\n\n    Return:\n         a dict with the results\n    \"\"\"\n    scrapeDict = dict()\n    if isinstance(scrapeDescr, list):\n        for scrapeItem in scrapeDescr:\n            value = self.fromTag(\n                soup,\n                scrapeItem.tag,\n                scrapeItem.attribute,\n                scrapeItem.value,\n                multi=scrapeItem.multi,\n            )\n            scrapeDict[scrapeItem.key] = value\n    self.valid = True\n    return scrapeDict\n</code></pre>"},{"location":"#ceurws.utils.webscrape.WebScrape.printPrettyHtml","title":"<code>printPrettyHtml(soup)</code>","text":"<p>print the prettified html for the given soup</p> <p>Parameters:</p> Name Type Description Default <code>soup(BeuatifulSoup)</code> <p>the parsed html to print</p> required Source code in <code>ceurws/utils/webscrape.py</code> <pre><code>def printPrettyHtml(self, soup):\n    \"\"\"\n    print the prettified html for the given soup\n\n    Args:\n        soup(BeuatifulSoup): the parsed html to print\n    \"\"\"\n    prettyHtml = soup.prettify()\n    print(prettyHtml)\n</code></pre>"},{"location":"#ceurws.version","title":"<code>version</code>","text":"<p>Created on 2022-09-11</p> <p>@author: wf</p>"},{"location":"#ceurws.version.Version","title":"<code>Version</code>  <code>dataclass</code>","text":"<p>Version handling for VolumeBrowser</p> Source code in <code>ceurws/version.py</code> <pre><code>@dataclass\nclass Version:\n    \"\"\"\n    Version handling for VolumeBrowser\n    \"\"\"\n\n    name = \"CEUR-WS Volume Browser\"\n    version = ceurws.__version__\n    date = \"2022-08-14\"\n    updated = \"2024-06-11\"\n    description = \"CEUR-WS Volume browser\"\n\n    authors = \"Tim Holzheim, Wolfgang Fahl\"\n\n    doc_url = \"https://wiki.bitplan.com/index.php/pyCEURmake\"\n    chat_url = \"https://github.com/WolfgangFahl/pyCEURmake/discussions\"\n    cm_url = \"https://github.com/WolfgangFahl/pyCEURmake\"\n\n    license = \"\"\"Copyright 2022 contributors. All rights reserved.\n\n  Licensed under the Apache License 2.0\n  http://www.apache.org/licenses/LICENSE-2.0\n\n  Distributed on an \"AS IS\" basis without warranties\n  or conditions of any kind, either express or implied.\"\"\"\n    longDescription = f\"\"\"{name} version {version}\n{description}\n\n  Created by {authors} on {date} last updated {updated}\"\"\"\n</code></pre>"},{"location":"#ceurws.view","title":"<code>view</code>","text":"<p>Created on 2024-02-23</p> <p>@author: wf</p>"},{"location":"#ceurws.view.View","title":"<code>View</code>","text":"<p>generic View</p> Source code in <code>ceurws/view.py</code> <pre><code>class View:\n    \"\"\"\n    generic View\n    \"\"\"\n\n    noneValue = \"-\"\n    wdPrefix = \"http://www.wikidata.org/entity/\"\n\n    def getValue(self, obj, attr):\n        value = getattr(obj, attr, View.noneValue)\n        if value is None:\n            value = View.noneValue\n        return value\n\n    def getRowValue(self, row, key):\n        value = None\n        if key in row:\n            value = row[key]\n        if value is None:\n            value = View.noneValue\n        return value\n\n    def createLink(self, url: str, text: str):\n        \"\"\"\n        create a link from the given url and text\n\n        Args:\n            url(str): the url to create a link for\n            text(str): the text to add for the link\n        \"\"\"\n        link = Link.create(url, text, target=\"_blank\")\n        return link\n\n    def createWdLink(self, qid: str, text: str):\n        wd_url = f\"{View.wdPrefix}/{qid}\"\n        link = self.createLink(wd_url, text)\n        return link\n\n    def get_dict_as_html_table(self, data_dict) -&gt; str:\n        # Convert the dictionary to a list of lists for tabulate\n        data_list = [[key, value] for key, value in data_dict.items()]\n\n        # Generate the HTML table\n        html_table = tabulate(data_list, tablefmt=\"html\", headers=[\"Key\", \"Value\"])\n        return html_table\n\n    def createExternalLink(\n        self,\n        row: dict,\n        key: str,\n        text: str,\n        formatterUrl: str,\n        emptyIfNone: bool = False,\n    ) -&gt; str:\n        \"\"\"\n        create an ExternalLink for the given row entry with the given key, text and formatterUrl\n\n        Args:\n            row(dict): the row to extract the value from\n            key(str): the key\n            text(str): the text to display for the link\n            formatterUrl(str): the prefix for the url to use\n            emptyIfNone(bool): if True return empty string if value is Display.noneValue\n\n        Returns:\n            str - html link for external id\n        \"\"\"\n        value = self.getRowValue(row, key)\n        if not value or value == View.noneValue:\n            if emptyIfNone:\n                return \"\"\n            else:\n                return View.noneValue\n\n        if value.startswith(View.wdPrefix):\n            value = value.replace(View.wdPrefix, \"\")\n        url = formatterUrl + value\n        link = self.createLink(url, text)\n        return link\n\n    def createItemLink(self, row: dict, key: str, separator: str | None = None) -&gt; str:\n        \"\"\"\n        create an item link\n        Args:\n            row: row object with the data\n            key: key of the value for which the link is created\n            separator: If not None split the value on the separator and create multiple links\n        \"\"\"\n        value = self.getRowValue(row, key)\n        if value == View.noneValue:\n            return value\n        item = row[key]\n        itemLabel = row[f\"{key}Label\"]\n        itemLink = \"\"\n        if separator is not None:\n            item_parts = item.split(separator)\n            itemLabel_parts = itemLabel.split(separator)\n            links = []\n            for url, label in zip(item_parts, itemLabel_parts, strict=False):\n                link = self.createLink(url, label)\n                links.append(link)\n            itemLink = \"&lt;br&gt;\".join(links)\n        else:\n            itemLink = self.createLink(item, itemLabel)\n        return itemLink\n</code></pre>"},{"location":"#ceurws.view.View.createExternalLink","title":"<code>createExternalLink(row, key, text, formatterUrl, emptyIfNone=False)</code>","text":"<p>create an ExternalLink for the given row entry with the given key, text and formatterUrl</p> <p>Parameters:</p> Name Type Description Default <code>row(dict)</code> <p>the row to extract the value from</p> required <code>key(str)</code> <p>the key</p> required <code>text(str)</code> <p>the text to display for the link</p> required <code>formatterUrl(str)</code> <p>the prefix for the url to use</p> required <code>emptyIfNone(bool)</code> <p>if True return empty string if value is Display.noneValue</p> required <p>Returns:</p> Type Description <code>str</code> <p>str - html link for external id</p> Source code in <code>ceurws/view.py</code> <pre><code>def createExternalLink(\n    self,\n    row: dict,\n    key: str,\n    text: str,\n    formatterUrl: str,\n    emptyIfNone: bool = False,\n) -&gt; str:\n    \"\"\"\n    create an ExternalLink for the given row entry with the given key, text and formatterUrl\n\n    Args:\n        row(dict): the row to extract the value from\n        key(str): the key\n        text(str): the text to display for the link\n        formatterUrl(str): the prefix for the url to use\n        emptyIfNone(bool): if True return empty string if value is Display.noneValue\n\n    Returns:\n        str - html link for external id\n    \"\"\"\n    value = self.getRowValue(row, key)\n    if not value or value == View.noneValue:\n        if emptyIfNone:\n            return \"\"\n        else:\n            return View.noneValue\n\n    if value.startswith(View.wdPrefix):\n        value = value.replace(View.wdPrefix, \"\")\n    url = formatterUrl + value\n    link = self.createLink(url, text)\n    return link\n</code></pre>"},{"location":"#ceurws.view.View.createItemLink","title":"<code>createItemLink(row, key, separator=None)</code>","text":"<p>create an item link Args:     row: row object with the data     key: key of the value for which the link is created     separator: If not None split the value on the separator and create multiple links</p> Source code in <code>ceurws/view.py</code> <pre><code>def createItemLink(self, row: dict, key: str, separator: str | None = None) -&gt; str:\n    \"\"\"\n    create an item link\n    Args:\n        row: row object with the data\n        key: key of the value for which the link is created\n        separator: If not None split the value on the separator and create multiple links\n    \"\"\"\n    value = self.getRowValue(row, key)\n    if value == View.noneValue:\n        return value\n    item = row[key]\n    itemLabel = row[f\"{key}Label\"]\n    itemLink = \"\"\n    if separator is not None:\n        item_parts = item.split(separator)\n        itemLabel_parts = itemLabel.split(separator)\n        links = []\n        for url, label in zip(item_parts, itemLabel_parts, strict=False):\n            link = self.createLink(url, label)\n            links.append(link)\n        itemLink = \"&lt;br&gt;\".join(links)\n    else:\n        itemLink = self.createLink(item, itemLabel)\n    return itemLink\n</code></pre>"},{"location":"#ceurws.view.View.createLink","title":"<code>createLink(url, text)</code>","text":"<p>create a link from the given url and text</p> <p>Parameters:</p> Name Type Description Default <code>url(str)</code> <p>the url to create a link for</p> required <code>text(str)</code> <p>the text to add for the link</p> required Source code in <code>ceurws/view.py</code> <pre><code>def createLink(self, url: str, text: str):\n    \"\"\"\n    create a link from the given url and text\n\n    Args:\n        url(str): the url to create a link for\n        text(str): the text to add for the link\n    \"\"\"\n    link = Link.create(url, text, target=\"_blank\")\n    return link\n</code></pre>"},{"location":"#ceurws.volume_neo4j","title":"<code>volume_neo4j</code>","text":""},{"location":"#ceurws.volume_neo4j.Editor","title":"<code>Editor</code>  <code>dataclass</code>","text":"<p>Represents an editor with their name and ORCID.</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>@dataclass\nclass Editor:\n    \"\"\"\n    Represents an editor with their name and ORCID.\n    \"\"\"\n\n    name: str\n    orcid: str | None = None\n    likelihood: float | None = None\n\n    @classmethod\n    def from_json(cls, json_data):\n        \"\"\"\n        Create an Editor instance from JSON data.\n\n        Args:\n            json_data (dict): The JSON data representing the editor.\n\n        Returns:\n            Editor: The Editor instance created from the JSON data.\n        \"\"\"\n        return cls(name=json_data.get(\"name\"), orcid=json_data.get(\"orcid\"))\n\n    def search_by_name(self):\n        \"\"\"\n        Search the editor by name using the ORCID API and calculate the likelihood.\n        \"\"\"\n        if self.name:\n            url = f\"https://pub.orcid.org/v3.0/search/?q={self.name}\"\n            headers = {\"Accept\": \"application/json\"}\n            response = requests.get(url, headers=headers)\n            if response.status_code == 200:\n                data = response.json()\n                num_results = data.get(\"num-found\", 0)\n                self.likelihood = num_results / 10  # Arbitrary calculation, adjust as needed\n\n    def create_node(self, tx, volume_node_id: int) -&gt; int | None:\n        \"\"\"\n        Create an Editor node in Neo4j and establish a relationship with a Volume node.\n\n        Args:\n            tx: The Neo4j transaction.\n            volume_node_id (int): The ID of the volume node.\n\n        Returns:\n            int: The ID of the created Editor node.\n            None: if the editor could not be created\n        \"\"\"\n        query = \"\"\"\n        MATCH (v:Volume)\n        WHERE id(v) = $volume_node_id\n        CREATE (v)-[:HAS_EDITOR]-&gt;(e:Editor {name: $name, orcid: $orcid, likelihood: $likelihood})\n        RETURN id(e) as node_id\n        \"\"\"\n        parameters = {\n            \"volume_node_id\": volume_node_id,\n            \"name\": self.name,\n            \"orcid\": self.orcid,\n            \"likelihood\": self.likelihood,\n        }\n        result = tx.run(query, parameters)\n        record = result.single()\n        if record is not None:\n            return record[\"node_id\"]\n        else:\n            return None\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Editor.create_node","title":"<code>create_node(tx, volume_node_id)</code>","text":"<p>Create an Editor node in Neo4j and establish a relationship with a Volume node.</p> <p>Parameters:</p> Name Type Description Default <code>tx</code> <p>The Neo4j transaction.</p> required <code>volume_node_id</code> <code>int</code> <p>The ID of the volume node.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int | None</code> <p>The ID of the created Editor node.</p> <code>None</code> <code>int | None</code> <p>if the editor could not be created</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>def create_node(self, tx, volume_node_id: int) -&gt; int | None:\n    \"\"\"\n    Create an Editor node in Neo4j and establish a relationship with a Volume node.\n\n    Args:\n        tx: The Neo4j transaction.\n        volume_node_id (int): The ID of the volume node.\n\n    Returns:\n        int: The ID of the created Editor node.\n        None: if the editor could not be created\n    \"\"\"\n    query = \"\"\"\n    MATCH (v:Volume)\n    WHERE id(v) = $volume_node_id\n    CREATE (v)-[:HAS_EDITOR]-&gt;(e:Editor {name: $name, orcid: $orcid, likelihood: $likelihood})\n    RETURN id(e) as node_id\n    \"\"\"\n    parameters = {\n        \"volume_node_id\": volume_node_id,\n        \"name\": self.name,\n        \"orcid\": self.orcid,\n        \"likelihood\": self.likelihood,\n    }\n    result = tx.run(query, parameters)\n    record = result.single()\n    if record is not None:\n        return record[\"node_id\"]\n    else:\n        return None\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Editor.from_json","title":"<code>from_json(json_data)</code>  <code>classmethod</code>","text":"<p>Create an Editor instance from JSON data.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>dict</code> <p>The JSON data representing the editor.</p> required <p>Returns:</p> Name Type Description <code>Editor</code> <p>The Editor instance created from the JSON data.</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>@classmethod\ndef from_json(cls, json_data):\n    \"\"\"\n    Create an Editor instance from JSON data.\n\n    Args:\n        json_data (dict): The JSON data representing the editor.\n\n    Returns:\n        Editor: The Editor instance created from the JSON data.\n    \"\"\"\n    return cls(name=json_data.get(\"name\"), orcid=json_data.get(\"orcid\"))\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Editor.search_by_name","title":"<code>search_by_name()</code>","text":"<p>Search the editor by name using the ORCID API and calculate the likelihood.</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>def search_by_name(self):\n    \"\"\"\n    Search the editor by name using the ORCID API and calculate the likelihood.\n    \"\"\"\n    if self.name:\n        url = f\"https://pub.orcid.org/v3.0/search/?q={self.name}\"\n        headers = {\"Accept\": \"application/json\"}\n        response = requests.get(url, headers=headers)\n        if response.status_code == 200:\n            data = response.json()\n            num_results = data.get(\"num-found\", 0)\n            self.likelihood = num_results / 10  # Arbitrary calculation, adjust as needed\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Location","title":"<code>Location</code>  <code>dataclass</code>","text":"Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>@dataclass\nclass Location:\n    city: str\n    country: str\n    date: str\n\n    @staticmethod\n    def parse(location_str: str) -&gt; Optional[\"Location\"]:\n        \"\"\"\n        Parse a location string of the format \"City, Country, Date\"\n\n        Args:\n            location_str: The location string to parse.\n\n        Returns:\n            A Location object or None if the string could not be parsed.\n        \"\"\"\n        match = re.match(r\"^(.*), (.*), (.*)$\", location_str)\n        if match:\n            city, country, date = match.groups()\n            return Location(city, country, date)\n        else:\n            return None\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Location.parse","title":"<code>parse(location_str)</code>  <code>staticmethod</code>","text":"<p>Parse a location string of the format \"City, Country, Date\"</p> <p>Parameters:</p> Name Type Description Default <code>location_str</code> <code>str</code> <p>The location string to parse.</p> required <p>Returns:</p> Type Description <code>Optional[Location]</code> <p>A Location object or None if the string could not be parsed.</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>@staticmethod\ndef parse(location_str: str) -&gt; Optional[\"Location\"]:\n    \"\"\"\n    Parse a location string of the format \"City, Country, Date\"\n\n    Args:\n        location_str: The location string to parse.\n\n    Returns:\n        A Location object or None if the string could not be parsed.\n    \"\"\"\n    match = re.match(r\"^(.*), (.*), (.*)$\", location_str)\n    if match:\n        city, country, date = match.groups()\n        return Location(city, country, date)\n    else:\n        return None\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Neo4j","title":"<code>Neo4j</code>","text":"<p>Neo4j wrapper class</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>class Neo4j:\n    \"\"\"\n    Neo4j wrapper class\n    \"\"\"\n\n    def __init__(\n        self,\n        host: str = socket.gethostbyname(socket.gethostname()),\n        bolt_port: int = 7687,\n        auth=(\"neo4j\", \"password\"),\n        scheme: str = \"bolt\",\n        encrypted: bool = False,\n    ):\n        \"\"\"\n        constructor\n        \"\"\"\n        self.driver = None\n        self.error = None\n        self.host = host\n        self.bolt_port = bolt_port\n        self.encrypted = encrypted\n        self.scheme = scheme\n        try:\n            uri = f\"{scheme}://{host}:{bolt_port}\"\n            if not Neo4j.is_port_available(host, bolt_port):\n                raise ValueError(f\"port at {uri} not available\")\n            self.driver = GraphDatabase.driver(uri, auth=auth, encrypted=encrypted)\n        except (ServiceUnavailable, AuthError, ConfigurationError) as e:\n            self.error = e\n\n    @classmethod\n    def is_port_available(cls, host, port: int) -&gt; bool:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)  # 1 Second Timeout\n        try:\n            sock.connect((host, port))\n        except OSError:\n            return False\n        finally:\n            sock.close()\n        return True\n\n    def close(self):\n        if self.driver is not None:\n            self.driver.close()\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Neo4j.__init__","title":"<code>__init__(host=socket.gethostbyname(socket.gethostname()), bolt_port=7687, auth=('neo4j', 'password'), scheme='bolt', encrypted=False)</code>","text":"<p>constructor</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>def __init__(\n    self,\n    host: str = socket.gethostbyname(socket.gethostname()),\n    bolt_port: int = 7687,\n    auth=(\"neo4j\", \"password\"),\n    scheme: str = \"bolt\",\n    encrypted: bool = False,\n):\n    \"\"\"\n    constructor\n    \"\"\"\n    self.driver = None\n    self.error = None\n    self.host = host\n    self.bolt_port = bolt_port\n    self.encrypted = encrypted\n    self.scheme = scheme\n    try:\n        uri = f\"{scheme}://{host}:{bolt_port}\"\n        if not Neo4j.is_port_available(host, bolt_port):\n            raise ValueError(f\"port at {uri} not available\")\n        self.driver = GraphDatabase.driver(uri, auth=auth, encrypted=encrypted)\n    except (ServiceUnavailable, AuthError, ConfigurationError) as e:\n        self.error = e\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Volume","title":"<code>Volume</code>  <code>dataclass</code>","text":"<p>Represents a volume with its attributes.</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>@dataclass\nclass Volume:\n    \"\"\"\n    Represents a volume with its attributes.\n    \"\"\"\n\n    acronym: str\n    title: str\n    loctime: str\n    editors: list[\"Editor\"] = field(default_factory=list)\n\n    @classmethod\n    def from_json(cls, json_data):\n        \"\"\"\n        Create a Volume instance from JSON data.\n\n        Args:\n            json_data (dict): The JSON data representing the volume.\n\n        Returns:\n            Volume: The Volume instance created from the JSON data.\n        \"\"\"\n        editor_names = json_data.get(\"editors\")\n        editor_names = editor_names.split(\",\") if editor_names else []\n        editors = [Editor(name=name.strip()) for name in editor_names]\n        return cls(\n            acronym=json_data.get(\"acronym\"),\n            title=json_data.get(\"title\"),\n            loctime=json_data.get(\"loctime\"),\n            editors=editors,\n        )\n\n    def create_node(self, tx) -&gt; int | None:\n        \"\"\"\n        Create a Volume node in Neo4j.\n\n        Args:\n            tx: The Neo4j transaction.\n\n        Returns:\n            int: The ID of the created node.\n            None: if the node was not created\n        \"\"\"\n        query = \"\"\"\n        CREATE (v:Volume {acronym: $acronym, title: $title, loctime: $loctime})\n        RETURN id(v) as node_id\n        \"\"\"\n        parameters = {\n            \"acronym\": self.acronym,\n            \"title\": self.title,\n            \"loctime\": self.loctime,\n        }\n        result = tx.run(query, parameters)\n        record = result.single()\n        if record is not None:\n            return record[\"node_id\"]\n        else:\n            return None\n\n    @staticmethod\n    def load_json_file(source: str) -&gt; list[\"Volume\"]:\n        \"\"\"\n        Load volumes from the source JSON file.\n\n        Args:\n            source (str): Path to the source JSON file.\n\n        Returns:\n            List[Volume]: The list of loaded volumes.\n        \"\"\"\n        with open(source) as file:\n            json_data = json.load(file)\n\n        volumes = [Volume.from_json(volume_data) for volume_data in json_data]\n        return volumes\n\n    @classmethod\n    def default_source(cls) -&gt; Path:\n        \"\"\"\n        get the default source\n        \"\"\"\n        default_source = CEURWS.CACHE_DIR / \"volumes.json\"\n        return default_source\n\n    @classmethod\n    def parse_args(cls, argv: list | None = None):\n        \"\"\"\n        Parse command line arguments.\n\n        Args:\n            argv(list): command line arguments\n\n        Returns:\n            argparse.Namespace: The parsed command line arguments.\n        \"\"\"\n\n        default_source = cls.default_source()\n        parser = argparse.ArgumentParser(description=\"Volume/Editor/Location Information\")\n        parser.add_argument(\"--source\", default=str(default_source), help=\"Source JSON file path\")\n        # Add progress option\n        parser.add_argument(\n            \"--progress\",\n            action=\"store_true\",\n            help=\"Display progress information\",\n        )\n\n        return parser.parse_args(argv)\n\n    @staticmethod\n    def main(argv=None):\n        if argv is None:\n            argv = sys.argv[1:]\n        args = Volume.parse_args(argv)\n        volumes = Volume.load_json_file(args.source)\n\n        # Connect to Neo4j\n        driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n        with driver.session() as session:\n            for volume in volumes:\n                volume_node_id = volume.create_node(session)\n                for editor in volume.editors:\n                    editor.search_by_name()\n                    editor.create_node(session, volume_node_id)\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Volume.create_node","title":"<code>create_node(tx)</code>","text":"<p>Create a Volume node in Neo4j.</p> <p>Parameters:</p> Name Type Description Default <code>tx</code> <p>The Neo4j transaction.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int | None</code> <p>The ID of the created node.</p> <code>None</code> <code>int | None</code> <p>if the node was not created</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>def create_node(self, tx) -&gt; int | None:\n    \"\"\"\n    Create a Volume node in Neo4j.\n\n    Args:\n        tx: The Neo4j transaction.\n\n    Returns:\n        int: The ID of the created node.\n        None: if the node was not created\n    \"\"\"\n    query = \"\"\"\n    CREATE (v:Volume {acronym: $acronym, title: $title, loctime: $loctime})\n    RETURN id(v) as node_id\n    \"\"\"\n    parameters = {\n        \"acronym\": self.acronym,\n        \"title\": self.title,\n        \"loctime\": self.loctime,\n    }\n    result = tx.run(query, parameters)\n    record = result.single()\n    if record is not None:\n        return record[\"node_id\"]\n    else:\n        return None\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Volume.default_source","title":"<code>default_source()</code>  <code>classmethod</code>","text":"<p>get the default source</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>@classmethod\ndef default_source(cls) -&gt; Path:\n    \"\"\"\n    get the default source\n    \"\"\"\n    default_source = CEURWS.CACHE_DIR / \"volumes.json\"\n    return default_source\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Volume.from_json","title":"<code>from_json(json_data)</code>  <code>classmethod</code>","text":"<p>Create a Volume instance from JSON data.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>dict</code> <p>The JSON data representing the volume.</p> required <p>Returns:</p> Name Type Description <code>Volume</code> <p>The Volume instance created from the JSON data.</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>@classmethod\ndef from_json(cls, json_data):\n    \"\"\"\n    Create a Volume instance from JSON data.\n\n    Args:\n        json_data (dict): The JSON data representing the volume.\n\n    Returns:\n        Volume: The Volume instance created from the JSON data.\n    \"\"\"\n    editor_names = json_data.get(\"editors\")\n    editor_names = editor_names.split(\",\") if editor_names else []\n    editors = [Editor(name=name.strip()) for name in editor_names]\n    return cls(\n        acronym=json_data.get(\"acronym\"),\n        title=json_data.get(\"title\"),\n        loctime=json_data.get(\"loctime\"),\n        editors=editors,\n    )\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Volume.load_json_file","title":"<code>load_json_file(source)</code>  <code>staticmethod</code>","text":"<p>Load volumes from the source JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Path to the source JSON file.</p> required <p>Returns:</p> Type Description <code>list[Volume]</code> <p>List[Volume]: The list of loaded volumes.</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>@staticmethod\ndef load_json_file(source: str) -&gt; list[\"Volume\"]:\n    \"\"\"\n    Load volumes from the source JSON file.\n\n    Args:\n        source (str): Path to the source JSON file.\n\n    Returns:\n        List[Volume]: The list of loaded volumes.\n    \"\"\"\n    with open(source) as file:\n        json_data = json.load(file)\n\n    volumes = [Volume.from_json(volume_data) for volume_data in json_data]\n    return volumes\n</code></pre>"},{"location":"#ceurws.volume_neo4j.Volume.parse_args","title":"<code>parse_args(argv=None)</code>  <code>classmethod</code>","text":"<p>Parse command line arguments.</p> <p>Parameters:</p> Name Type Description Default <code>argv(list)</code> <p>command line arguments</p> required <p>Returns:</p> Type Description <p>argparse.Namespace: The parsed command line arguments.</p> Source code in <code>ceurws/volume_neo4j.py</code> <pre><code>@classmethod\ndef parse_args(cls, argv: list | None = None):\n    \"\"\"\n    Parse command line arguments.\n\n    Args:\n        argv(list): command line arguments\n\n    Returns:\n        argparse.Namespace: The parsed command line arguments.\n    \"\"\"\n\n    default_source = cls.default_source()\n    parser = argparse.ArgumentParser(description=\"Volume/Editor/Location Information\")\n    parser.add_argument(\"--source\", default=str(default_source), help=\"Source JSON file path\")\n    # Add progress option\n    parser.add_argument(\n        \"--progress\",\n        action=\"store_true\",\n        help=\"Display progress information\",\n    )\n\n    return parser.parse_args(argv)\n</code></pre>"},{"location":"#ceurws.volume_view","title":"<code>volume_view</code>","text":"<p>Created on 2024-02-23</p> <p>@author: wf</p>"},{"location":"#ceurws.volume_view.VolumeListView","title":"<code>VolumeListView</code>","text":"<p>               Bases: <code>View</code></p> <p>show a list of volumes a table</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>class VolumeListView(View):\n    \"\"\"\n    show a list of volumes a table\n    \"\"\"\n\n    def __init__(self, solution, parent):\n        \"\"\"\n        constructor\n\n        Args:\n            solution: the solution\n            parent: the parent UI container\n\n        \"\"\"\n        self.solution = solution\n        self.parent = parent\n        self.wdSync = self.solution.wdSync\n        self.dry_run = True\n        self.ignore_errors = False\n        self.get_volume_lod()\n        self.setup_ui()\n\n    def setup_ui(self):\n        \"\"\"\n        show my volumes as a list\n        \"\"\"\n        try:\n            with ui.row() as self.button_row:\n                self.check_recently_added_volumes_button = (\n                    ui.button(\n                        icon=\"cloud_download\",\n                        on_click=self.on_check_recently_update_volumes_button_click,\n                    )\n                    .classes(\"btn btn-primary btn-sm col-1\")\n                    .tooltip(\"check for recently added volumes\")\n                )\n                self.wikidataButton = (\n                    ui.button(\n                        icon=\"web\",\n                        on_click=self.onWikidataButtonClick,\n                    )\n                    .classes(\"btn btn-primary btn-sm col-1\")\n                    .tooltip(\"Export to Wikidata\")\n                )\n                self.dry_run_switch = ui.switch(\"dry run\").bind_value(self, \"dry_run\")\n                self.ignore_errors_check_box = ui.checkbox(\"ignore_errors\", value=self.ignore_errors).bind_value(\n                    self, \"ignore_errors\"\n                )\n                pass\n                self.progress_bar = NiceguiProgressbar(total=100, desc=\"added\", unit=\"volume\")\n            with ui.row() as self.log_row:\n                self.log_view = ui.html()\n            with ui.row() as self.grid_row:\n                grid_config = GridConfig(key_col=\"Vol\", multiselect=True)\n                self.lod_grid = ListOfDictsGrid(lod=self.lod, config=grid_config)\n                # Modify the columnDefs for the \"Title\" column after grid initialization\n                for col_def in self.lod_grid.ag_grid.options[\"columnDefs\"]:\n                    if col_def[\"field\"] == \"Title\":  # Identify the \"Title\" column\n                        col_def[\"maxWidth\"] = 400  # width in pixels\n                self.lod_grid.sizeColumnsToFit()\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n\n    def clear_msg(self, msg: str = \"\"):\n        \"\"\"\n        clear the log_view with the given message\n\n        Args:\n            msg(str): the message to display\n        \"\"\"\n        with self.log_row:\n            self.log_view.content = msg\n\n    def add_msg(self, html_markup: str):\n        \"\"\"\n        add the given html_markup message to the log_view\n\n        Args:\n            msg(str): the html formatted message to add\n        \"\"\"\n        with self.log_row:\n            self.log_view.content += html_markup\n\n    def updateWikidataVolumes(self, selected_rows):\n        \"\"\"\n        update wikidata volumes for the selected rows\n        \"\"\"\n        try:\n            msg = f\"{len(selected_rows)} Volumes selected&lt;br&gt;\"\n            self.clear_msg(msg)\n            # First, sort selected_rows by the volume number in ascending order\n            sorted_rows = sorted(selected_rows, key=lambda row: row[\"#\"])\n            for row in sorted_rows:\n                vol_number = row[\"#\"]\n                volume = self.wdSync.volumesByNumber[vol_number]\n                self.add_or_update_volume_in_wikidata(volume)\n            pass\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n\n    async def onWikidataButtonClick(self, _args):\n        \"\"\"\n        handle wikidata sync request\n        \"\"\"\n        selected_rows = await self.lod_grid.get_selected_rows()\n        await run.io_bound(self.updateWikidataVolumes, selected_rows)\n\n    def check_recently_updated_volumes(self):\n        \"\"\"\n        check recently updated volumes\n        \"\"\"\n        try:\n            text = \"checking CEUR-WS index.html for recently added volumes ...\"\n            self.clear_msg(text)\n            (\n                volumesByNumber,\n                addedVolumeNumberList,\n            ) = self.wdSync.getRecentlyAddedVolumeList()\n            self.add_msg(f\"&lt;br&gt;found {len(addedVolumeNumberList)} new volumes\")\n            total = len(addedVolumeNumberList)\n            self.progress_bar.total = total\n            for i, volumeNumber in enumerate(addedVolumeNumberList):\n                if i % 100 == 0 and i != 0:\n                    self.wdSync.storeVolumes()\n                    time.sleep(60)\n                volume = volumesByNumber[volumeNumber]\n                self.updateRecentlyAddedVolume(volume, i + 1, total)\n                url = f\"/volume/{volume.number}\"\n                text = f\"{volume}:{volume.acronym}\"\n                link = self.createLink(url, text)\n                self.add_msg(f\":{link}\")\n            pass\n            self.wdSync.storeVolumes()\n            with self.parent:\n                self.progress_bar.reset()\n            with self.grid_row:\n                self.lod_grid.update()\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n\n    async def on_check_recently_update_volumes_button_click(self, args):\n        \"\"\"\n        handle clicking of the refresh button to get recently added volumes\n        \"\"\"\n        await run.io_bound(self.check_recently_updated_volumes)\n\n    def updateRecentlyAddedVolume(self, volume, index, total):\n        \"\"\"\n        update a recently added Volume\n\n        Args:\n            volume(Volume): the volume to update\n            index(int): the relative index of the volume currently being added\n            total(int): the total number of volumes currently being added\n        \"\"\"\n        html_msg = f\"&lt;br&gt;reading {index}/{total} from {volume.url}\"\n        self.add_msg(html_msg)\n        volume.extractValuesFromVolumePage()\n        self.wdSync.addVolume(volume)\n        self.progress_bar.update_value(index)\n\n    def get_volume_lod(self):\n        \"\"\"\n        get the list of dict of all volumes\n        \"\"\"\n        self.lod = []\n        volumeList = self.wdSync.vm.getList()\n        reverseVolumeList = sorted(volumeList, key=lambda volume: volume.number, reverse=True)\n        for volume in reverseVolumeList:\n            validMark = \"\u2705\" if volume.valid else \"\u274c\"\n            self.lod.append(\n                {\n                    \"#\": volume.number,\n                    \"Vol\": self.createLink(volume.url, f\"Vol-{volume.number:04}\"),\n                    \"Acronym\": self.getValue(volume, \"acronym\"),\n                    \"Title\": self.getValue(volume, \"title\"),\n                    \"Loctime\": self.getValue(volume, \"loctime\"),\n                    \"Published\": self.getValue(volume, \"published\"),\n                    \"SubmittedBy\": self.getValue(volume, \"submittedBy\"),\n                    \"valid\": validMark,\n                }\n            )\n\n    def add_or_update_volume_in_wikidata(self, volume: Volume):\n        \"\"\"\n        add the given volume to wikidata or update it if it already exists\n\n        Args:\n            volume(Volume): the CEUR-WS volume to update proceedings and event entries for\n        \"\"\"\n        try:\n            msg = f\"trying to add Volume {volume.number} to wikidata\"\n            with self.parent:\n                ui.notify(msg)\n            self.add_msg(msg + \"&lt;br&gt;\")\n            proceedingsWikidataId = self.createProceedingsItemFromVolume(volume)\n            if proceedingsWikidataId is not None:\n                self.createEventItemAndLinkProceedings(volume, proceedingsWikidataId)\n            else:\n                msg = f\"&lt;br&gt;adding Volume {volume.number} proceedings to wikidata failed\"\n                self.add_msg(msg)\n                with self.parent:\n                    ui.notify(msg)\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n\n    def optional_login(self) -&gt; bool:\n        \"\"\"\n        check if we need to login\n\n        Returns:\n            bool: True if write is enabled\n        \"\"\"\n        write = not self.dry_run\n        if write:\n            self.wdSync.login()\n        return write\n\n    def createProceedingsItemFromVolume(self, volume: Volume):\n        \"\"\"\n        Create wikidata item for proceedings of given volume\n        \"\"\"\n        qId = None\n        try:\n            write = self.optional_login()\n            # check if already in wikidata \u2192 use URN\n            urn = volume.urn\n            wdItems = self.wdSync.getProceedingWdItemsByUrn(urn)\n            if len(wdItems) &gt; 0:\n                html = f\"Volume {volume.number} already in Wikidata see \"\n                delim = \"\"\n                for wdItem in wdItems:\n                    qId = wdItem.split(\"/\")[-1]\n                    link = self.createLink(wdItem, qId)\n                    html += f\"{link}{delim}\"\n                    delim = \",\"\n                self.add_msg(html + \"&lt;br&gt;\")\n            else:\n                # A proceedings volume for the URN is not known \u2192 create wd entry\n                wdRecord = self.wdSync.getWikidataProceedingsRecord(volume)\n                if self.dry_run:\n                    markup = self.get_dict_as_html_table(wdRecord)\n                    self.add_msg(markup)\n                result = self.wdSync.addProceedingsToWikidata(wdRecord, write=write, ignoreErrors=self.ignore_errors)\n                qId = result.qid\n                if qId is not None:\n                    proc_link = self.createWdLink(\n                        qId,\n                        f\"Proceedings entry for Vol {volume.number} {qId} was created\",\n                    )\n                    self.add_msg(proc_link)\n                else:\n                    self.add_msg(f\"Creating wikidata Proceedings entry for Vol {volume.number} failed\")\n                    for key, value in result.errors.items():\n                        msg = f\"{key}:{value}\"\n                        self.add_msg(msg)\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n        return qId\n\n    def createEventItemAndLinkProceedings(self, volume: Volume, proceedingsWikidataId: str | None = None):\n        \"\"\"\n        Create event  wikidata item for given volume and link\n        the proceedings with the event\n\n        Args:\n            volume(Volume): the volume for which to create the event item\n            proceedingsWikidataId: wikidata id of the proceedings\n        \"\"\"\n        try:\n            write = self.optional_login()\n            results = self.wdSync.doCreateEventItemAndLinkProceedings(volume, proceedingsWikidataId, write=write)\n            if write:\n                self.wdSync.logout()\n            for key, result in results.items():\n                if result.qid:\n                    if key == \"dblp\":\n                        url = f\"https://dblp.org/db/{result.qid}.html\"\n                        link = self.createLink(url, f\"dblp {result.qid}\")\n                    else:\n                        link = self.createWdLink(\n                            result.qid,\n                            f\"{key} for Vol {volume.number} {result.qid}\",\n                        )\n                    self.add_msg(\"&lt;br&gt;\" + link)\n                if result.msg:\n                    self.add_msg(\"&lt;br&gt;\" + result.msg)\n                if len(result.errors) &gt; 0:\n                    for error in result.errors.values():\n                        self.add_msg(f\"error {str(error)}\")\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n        pass\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.__init__","title":"<code>__init__(solution, parent)</code>","text":"<p>constructor</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <p>the solution</p> required <code>parent</code> <p>the parent UI container</p> required Source code in <code>ceurws/volume_view.py</code> <pre><code>def __init__(self, solution, parent):\n    \"\"\"\n    constructor\n\n    Args:\n        solution: the solution\n        parent: the parent UI container\n\n    \"\"\"\n    self.solution = solution\n    self.parent = parent\n    self.wdSync = self.solution.wdSync\n    self.dry_run = True\n    self.ignore_errors = False\n    self.get_volume_lod()\n    self.setup_ui()\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.add_msg","title":"<code>add_msg(html_markup)</code>","text":"<p>add the given html_markup message to the log_view</p> <p>Parameters:</p> Name Type Description Default <code>msg(str)</code> <p>the html formatted message to add</p> required Source code in <code>ceurws/volume_view.py</code> <pre><code>def add_msg(self, html_markup: str):\n    \"\"\"\n    add the given html_markup message to the log_view\n\n    Args:\n        msg(str): the html formatted message to add\n    \"\"\"\n    with self.log_row:\n        self.log_view.content += html_markup\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.add_or_update_volume_in_wikidata","title":"<code>add_or_update_volume_in_wikidata(volume)</code>","text":"<p>add the given volume to wikidata or update it if it already exists</p> <p>Parameters:</p> Name Type Description Default <code>volume(Volume)</code> <p>the CEUR-WS volume to update proceedings and event entries for</p> required Source code in <code>ceurws/volume_view.py</code> <pre><code>def add_or_update_volume_in_wikidata(self, volume: Volume):\n    \"\"\"\n    add the given volume to wikidata or update it if it already exists\n\n    Args:\n        volume(Volume): the CEUR-WS volume to update proceedings and event entries for\n    \"\"\"\n    try:\n        msg = f\"trying to add Volume {volume.number} to wikidata\"\n        with self.parent:\n            ui.notify(msg)\n        self.add_msg(msg + \"&lt;br&gt;\")\n        proceedingsWikidataId = self.createProceedingsItemFromVolume(volume)\n        if proceedingsWikidataId is not None:\n            self.createEventItemAndLinkProceedings(volume, proceedingsWikidataId)\n        else:\n            msg = f\"&lt;br&gt;adding Volume {volume.number} proceedings to wikidata failed\"\n            self.add_msg(msg)\n            with self.parent:\n                ui.notify(msg)\n    except Exception as ex:\n        self.solution.handle_exception(ex)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.check_recently_updated_volumes","title":"<code>check_recently_updated_volumes()</code>","text":"<p>check recently updated volumes</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>def check_recently_updated_volumes(self):\n    \"\"\"\n    check recently updated volumes\n    \"\"\"\n    try:\n        text = \"checking CEUR-WS index.html for recently added volumes ...\"\n        self.clear_msg(text)\n        (\n            volumesByNumber,\n            addedVolumeNumberList,\n        ) = self.wdSync.getRecentlyAddedVolumeList()\n        self.add_msg(f\"&lt;br&gt;found {len(addedVolumeNumberList)} new volumes\")\n        total = len(addedVolumeNumberList)\n        self.progress_bar.total = total\n        for i, volumeNumber in enumerate(addedVolumeNumberList):\n            if i % 100 == 0 and i != 0:\n                self.wdSync.storeVolumes()\n                time.sleep(60)\n            volume = volumesByNumber[volumeNumber]\n            self.updateRecentlyAddedVolume(volume, i + 1, total)\n            url = f\"/volume/{volume.number}\"\n            text = f\"{volume}:{volume.acronym}\"\n            link = self.createLink(url, text)\n            self.add_msg(f\":{link}\")\n        pass\n        self.wdSync.storeVolumes()\n        with self.parent:\n            self.progress_bar.reset()\n        with self.grid_row:\n            self.lod_grid.update()\n    except Exception as ex:\n        self.solution.handle_exception(ex)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.clear_msg","title":"<code>clear_msg(msg='')</code>","text":"<p>clear the log_view with the given message</p> <p>Parameters:</p> Name Type Description Default <code>msg(str)</code> <p>the message to display</p> required Source code in <code>ceurws/volume_view.py</code> <pre><code>def clear_msg(self, msg: str = \"\"):\n    \"\"\"\n    clear the log_view with the given message\n\n    Args:\n        msg(str): the message to display\n    \"\"\"\n    with self.log_row:\n        self.log_view.content = msg\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.createEventItemAndLinkProceedings","title":"<code>createEventItemAndLinkProceedings(volume, proceedingsWikidataId=None)</code>","text":"<p>Create event  wikidata item for given volume and link the proceedings with the event</p> <p>Parameters:</p> Name Type Description Default <code>volume(Volume)</code> <p>the volume for which to create the event item</p> required <code>proceedingsWikidataId</code> <code>str | None</code> <p>wikidata id of the proceedings</p> <code>None</code> Source code in <code>ceurws/volume_view.py</code> <pre><code>def createEventItemAndLinkProceedings(self, volume: Volume, proceedingsWikidataId: str | None = None):\n    \"\"\"\n    Create event  wikidata item for given volume and link\n    the proceedings with the event\n\n    Args:\n        volume(Volume): the volume for which to create the event item\n        proceedingsWikidataId: wikidata id of the proceedings\n    \"\"\"\n    try:\n        write = self.optional_login()\n        results = self.wdSync.doCreateEventItemAndLinkProceedings(volume, proceedingsWikidataId, write=write)\n        if write:\n            self.wdSync.logout()\n        for key, result in results.items():\n            if result.qid:\n                if key == \"dblp\":\n                    url = f\"https://dblp.org/db/{result.qid}.html\"\n                    link = self.createLink(url, f\"dblp {result.qid}\")\n                else:\n                    link = self.createWdLink(\n                        result.qid,\n                        f\"{key} for Vol {volume.number} {result.qid}\",\n                    )\n                self.add_msg(\"&lt;br&gt;\" + link)\n            if result.msg:\n                self.add_msg(\"&lt;br&gt;\" + result.msg)\n            if len(result.errors) &gt; 0:\n                for error in result.errors.values():\n                    self.add_msg(f\"error {str(error)}\")\n    except Exception as ex:\n        self.solution.handle_exception(ex)\n    pass\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.createProceedingsItemFromVolume","title":"<code>createProceedingsItemFromVolume(volume)</code>","text":"<p>Create wikidata item for proceedings of given volume</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>def createProceedingsItemFromVolume(self, volume: Volume):\n    \"\"\"\n    Create wikidata item for proceedings of given volume\n    \"\"\"\n    qId = None\n    try:\n        write = self.optional_login()\n        # check if already in wikidata \u2192 use URN\n        urn = volume.urn\n        wdItems = self.wdSync.getProceedingWdItemsByUrn(urn)\n        if len(wdItems) &gt; 0:\n            html = f\"Volume {volume.number} already in Wikidata see \"\n            delim = \"\"\n            for wdItem in wdItems:\n                qId = wdItem.split(\"/\")[-1]\n                link = self.createLink(wdItem, qId)\n                html += f\"{link}{delim}\"\n                delim = \",\"\n            self.add_msg(html + \"&lt;br&gt;\")\n        else:\n            # A proceedings volume for the URN is not known \u2192 create wd entry\n            wdRecord = self.wdSync.getWikidataProceedingsRecord(volume)\n            if self.dry_run:\n                markup = self.get_dict_as_html_table(wdRecord)\n                self.add_msg(markup)\n            result = self.wdSync.addProceedingsToWikidata(wdRecord, write=write, ignoreErrors=self.ignore_errors)\n            qId = result.qid\n            if qId is not None:\n                proc_link = self.createWdLink(\n                    qId,\n                    f\"Proceedings entry for Vol {volume.number} {qId} was created\",\n                )\n                self.add_msg(proc_link)\n            else:\n                self.add_msg(f\"Creating wikidata Proceedings entry for Vol {volume.number} failed\")\n                for key, value in result.errors.items():\n                    msg = f\"{key}:{value}\"\n                    self.add_msg(msg)\n    except Exception as ex:\n        self.solution.handle_exception(ex)\n    return qId\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.get_volume_lod","title":"<code>get_volume_lod()</code>","text":"<p>get the list of dict of all volumes</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>def get_volume_lod(self):\n    \"\"\"\n    get the list of dict of all volumes\n    \"\"\"\n    self.lod = []\n    volumeList = self.wdSync.vm.getList()\n    reverseVolumeList = sorted(volumeList, key=lambda volume: volume.number, reverse=True)\n    for volume in reverseVolumeList:\n        validMark = \"\u2705\" if volume.valid else \"\u274c\"\n        self.lod.append(\n            {\n                \"#\": volume.number,\n                \"Vol\": self.createLink(volume.url, f\"Vol-{volume.number:04}\"),\n                \"Acronym\": self.getValue(volume, \"acronym\"),\n                \"Title\": self.getValue(volume, \"title\"),\n                \"Loctime\": self.getValue(volume, \"loctime\"),\n                \"Published\": self.getValue(volume, \"published\"),\n                \"SubmittedBy\": self.getValue(volume, \"submittedBy\"),\n                \"valid\": validMark,\n            }\n        )\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.onWikidataButtonClick","title":"<code>onWikidataButtonClick(_args)</code>  <code>async</code>","text":"<p>handle wikidata sync request</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>async def onWikidataButtonClick(self, _args):\n    \"\"\"\n    handle wikidata sync request\n    \"\"\"\n    selected_rows = await self.lod_grid.get_selected_rows()\n    await run.io_bound(self.updateWikidataVolumes, selected_rows)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.on_check_recently_update_volumes_button_click","title":"<code>on_check_recently_update_volumes_button_click(args)</code>  <code>async</code>","text":"<p>handle clicking of the refresh button to get recently added volumes</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>async def on_check_recently_update_volumes_button_click(self, args):\n    \"\"\"\n    handle clicking of the refresh button to get recently added volumes\n    \"\"\"\n    await run.io_bound(self.check_recently_updated_volumes)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.optional_login","title":"<code>optional_login()</code>","text":"<p>check if we need to login</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if write is enabled</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>def optional_login(self) -&gt; bool:\n    \"\"\"\n    check if we need to login\n\n    Returns:\n        bool: True if write is enabled\n    \"\"\"\n    write = not self.dry_run\n    if write:\n        self.wdSync.login()\n    return write\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.setup_ui","title":"<code>setup_ui()</code>","text":"<p>show my volumes as a list</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>def setup_ui(self):\n    \"\"\"\n    show my volumes as a list\n    \"\"\"\n    try:\n        with ui.row() as self.button_row:\n            self.check_recently_added_volumes_button = (\n                ui.button(\n                    icon=\"cloud_download\",\n                    on_click=self.on_check_recently_update_volumes_button_click,\n                )\n                .classes(\"btn btn-primary btn-sm col-1\")\n                .tooltip(\"check for recently added volumes\")\n            )\n            self.wikidataButton = (\n                ui.button(\n                    icon=\"web\",\n                    on_click=self.onWikidataButtonClick,\n                )\n                .classes(\"btn btn-primary btn-sm col-1\")\n                .tooltip(\"Export to Wikidata\")\n            )\n            self.dry_run_switch = ui.switch(\"dry run\").bind_value(self, \"dry_run\")\n            self.ignore_errors_check_box = ui.checkbox(\"ignore_errors\", value=self.ignore_errors).bind_value(\n                self, \"ignore_errors\"\n            )\n            pass\n            self.progress_bar = NiceguiProgressbar(total=100, desc=\"added\", unit=\"volume\")\n        with ui.row() as self.log_row:\n            self.log_view = ui.html()\n        with ui.row() as self.grid_row:\n            grid_config = GridConfig(key_col=\"Vol\", multiselect=True)\n            self.lod_grid = ListOfDictsGrid(lod=self.lod, config=grid_config)\n            # Modify the columnDefs for the \"Title\" column after grid initialization\n            for col_def in self.lod_grid.ag_grid.options[\"columnDefs\"]:\n                if col_def[\"field\"] == \"Title\":  # Identify the \"Title\" column\n                    col_def[\"maxWidth\"] = 400  # width in pixels\n            self.lod_grid.sizeColumnsToFit()\n    except Exception as ex:\n        self.solution.handle_exception(ex)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.updateRecentlyAddedVolume","title":"<code>updateRecentlyAddedVolume(volume, index, total)</code>","text":"<p>update a recently added Volume</p> <p>Parameters:</p> Name Type Description Default <code>volume(Volume)</code> <p>the volume to update</p> required <code>index(int)</code> <p>the relative index of the volume currently being added</p> required <code>total(int)</code> <p>the total number of volumes currently being added</p> required Source code in <code>ceurws/volume_view.py</code> <pre><code>def updateRecentlyAddedVolume(self, volume, index, total):\n    \"\"\"\n    update a recently added Volume\n\n    Args:\n        volume(Volume): the volume to update\n        index(int): the relative index of the volume currently being added\n        total(int): the total number of volumes currently being added\n    \"\"\"\n    html_msg = f\"&lt;br&gt;reading {index}/{total} from {volume.url}\"\n    self.add_msg(html_msg)\n    volume.extractValuesFromVolumePage()\n    self.wdSync.addVolume(volume)\n    self.progress_bar.update_value(index)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeListView.updateWikidataVolumes","title":"<code>updateWikidataVolumes(selected_rows)</code>","text":"<p>update wikidata volumes for the selected rows</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>def updateWikidataVolumes(self, selected_rows):\n    \"\"\"\n    update wikidata volumes for the selected rows\n    \"\"\"\n    try:\n        msg = f\"{len(selected_rows)} Volumes selected&lt;br&gt;\"\n        self.clear_msg(msg)\n        # First, sort selected_rows by the volume number in ascending order\n        sorted_rows = sorted(selected_rows, key=lambda row: row[\"#\"])\n        for row in sorted_rows:\n            vol_number = row[\"#\"]\n            volume = self.wdSync.volumesByNumber[vol_number]\n            self.add_or_update_volume_in_wikidata(volume)\n        pass\n    except Exception as ex:\n        self.solution.handle_exception(ex)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeView","title":"<code>VolumeView</code>","text":"<p>               Bases: <code>View</code></p> <p>displays a single volume</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>class VolumeView(View):\n    \"\"\"\n    displays a single volume\n    \"\"\"\n\n    def __init__(self, solution, parent):\n        \"\"\"\n        constructor\n\n        Args:\n            solution: the solution\n            parent: the parent UI container\n\n        \"\"\"\n        self.solution = solution\n        self.parent = parent\n        self.volumeToolBar = None\n        self.wdSync = self.solution.wdSync\n        self.wdSpan = None\n\n    def setup_ui(self):\n        \"\"\"\n        setup my User Interface elements\n        \"\"\"\n        with self.parent:\n            with ui.row() as self.volumeToolBar:\n                self.volumeRefreshButton = (\n                    ui.button(\n                        icon=\"refresh\",\n                        on_click=self.onRefreshButtonClick,\n                    )\n                    .classes(\"btn btn-primary btn-sm col-1\")\n                    .tooltip(\"Refresh from CEUR-WS Volume page\")\n                )\n                self.wikidataButton = (\n                    ui.button(\n                        icon=\"web\",\n                        on_click=self.onWikidataButtonClick,\n                    )\n                    .classes(\"btn btn-primary btn-sm col-1\")\n                    .tooltip(\"Export to Wikidata\")\n                )\n            self.header_view = ui.html()\n            self.iframe_view = ui.html().classes(\"w-full\").style(\"height: 80vh;\")\n\n    def updateWikidataSpan(self, qId: str, volume: Volume):\n        \"\"\"\n        create a Wikidata Export span\n\n        Args:\n            a(): ancestor\n            qId(str): wikidata item Q Identifier\n            volume(Volume): the Volume\n        \"\"\"\n        if self.wdSpan is None:\n            self.wdSpan = ui.html()\n        volume_link = Link.create(url=self.volume.url, text=f\"{volume.number}:{volume.acronym}\")\n        wd_url = self.wdSync.itemUrl(qId)\n        wd_link = Link.create(url=wd_url, text=f\"{qId} \")\n        self.wdSpan.content = f\"{volume_link}{wd_link}\"\n\n    def showVolume(self, volume: Volume):\n        \"\"\"\n        show the given volume\n\n        Args:\n            volume(Volume): the volume to show\n        \"\"\"\n        try:\n            self.volume = volume\n            if self.volumeToolBar is None:\n                self.setup_ui()\n\n            wdProc = self.wdSync.getProceedingsForVolume(volume.number)\n            self.wikidataButton.disabled = wdProc is not None\n            links = \"\"\n            if wdProc is not None:\n                # wikidata proceedings link\n                itemLink = self.createLink(wdProc[\"item\"], \"wikidataitem\")\n                # dblp proceedings link\n                dblpLink = self.createExternalLink(\n                    wdProc,\n                    \"dblpEventId\",\n                    \"dblp\",\n                    DblpEndpoint.DBLP_EVENT_PREFIX,\n                    emptyIfNone=True,\n                )\n                # k10plus proceedings link\n                k10PlusLink = self.createExternalLink(\n                    wdProc,\n                    \"ppnId\",\n                    \"k10plus\",\n                    \"https://opac.k10plus.de/DB=2.299/PPNSET?PPN=\",\n                    emptyIfNone=True,\n                )\n                # scholia proceedings link\n                scholiaLink = self.createExternalLink(\n                    wdProc,\n                    \"item\",\n                    \"scholia\",\n                    \"https://scholia.toolforge.org/venue/\",\n                    emptyIfNone=True,\n                )\n                # scholia event link\n                scholiaEventLink = self.createExternalLink(\n                    wdProc,\n                    \"event\",\n                    \"event\",\n                    \"https://scholia.toolforge.org/event/\",\n                    emptyIfNone=True,\n                )\n                # scholia event series link\n                scholiaEventSeriesLink = self.createExternalLink(\n                    wdProc,\n                    \"eventSeries\",\n                    \"series\",\n                    \"https://scholia.toolforge.org/event-series/\",\n                    emptyIfNone=True,\n                )\n                # scholia colocated with link\n                delim = \"\"\n                for link in [\n                    itemLink,\n                    dblpLink,\n                    k10PlusLink,\n                    scholiaLink,\n                    scholiaEventLink,\n                    scholiaEventSeriesLink,\n                ]:\n                    if link:\n                        links += delim + link\n                        delim = \"&amp;nbsp;\"\n\n            headerHtml = f\"\"\"\n    {links}&lt;h3 style='font-size: 24px; font-weight: normal; margin-top: 20px; margin-bottom: 10px;'&gt;{volume.h1}&lt;/h3&gt;\n    &lt;a href='{volume.url}'&gt;{volume.acronym}&lt;a&gt;\n    {volume.title}&lt;br&gt;\n    {volume.desc}\n    published: {volume.pubDate}\n    submitted By: {volume.submittedBy}\"\"\"\n            iframeHtml = f\"\"\"\n            &lt;iframe src='{volume.url}' style='width: 100%; height: 80vh; border: none;'&gt;&lt;/iframe&gt;\"\"\"\n            self.header_view.content = headerHtml\n            self.iframe_view.content = iframeHtml\n\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n\n    async def onRefreshButtonClick(self, _args):\n        try:\n            self.volume.extractValuesFromVolumePage()\n            msg = f\"updated from {self.volume.url}\"\n            ui.notify(msg)\n            self.showVolume(self.volume)\n            # self.wdSync.storeVolumes()\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n\n    async def onWikidataButtonClick(self, _args):\n        \"\"\"\n        handle wikidata sync request\n        \"\"\"\n        try:\n            wdRecord = self.wdSync.getWikidataProceedingsRecord(self.volume)\n            result = self.wdSync.addProceedingsToWikidata(wdRecord, write=True, ignoreErrors=False)\n            qId = result.qid\n            if qId is not None:\n                msg = f\"wikidata export of {self.volume.number} to {qId} done\"\n                ui.notify(msg)\n                self.updateWikidataSpan(qId=qId, volume=self.volume)\n            else:\n                err_msg = f\"error:{result.error}\"\n                self.solution.log_view.push(err_msg)\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeView.__init__","title":"<code>__init__(solution, parent)</code>","text":"<p>constructor</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <p>the solution</p> required <code>parent</code> <p>the parent UI container</p> required Source code in <code>ceurws/volume_view.py</code> <pre><code>def __init__(self, solution, parent):\n    \"\"\"\n    constructor\n\n    Args:\n        solution: the solution\n        parent: the parent UI container\n\n    \"\"\"\n    self.solution = solution\n    self.parent = parent\n    self.volumeToolBar = None\n    self.wdSync = self.solution.wdSync\n    self.wdSpan = None\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeView.onWikidataButtonClick","title":"<code>onWikidataButtonClick(_args)</code>  <code>async</code>","text":"<p>handle wikidata sync request</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>async def onWikidataButtonClick(self, _args):\n    \"\"\"\n    handle wikidata sync request\n    \"\"\"\n    try:\n        wdRecord = self.wdSync.getWikidataProceedingsRecord(self.volume)\n        result = self.wdSync.addProceedingsToWikidata(wdRecord, write=True, ignoreErrors=False)\n        qId = result.qid\n        if qId is not None:\n            msg = f\"wikidata export of {self.volume.number} to {qId} done\"\n            ui.notify(msg)\n            self.updateWikidataSpan(qId=qId, volume=self.volume)\n        else:\n            err_msg = f\"error:{result.error}\"\n            self.solution.log_view.push(err_msg)\n    except Exception as ex:\n        self.solution.handle_exception(ex)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeView.setup_ui","title":"<code>setup_ui()</code>","text":"<p>setup my User Interface elements</p> Source code in <code>ceurws/volume_view.py</code> <pre><code>def setup_ui(self):\n    \"\"\"\n    setup my User Interface elements\n    \"\"\"\n    with self.parent:\n        with ui.row() as self.volumeToolBar:\n            self.volumeRefreshButton = (\n                ui.button(\n                    icon=\"refresh\",\n                    on_click=self.onRefreshButtonClick,\n                )\n                .classes(\"btn btn-primary btn-sm col-1\")\n                .tooltip(\"Refresh from CEUR-WS Volume page\")\n            )\n            self.wikidataButton = (\n                ui.button(\n                    icon=\"web\",\n                    on_click=self.onWikidataButtonClick,\n                )\n                .classes(\"btn btn-primary btn-sm col-1\")\n                .tooltip(\"Export to Wikidata\")\n            )\n        self.header_view = ui.html()\n        self.iframe_view = ui.html().classes(\"w-full\").style(\"height: 80vh;\")\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeView.showVolume","title":"<code>showVolume(volume)</code>","text":"<p>show the given volume</p> <p>Parameters:</p> Name Type Description Default <code>volume(Volume)</code> <p>the volume to show</p> required Source code in <code>ceurws/volume_view.py</code> <pre><code>def showVolume(self, volume: Volume):\n    \"\"\"\n    show the given volume\n\n    Args:\n        volume(Volume): the volume to show\n    \"\"\"\n    try:\n        self.volume = volume\n        if self.volumeToolBar is None:\n            self.setup_ui()\n\n        wdProc = self.wdSync.getProceedingsForVolume(volume.number)\n        self.wikidataButton.disabled = wdProc is not None\n        links = \"\"\n        if wdProc is not None:\n            # wikidata proceedings link\n            itemLink = self.createLink(wdProc[\"item\"], \"wikidataitem\")\n            # dblp proceedings link\n            dblpLink = self.createExternalLink(\n                wdProc,\n                \"dblpEventId\",\n                \"dblp\",\n                DblpEndpoint.DBLP_EVENT_PREFIX,\n                emptyIfNone=True,\n            )\n            # k10plus proceedings link\n            k10PlusLink = self.createExternalLink(\n                wdProc,\n                \"ppnId\",\n                \"k10plus\",\n                \"https://opac.k10plus.de/DB=2.299/PPNSET?PPN=\",\n                emptyIfNone=True,\n            )\n            # scholia proceedings link\n            scholiaLink = self.createExternalLink(\n                wdProc,\n                \"item\",\n                \"scholia\",\n                \"https://scholia.toolforge.org/venue/\",\n                emptyIfNone=True,\n            )\n            # scholia event link\n            scholiaEventLink = self.createExternalLink(\n                wdProc,\n                \"event\",\n                \"event\",\n                \"https://scholia.toolforge.org/event/\",\n                emptyIfNone=True,\n            )\n            # scholia event series link\n            scholiaEventSeriesLink = self.createExternalLink(\n                wdProc,\n                \"eventSeries\",\n                \"series\",\n                \"https://scholia.toolforge.org/event-series/\",\n                emptyIfNone=True,\n            )\n            # scholia colocated with link\n            delim = \"\"\n            for link in [\n                itemLink,\n                dblpLink,\n                k10PlusLink,\n                scholiaLink,\n                scholiaEventLink,\n                scholiaEventSeriesLink,\n            ]:\n                if link:\n                    links += delim + link\n                    delim = \"&amp;nbsp;\"\n\n        headerHtml = f\"\"\"\n{links}&lt;h3 style='font-size: 24px; font-weight: normal; margin-top: 20px; margin-bottom: 10px;'&gt;{volume.h1}&lt;/h3&gt;\n&lt;a href='{volume.url}'&gt;{volume.acronym}&lt;a&gt;\n{volume.title}&lt;br&gt;\n{volume.desc}\npublished: {volume.pubDate}\nsubmitted By: {volume.submittedBy}\"\"\"\n        iframeHtml = f\"\"\"\n        &lt;iframe src='{volume.url}' style='width: 100%; height: 80vh; border: none;'&gt;&lt;/iframe&gt;\"\"\"\n        self.header_view.content = headerHtml\n        self.iframe_view.content = iframeHtml\n\n    except Exception as ex:\n        self.solution.handle_exception(ex)\n</code></pre>"},{"location":"#ceurws.volume_view.VolumeView.updateWikidataSpan","title":"<code>updateWikidataSpan(qId, volume)</code>","text":"<p>create a Wikidata Export span</p> <p>Parameters:</p> Name Type Description Default <code>a()</code> <p>ancestor</p> required <code>qId(str)</code> <p>wikidata item Q Identifier</p> required <code>volume(Volume)</code> <p>the Volume</p> required Source code in <code>ceurws/volume_view.py</code> <pre><code>def updateWikidataSpan(self, qId: str, volume: Volume):\n    \"\"\"\n    create a Wikidata Export span\n\n    Args:\n        a(): ancestor\n        qId(str): wikidata item Q Identifier\n        volume(Volume): the Volume\n    \"\"\"\n    if self.wdSpan is None:\n        self.wdSpan = ui.html()\n    volume_link = Link.create(url=self.volume.url, text=f\"{volume.number}:{volume.acronym}\")\n    wd_url = self.wdSync.itemUrl(qId)\n    wd_link = Link.create(url=wd_url, text=f\"{qId} \")\n    self.wdSpan.content = f\"{volume_link}{wd_link}\"\n</code></pre>"},{"location":"#ceurws.volumeparser","title":"<code>volumeparser</code>","text":"<p>Created on 2022-08-14</p> <p>@author: wf</p>"},{"location":"#ceurws.volumeparser.VolumePageCache","title":"<code>VolumePageCache</code>","text":"<p>Cache interface for ceur-ws volume pages</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>class VolumePageCache:\n    \"\"\"\n    Cache interface for ceur-ws volume pages\n    \"\"\"\n\n    cache_location: Path = CEURWS.CACHE_DIR / \"volumes\"\n\n    @classmethod\n    def is_cached(cls, number: int) -&gt; bool:\n        \"\"\"\n        Check if the volume page of the given volume number is cached\n        Args:\n            number: volume number of the volume page\n\n        Returns:\n            True if the corresponding volume page is cached\n        \"\"\"\n        return cls._get_volume_cache_path(number).is_file()\n\n    @classmethod\n    def cache(cls, number: int, html: str | bytes):\n        \"\"\"\n        cache the volume page corresponding to the given number\n        Args:\n            number: number of the volume to cache\n            html: html of the volume page to cache\n        \"\"\"\n        if html is None:\n            return\n        Path(cls.cache_location).mkdir(parents=True, exist_ok=True)\n        filename = cls._get_volume_cache_path(number)\n        mode = \"w\"\n        if isinstance(html, bytes):\n            mode += \"b\"\n        with open(filename, mode=mode) as f:\n            f.write(html)\n\n    @classmethod\n    def _get_volume_cache_path(cls, number: int) -&gt; Path:\n        \"\"\"\n        get the name of the volume cache file\n        \"\"\"\n        return cls.cache_location / f\"Vol-{number}.html\"\n\n    @classmethod\n    def get(cls, number: int) -&gt; str | bytes | None:\n        \"\"\"\n        Get the cached volume page of the given volume number.\n        If the volume page is not cached None is returned.\n        Args:\n            number: volume number to retrieve\n\n        Returns:\n            str: cached volume page\n            bytes: if the cached volume page contains encoding errors\n            None: if no volume with the given number is cached\n        \"\"\"\n        volume_page: str | bytes | None = None\n        if cls.is_cached(number):\n            filepath = cls._get_volume_cache_path(number)\n            try:\n                volume_page = filepath.read_text()\n            except UnicodeDecodeError as _ex:\n                volume_page = filepath.read_bytes()\n        return volume_page\n\n    @classmethod\n    def delete(cls, number: int):\n        \"\"\"\n        Delete the cache corresponding to the given volume number\n        Args:\n            number: volume number\n        \"\"\"\n        if cls.is_cached(number):\n            filepath = cls._get_volume_cache_path(number)\n            os.remove(filepath)\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumePageCache.cache","title":"<code>cache(number, html)</code>  <code>classmethod</code>","text":"<p>cache the volume page corresponding to the given number Args:     number: number of the volume to cache     html: html of the volume page to cache</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>@classmethod\ndef cache(cls, number: int, html: str | bytes):\n    \"\"\"\n    cache the volume page corresponding to the given number\n    Args:\n        number: number of the volume to cache\n        html: html of the volume page to cache\n    \"\"\"\n    if html is None:\n        return\n    Path(cls.cache_location).mkdir(parents=True, exist_ok=True)\n    filename = cls._get_volume_cache_path(number)\n    mode = \"w\"\n    if isinstance(html, bytes):\n        mode += \"b\"\n    with open(filename, mode=mode) as f:\n        f.write(html)\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumePageCache.delete","title":"<code>delete(number)</code>  <code>classmethod</code>","text":"<p>Delete the cache corresponding to the given volume number Args:     number: volume number</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>@classmethod\ndef delete(cls, number: int):\n    \"\"\"\n    Delete the cache corresponding to the given volume number\n    Args:\n        number: volume number\n    \"\"\"\n    if cls.is_cached(number):\n        filepath = cls._get_volume_cache_path(number)\n        os.remove(filepath)\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumePageCache.get","title":"<code>get(number)</code>  <code>classmethod</code>","text":"<p>Get the cached volume page of the given volume number. If the volume page is not cached None is returned. Args:     number: volume number to retrieve</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str | bytes | None</code> <p>cached volume page</p> <code>bytes</code> <code>str | bytes | None</code> <p>if the cached volume page contains encoding errors</p> <code>None</code> <code>str | bytes | None</code> <p>if no volume with the given number is cached</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>@classmethod\ndef get(cls, number: int) -&gt; str | bytes | None:\n    \"\"\"\n    Get the cached volume page of the given volume number.\n    If the volume page is not cached None is returned.\n    Args:\n        number: volume number to retrieve\n\n    Returns:\n        str: cached volume page\n        bytes: if the cached volume page contains encoding errors\n        None: if no volume with the given number is cached\n    \"\"\"\n    volume_page: str | bytes | None = None\n    if cls.is_cached(number):\n        filepath = cls._get_volume_cache_path(number)\n        try:\n            volume_page = filepath.read_text()\n        except UnicodeDecodeError as _ex:\n            volume_page = filepath.read_bytes()\n    return volume_page\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumePageCache.is_cached","title":"<code>is_cached(number)</code>  <code>classmethod</code>","text":"<p>Check if the volume page of the given volume number is cached Args:     number: volume number of the volume page</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the corresponding volume page is cached</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>@classmethod\ndef is_cached(cls, number: int) -&gt; bool:\n    \"\"\"\n    Check if the volume page of the given volume number is cached\n    Args:\n        number: volume number of the volume page\n\n    Returns:\n        True if the corresponding volume page is cached\n    \"\"\"\n    return cls._get_volume_cache_path(number).is_file()\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser","title":"<code>VolumeParser</code>","text":"<p>               Bases: <code>Textparser</code></p> <p>CEUR-WS VolumeParser</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>class VolumeParser(Textparser):\n    \"\"\"\n    CEUR-WS VolumeParser\n    \"\"\"\n\n    def __init__(\n        self,\n        baseurl: str = \"http://ceur-ws.org\",\n        timeout: float = 3,\n        showHtml: bool = False,\n        debug: bool = False,\n    ):\n        \"\"\"\n        Constructor\n\n        Args:\n            baseurl(str): the baseurl of the CEUR-WS website,\n            timeout(float): the number of seconds to wait\n            showHtml(bool): if True show the HTML code\n            debug(bool): if True switch debugging on\n        \"\"\"\n        Textparser.__init__(self, debug=debug)\n        self.showHtml = showHtml\n        self.baseurl = baseurl\n        self.timeout = timeout\n        self.scrape = WebScrape(timeout=timeout)\n\n    def volumeUrl(self, volnumber: str | int):\n        \"\"\"\n        get the url for the given volume number\n\n        Args:\n            volnumber(str): the volume number\n\n        Returns:\n            str: url - the url of the volume\n        \"\"\"\n        # e.g. http://ceur-ws.org/Vol-2635/\n        url = f\"{self.baseurl}/Vol-{volnumber}\"\n        return url\n\n    def getSoup(self, url: str) -&gt; BeautifulSoup | None:\n        \"\"\"\n        get the beautiful Soup parser for the given url\n        Args:\n            url: url to parse\n\n        Returns:\n            parsed webpage\n        \"\"\"\n        return self.scrape.getSoup(url, showHtml=self.showHtml, debug=self.debug)\n\n    def get_volume_soup(self, number: int, use_cache: bool = True) -&gt; BeautifulSoup | None:\n        \"\"\"\n        Get Soup of the volume page for the given volume number\n        Args:\n            number: volume number of the volume to parse\n            use_cache: If True use volume page from cache if present otherwise load from web and cache\n\n        Returns:\n            BeautifulSoup: soup of the volume page\n            None: soup can not be loaded from cache or from web\n        \"\"\"\n        html = self.get_volume_page(number, recache=not use_cache)\n        if html is None:\n            if self.debug:\n                print(f\"Vol-{number} could not be retrieved\")\n            return None\n        soup = self.scrape.get_soup_from_string(html, show_html=self.showHtml)\n        return soup\n\n    def get_volume_page(self, number: int, recache: bool = False) -&gt; str | bytes | None:\n        \"\"\"\n        Get the html content of the given volume number.\n        Retrieves the volume page from cache or from ceur-ws.org\n        Caches the volume page if not already cached\n        Args:\n            number: volume number\n            recache: If True update the cache with a new fetch from the web. Otherwise, cache is used if present\n\n        Returns:\n            html of volume page or None if the volume page is not found\n        \"\"\"\n        if not recache and VolumePageCache.is_cached(number):\n            volume_page = VolumePageCache.get(number)\n        else:\n            url = self.volumeUrl(number)\n            volume_page = self.scrape.get_html_from_url(url)\n            if volume_page:\n                VolumePageCache.cache(number, volume_page)\n        return volume_page\n\n    def parse_volume(self, number: int, use_cache: bool = True) -&gt; tuple[dict, BeautifulSoup | None]:\n        \"\"\"\n        parse the given volume\n        caches the volume pages at ~/.ceurws/volumes\n\n        Args:\n            number: volume number of the volume to parse\n            use_cache: If True use volume page from cache if present otherwise load from web and cache\n\n        Returns:\n            dict: extracted information\n        \"\"\"\n        soup = self.get_volume_soup(number, use_cache=use_cache)\n        parsed_dict = self.parse_soup(number=str(number), soup=soup) if soup else {}\n        self.check_parsed_dict(parsed_dict)\n        return parsed_dict, soup\n\n    def check_parsed_dict(self, parsed_dict: dict):\n        \"\"\"\n        check parsed_dict content e.g. urn check digit\n        \"\"\"\n        if \"urn\" in parsed_dict:\n            urn = parsed_dict[\"urn\"]\n            if urn:\n                urn_prefix = urn[:-1]\n                check_digit = URN.calc_urn_checksum(urn_prefix)\n                parsed_dict[\"urn_check_digit\"] = check_digit\n                urn_ok = URN.check_urn_checksum(urn)\n                parsed_dict[\"urn_ok\"] = urn_ok\n\n    def parse(self, url: str) -&gt; dict:\n        \"\"\"\n        parse the given url\n        Args:\n             url: URL to parse the volume information from\n\n        Returns:\n            dict: extracted information\n        \"\"\"\n        soup = self.getSoup(url)\n        parsed_dict = self.parse_soup(soup=soup) if soup else {}\n        return parsed_dict\n\n    def parse_soup(self, soup: BeautifulSoup, number: str | None = None) -&gt; dict:\n        \"\"\"\n        parse the volume page data from the given soup\n\n        Args:\n            number(str): the volume number\n            soup(BeautifulSoup): html parser to extract the content from\n\n        Returns:\n            dict: parsed content\n        \"\"\"\n        if soup is None:\n            return {\"vol_number\": number}\n        # first try RDFa annotations\n        scrapedDict = self.parseRDFa(soup)\n        for key in scrapedDict:\n            scrapedDict[key] = Textparser.sanitize(scrapedDict[key])\n\n        # second part\n        for descValue in [\"description\", \"descripton\"]:\n            # descripton is a typo in the Volume index files not here!\n            firstDesc = soup.find(\"meta\", {\"name\": descValue})\n            if isinstance(firstDesc, Tag):\n                desc = firstDesc[\"content\"]\n                desc = Textparser.sanitize(desc, [\"CEUR Workshop Proceedings \"])\n                scrapedDict[\"desc\"] = desc\n                break\n\n        # first H1 has title info\n        firstH1 = soup.find(\"h1\")\n        if firstH1 is not None:\n            h1 = firstH1.text\n            h1 = Textparser.sanitize(h1, ['&lt;TD bgcolor=\"#FFFFFF\"&gt;'])\n            scrapedDict[\"h1\"] = h1\n            link = firstH1.find(\"a\")\n            if link is not None and isinstance(link, Tag) and len(link.text) &lt; 20:\n                acronym = link.text.strip()\n                if not acronym:\n                    acronym = h1 if len(h1) &lt; 28 else h1.split()[0]\n\n                eventHomepage = link.attrs.get(\"href\")\n                scrapedDict[\"acronym\"] = acronym\n                scrapedDict[\"homepage\"] = eventHomepage\n\n        # first h3 has loctime\n        firstH3 = soup.find(\"h3\")\n        if firstH3 is not None:\n            h3 = firstH3.text\n            h3 = Textparser.sanitize(h3)\n            scrapedDict[\"h3\"] = h3\n\n        if self.hasValue(scrapedDict, \"desc\") and not self.hasValue(scrapedDict, \"acronym\"):\n            scrapedDict[\"acronym\"] = scrapedDict[\"desc\"]\n        if self.hasValue(scrapedDict, \"h1\") and not self.hasValue(scrapedDict, \"title\"):\n            scrapedDict[\"title\"] = scrapedDict[\"h1\"]\n        if (\n            self.hasValue(scrapedDict, \"h1\")\n            and self.hasValue(scrapedDict, \"title\")\n            and not self.hasValue(scrapedDict, \"acronym\")\n        ):\n            scrapedDict[\"acronym\"] = scrapedDict[\"h1\"]\n        # editorsRecords = self.parseEditors(soup)\n        # scrapedDict[\"editors\"] = editorsRecords\n        return scrapedDict\n\n    def parseEditors(self, soup: BeautifulSoup):\n        \"\"\"\n        parse all editor information contained in the given soup\n        parse all information between &lt;b&gt; Edited by &lt;/b&gt; ... &lt;hr&gt;\n        Args:\n            soup: volume web page\n        \"\"\"\n        if soup is None:\n            return None\n        possible_start_elements = soup.find_all(\"b\")\n        # find start\n        start_elements = []\n        for e in possible_start_elements:\n            start_tags = [\"edited by\", \"program committee\"]\n            for tag in start_tags:\n                if tag in e.text.lower():\n                    start_elements.append(e)\n        if len(start_elements) == 0:\n            return None\n        edited_by = start_elements[0]\n        editor_h3 = edited_by.find_next(\"h3\")\n        editor_records: dict[str, dict] = dict()\n        if editor_h3 is None:\n            return None\n        editor_spans = editor_h3.find_all(attrs={\"class\": \"CEURVOLEDITOR\"})\n        if editor_spans is not None and len(editor_spans) &gt; 0:\n            for editor_span in editor_spans:\n                editor_name = editor_span.text\n                editor = {\"name\": editor_name}\n                if editor_span.parent.name == \"a\":\n                    homepage = editor_span.parent.attrs.get(\"href\", None)\n                    editor[\"homepage\"] = homepage\n                    if editor_span.parent.next_sibling is not None:\n                        affiliation_keys = editor_span.parent.next_sibling.text.strip()\n                    else:\n                        affiliation_keys = None\n                else:\n                    if editor_span.next_sibling is not None:\n                        affiliation_keys = editor_span.next_sibling.text.strip()\n                    else:\n                        affiliation_keys = None\n                if affiliation_keys is None or affiliation_keys == \"\":\n                    sup = editor_span.find_next(\"sup\")\n                    if sup is not None:\n                        affiliation_keys = sup.text.strip()\n                editor[\"affiliation_keys\"] = affiliation_keys\n                editor_records[editor_name] = editor\n        else:\n            editor_elements = []\n            group_elements: list[PageElement] = []\n            if (\n                editor_h3.next_sibling\n                and editor_h3.next_sibling.next_sibling\n                and editor_h3.next_sibling.next_sibling.name == \"h3\"\n            ):\n                while editor_h3.next_sibling.next_sibling.name == \"h3\" and editor_h3.text.strip() != \"\":\n                    editor_elements.append(editor_h3.contents)\n                    editor_h3 = editor_h3.next_sibling.next_sibling\n            else:\n                for child in editor_h3.childGenerator():\n                    if child.name == \"br\":\n                        editor_elements.append(group_elements)\n                        group_elements = []\n                    else:\n                        group_elements.append(child)\n            for elements in editor_elements:\n                text = \"\".join([e.text for e in elements]).strip()\n                affiliation_key = text.split(\" \")[-1]\n                editor_name = text[: -len(affiliation_key)]\n                links = [e for e in elements if e.name == \"a\"]\n                homepage = links[0].attrs.get(\"href\", None) if len(links) &gt; 0 else None\n                editor = {\n                    \"name\": editor_name,\n                    \"homepage\": homepage,\n                    \"affiliation_key\": affiliation_key,\n                }\n                editor_records[editor_name] = editor\n        affiliation_keys = {\n            editor.get(\"affiliation_key\")\n            for editor in editor_records.values()\n            if editor.get(\"affiliation_key\", None) is not None\n        }\n        affiliation_map = self.parseAffiliationMap(editor_h3.next_sibling)\n        for editor_record in editor_records.values():\n            editor_keys = editor_record.get(\"affiliation_keys\", \"\")\n            if editor_keys is not None:\n                keys = re.split(\"[, ]\", editor_keys)\n                editor_affiliations = []\n                for key in keys:\n                    if key in affiliation_map:\n                        editor_affiliations.append(affiliation_map.get(key.strip()))\n                editor_record[\"affiliation\"] = editor_affiliations\n        return editor_records\n\n    def parseAffiliationMap(self, start: PageElement) -&gt; dict:\n        \"\"\"\n        Parse out the affiliations and their reference key\n        Args:\n            start:\n\n        Returns:\n            dict\n        \"\"\"\n        if start is None:\n            return dict()\n        end = start.find_next(\"hr\")\n        affiliations_elements = []\n        group_elements: list[PageElement] = []\n        if isinstance(start.previous, Tag | NavigableString):\n            for element in start.previous.nextGenerator():\n                if isinstance(element, Tag | NavigableString) and element.name in [\"br\", \"hr\"]:\n                    affiliations_elements.append(group_elements)\n                    group_elements = []\n                elif isinstance(element, NavigableString) and element.text.strip() == \"\":\n                    pass\n                elif isinstance(element, Tag | NavigableString) and element.name == \"h3\":\n                    # elements inside the element are included through the nextGenerator\n                    pass\n                else:\n                    group_elements.append(element)\n                if element == end:\n                    break\n        affiliations_elements = [x for x in affiliations_elements if x != []]\n        affiliation_map = dict()\n        for elements in affiliations_elements:\n            if isinstance(elements[0], NavigableString) and \" \" in elements[0].text.strip():\n                text_containing_key = elements[0].text.strip()\n                key = text_containing_key.split(\" \")[0]\n                key_element = NavigableString(value=key)\n                text_element = NavigableString(value=text_containing_key[len(key) :])\n                elements = [key_element, text_element, *elements[1:]]\n            key = elements[0].text.strip()\n            text_elements = []\n            link_elements = []\n            for element in elements[1:]:\n                if isinstance(element, NavigableString):\n                    text_elements.append(element)\n                elif isinstance(element, Tag | NavigableString) and element.name == \"a\":\n                    link_elements.append(element)\n            affiliation = \"\".join([elem.text for elem in text_elements])\n            affiliation = affiliation.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"\\r\", \"\")\n            if affiliation.startswith(key):\n                affiliation = affiliation[len(key) :]\n            homepages = []\n            for element in link_elements:\n                if hasattr(element, \"attrs\") and element.attrs.get(\"href\", None) is not None:\n                    homepage = element.attrs.get(\"href\", None)\n                    homepages.append(homepage)\n            if key is not None and key != \"\":\n                key = key.strip(\".\")\n                affiliation_map[key] = {\n                    \"name\": affiliation,\n                    \"homepage\": homepages,\n                }\n        return affiliation_map\n\n    def parseRDFa(self, soup: BeautifulSoup) -&gt; dict:\n        \"\"\"\n        tries to parse rdfa content from the given soup\n        Args:\n            soup: html parser to extract the content from\n\n        Returns:\n            dict: dict with the extracted content\n        \"\"\"\n        scrapeDescr = [\n            ScrapeDescription(\n                key=\"volume_number\",\n                tag=\"span\",\n                attribute=\"class\",\n                value=\"CEURVOLNR\",\n            ),\n            ScrapeDescription(key=\"urn\", tag=\"span\", attribute=\"class\", value=\"CEURURN\"),\n            ScrapeDescription(key=\"year\", tag=\"span\", attribute=\"class\", value=\"CEURPUBYEAR\"),\n            ScrapeDescription(\n                key=\"ceurpubdate\",\n                tag=\"span\",\n                attribute=\"class\",\n                value=\"CEURPUBDATE\",\n            ),\n            ScrapeDescription(\n                key=\"acronym\",\n                tag=\"span\",\n                attribute=\"class\",\n                value=\"CEURVOLACRONYM\",\n            ),\n            ScrapeDescription(\n                key=\"voltitle\",\n                tag=\"span\",\n                attribute=\"class\",\n                value=\"CEURVOLTITLE\",\n            ),\n            ScrapeDescription(\n                key=\"title\",\n                tag=\"span\",\n                attribute=\"class\",\n                value=\"CEURFULLTITLE\",\n            ),\n            ScrapeDescription(\n                key=\"loctime\",\n                tag=\"span\",\n                attribute=\"class\",\n                value=\"CEURLOCTIME\",\n            ),\n            ScrapeDescription(\n                key=\"colocated\",\n                tag=\"span\",\n                attribute=\"class\",\n                value=\"CEURCOLOCATED\",\n            ),\n        ]\n        scrapedDict = self.scrape.parseWithScrapeDescription(soup, scrapeDescr)\n        return scrapedDict\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.__init__","title":"<code>__init__(baseurl='http://ceur-ws.org', timeout=3, showHtml=False, debug=False)</code>","text":"<p>Constructor</p> <p>Parameters:</p> Name Type Description Default <code>baseurl(str)</code> <p>the baseurl of the CEUR-WS website,</p> required <code>timeout(float)</code> <p>the number of seconds to wait</p> required <code>showHtml(bool)</code> <p>if True show the HTML code</p> required <code>debug(bool)</code> <p>if True switch debugging on</p> required Source code in <code>ceurws/volumeparser.py</code> <pre><code>def __init__(\n    self,\n    baseurl: str = \"http://ceur-ws.org\",\n    timeout: float = 3,\n    showHtml: bool = False,\n    debug: bool = False,\n):\n    \"\"\"\n    Constructor\n\n    Args:\n        baseurl(str): the baseurl of the CEUR-WS website,\n        timeout(float): the number of seconds to wait\n        showHtml(bool): if True show the HTML code\n        debug(bool): if True switch debugging on\n    \"\"\"\n    Textparser.__init__(self, debug=debug)\n    self.showHtml = showHtml\n    self.baseurl = baseurl\n    self.timeout = timeout\n    self.scrape = WebScrape(timeout=timeout)\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.check_parsed_dict","title":"<code>check_parsed_dict(parsed_dict)</code>","text":"<p>check parsed_dict content e.g. urn check digit</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def check_parsed_dict(self, parsed_dict: dict):\n    \"\"\"\n    check parsed_dict content e.g. urn check digit\n    \"\"\"\n    if \"urn\" in parsed_dict:\n        urn = parsed_dict[\"urn\"]\n        if urn:\n            urn_prefix = urn[:-1]\n            check_digit = URN.calc_urn_checksum(urn_prefix)\n            parsed_dict[\"urn_check_digit\"] = check_digit\n            urn_ok = URN.check_urn_checksum(urn)\n            parsed_dict[\"urn_ok\"] = urn_ok\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.getSoup","title":"<code>getSoup(url)</code>","text":"<p>get the beautiful Soup parser for the given url Args:     url: url to parse</p> <p>Returns:</p> Type Description <code>BeautifulSoup | None</code> <p>parsed webpage</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def getSoup(self, url: str) -&gt; BeautifulSoup | None:\n    \"\"\"\n    get the beautiful Soup parser for the given url\n    Args:\n        url: url to parse\n\n    Returns:\n        parsed webpage\n    \"\"\"\n    return self.scrape.getSoup(url, showHtml=self.showHtml, debug=self.debug)\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.get_volume_page","title":"<code>get_volume_page(number, recache=False)</code>","text":"<p>Get the html content of the given volume number. Retrieves the volume page from cache or from ceur-ws.org Caches the volume page if not already cached Args:     number: volume number     recache: If True update the cache with a new fetch from the web. Otherwise, cache is used if present</p> <p>Returns:</p> Type Description <code>str | bytes | None</code> <p>html of volume page or None if the volume page is not found</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def get_volume_page(self, number: int, recache: bool = False) -&gt; str | bytes | None:\n    \"\"\"\n    Get the html content of the given volume number.\n    Retrieves the volume page from cache or from ceur-ws.org\n    Caches the volume page if not already cached\n    Args:\n        number: volume number\n        recache: If True update the cache with a new fetch from the web. Otherwise, cache is used if present\n\n    Returns:\n        html of volume page or None if the volume page is not found\n    \"\"\"\n    if not recache and VolumePageCache.is_cached(number):\n        volume_page = VolumePageCache.get(number)\n    else:\n        url = self.volumeUrl(number)\n        volume_page = self.scrape.get_html_from_url(url)\n        if volume_page:\n            VolumePageCache.cache(number, volume_page)\n    return volume_page\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.get_volume_soup","title":"<code>get_volume_soup(number, use_cache=True)</code>","text":"<p>Get Soup of the volume page for the given volume number Args:     number: volume number of the volume to parse     use_cache: If True use volume page from cache if present otherwise load from web and cache</p> <p>Returns:</p> Name Type Description <code>BeautifulSoup</code> <code>BeautifulSoup | None</code> <p>soup of the volume page</p> <code>None</code> <code>BeautifulSoup | None</code> <p>soup can not be loaded from cache or from web</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def get_volume_soup(self, number: int, use_cache: bool = True) -&gt; BeautifulSoup | None:\n    \"\"\"\n    Get Soup of the volume page for the given volume number\n    Args:\n        number: volume number of the volume to parse\n        use_cache: If True use volume page from cache if present otherwise load from web and cache\n\n    Returns:\n        BeautifulSoup: soup of the volume page\n        None: soup can not be loaded from cache or from web\n    \"\"\"\n    html = self.get_volume_page(number, recache=not use_cache)\n    if html is None:\n        if self.debug:\n            print(f\"Vol-{number} could not be retrieved\")\n        return None\n    soup = self.scrape.get_soup_from_string(html, show_html=self.showHtml)\n    return soup\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.parse","title":"<code>parse(url)</code>","text":"<p>parse the given url Args:      url: URL to parse the volume information from</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>extracted information</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def parse(self, url: str) -&gt; dict:\n    \"\"\"\n    parse the given url\n    Args:\n         url: URL to parse the volume information from\n\n    Returns:\n        dict: extracted information\n    \"\"\"\n    soup = self.getSoup(url)\n    parsed_dict = self.parse_soup(soup=soup) if soup else {}\n    return parsed_dict\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.parseAffiliationMap","title":"<code>parseAffiliationMap(start)</code>","text":"<p>Parse out the affiliations and their reference key Args:     start:</p> <p>Returns:</p> Type Description <code>dict</code> <p>dict</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def parseAffiliationMap(self, start: PageElement) -&gt; dict:\n    \"\"\"\n    Parse out the affiliations and their reference key\n    Args:\n        start:\n\n    Returns:\n        dict\n    \"\"\"\n    if start is None:\n        return dict()\n    end = start.find_next(\"hr\")\n    affiliations_elements = []\n    group_elements: list[PageElement] = []\n    if isinstance(start.previous, Tag | NavigableString):\n        for element in start.previous.nextGenerator():\n            if isinstance(element, Tag | NavigableString) and element.name in [\"br\", \"hr\"]:\n                affiliations_elements.append(group_elements)\n                group_elements = []\n            elif isinstance(element, NavigableString) and element.text.strip() == \"\":\n                pass\n            elif isinstance(element, Tag | NavigableString) and element.name == \"h3\":\n                # elements inside the element are included through the nextGenerator\n                pass\n            else:\n                group_elements.append(element)\n            if element == end:\n                break\n    affiliations_elements = [x for x in affiliations_elements if x != []]\n    affiliation_map = dict()\n    for elements in affiliations_elements:\n        if isinstance(elements[0], NavigableString) and \" \" in elements[0].text.strip():\n            text_containing_key = elements[0].text.strip()\n            key = text_containing_key.split(\" \")[0]\n            key_element = NavigableString(value=key)\n            text_element = NavigableString(value=text_containing_key[len(key) :])\n            elements = [key_element, text_element, *elements[1:]]\n        key = elements[0].text.strip()\n        text_elements = []\n        link_elements = []\n        for element in elements[1:]:\n            if isinstance(element, NavigableString):\n                text_elements.append(element)\n            elif isinstance(element, Tag | NavigableString) and element.name == \"a\":\n                link_elements.append(element)\n        affiliation = \"\".join([elem.text for elem in text_elements])\n        affiliation = affiliation.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"\\r\", \"\")\n        if affiliation.startswith(key):\n            affiliation = affiliation[len(key) :]\n        homepages = []\n        for element in link_elements:\n            if hasattr(element, \"attrs\") and element.attrs.get(\"href\", None) is not None:\n                homepage = element.attrs.get(\"href\", None)\n                homepages.append(homepage)\n        if key is not None and key != \"\":\n            key = key.strip(\".\")\n            affiliation_map[key] = {\n                \"name\": affiliation,\n                \"homepage\": homepages,\n            }\n    return affiliation_map\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.parseEditors","title":"<code>parseEditors(soup)</code>","text":"<p>parse all editor information contained in the given soup parse all information between  Edited by  ...  Args:     soup: volume web page</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def parseEditors(self, soup: BeautifulSoup):\n    \"\"\"\n    parse all editor information contained in the given soup\n    parse all information between &lt;b&gt; Edited by &lt;/b&gt; ... &lt;hr&gt;\n    Args:\n        soup: volume web page\n    \"\"\"\n    if soup is None:\n        return None\n    possible_start_elements = soup.find_all(\"b\")\n    # find start\n    start_elements = []\n    for e in possible_start_elements:\n        start_tags = [\"edited by\", \"program committee\"]\n        for tag in start_tags:\n            if tag in e.text.lower():\n                start_elements.append(e)\n    if len(start_elements) == 0:\n        return None\n    edited_by = start_elements[0]\n    editor_h3 = edited_by.find_next(\"h3\")\n    editor_records: dict[str, dict] = dict()\n    if editor_h3 is None:\n        return None\n    editor_spans = editor_h3.find_all(attrs={\"class\": \"CEURVOLEDITOR\"})\n    if editor_spans is not None and len(editor_spans) &gt; 0:\n        for editor_span in editor_spans:\n            editor_name = editor_span.text\n            editor = {\"name\": editor_name}\n            if editor_span.parent.name == \"a\":\n                homepage = editor_span.parent.attrs.get(\"href\", None)\n                editor[\"homepage\"] = homepage\n                if editor_span.parent.next_sibling is not None:\n                    affiliation_keys = editor_span.parent.next_sibling.text.strip()\n                else:\n                    affiliation_keys = None\n            else:\n                if editor_span.next_sibling is not None:\n                    affiliation_keys = editor_span.next_sibling.text.strip()\n                else:\n                    affiliation_keys = None\n            if affiliation_keys is None or affiliation_keys == \"\":\n                sup = editor_span.find_next(\"sup\")\n                if sup is not None:\n                    affiliation_keys = sup.text.strip()\n            editor[\"affiliation_keys\"] = affiliation_keys\n            editor_records[editor_name] = editor\n    else:\n        editor_elements = []\n        group_elements: list[PageElement] = []\n        if (\n            editor_h3.next_sibling\n            and editor_h3.next_sibling.next_sibling\n            and editor_h3.next_sibling.next_sibling.name == \"h3\"\n        ):\n            while editor_h3.next_sibling.next_sibling.name == \"h3\" and editor_h3.text.strip() != \"\":\n                editor_elements.append(editor_h3.contents)\n                editor_h3 = editor_h3.next_sibling.next_sibling\n        else:\n            for child in editor_h3.childGenerator():\n                if child.name == \"br\":\n                    editor_elements.append(group_elements)\n                    group_elements = []\n                else:\n                    group_elements.append(child)\n        for elements in editor_elements:\n            text = \"\".join([e.text for e in elements]).strip()\n            affiliation_key = text.split(\" \")[-1]\n            editor_name = text[: -len(affiliation_key)]\n            links = [e for e in elements if e.name == \"a\"]\n            homepage = links[0].attrs.get(\"href\", None) if len(links) &gt; 0 else None\n            editor = {\n                \"name\": editor_name,\n                \"homepage\": homepage,\n                \"affiliation_key\": affiliation_key,\n            }\n            editor_records[editor_name] = editor\n    affiliation_keys = {\n        editor.get(\"affiliation_key\")\n        for editor in editor_records.values()\n        if editor.get(\"affiliation_key\", None) is not None\n    }\n    affiliation_map = self.parseAffiliationMap(editor_h3.next_sibling)\n    for editor_record in editor_records.values():\n        editor_keys = editor_record.get(\"affiliation_keys\", \"\")\n        if editor_keys is not None:\n            keys = re.split(\"[, ]\", editor_keys)\n            editor_affiliations = []\n            for key in keys:\n                if key in affiliation_map:\n                    editor_affiliations.append(affiliation_map.get(key.strip()))\n            editor_record[\"affiliation\"] = editor_affiliations\n    return editor_records\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.parseRDFa","title":"<code>parseRDFa(soup)</code>","text":"<p>tries to parse rdfa content from the given soup Args:     soup: html parser to extract the content from</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>dict with the extracted content</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def parseRDFa(self, soup: BeautifulSoup) -&gt; dict:\n    \"\"\"\n    tries to parse rdfa content from the given soup\n    Args:\n        soup: html parser to extract the content from\n\n    Returns:\n        dict: dict with the extracted content\n    \"\"\"\n    scrapeDescr = [\n        ScrapeDescription(\n            key=\"volume_number\",\n            tag=\"span\",\n            attribute=\"class\",\n            value=\"CEURVOLNR\",\n        ),\n        ScrapeDescription(key=\"urn\", tag=\"span\", attribute=\"class\", value=\"CEURURN\"),\n        ScrapeDescription(key=\"year\", tag=\"span\", attribute=\"class\", value=\"CEURPUBYEAR\"),\n        ScrapeDescription(\n            key=\"ceurpubdate\",\n            tag=\"span\",\n            attribute=\"class\",\n            value=\"CEURPUBDATE\",\n        ),\n        ScrapeDescription(\n            key=\"acronym\",\n            tag=\"span\",\n            attribute=\"class\",\n            value=\"CEURVOLACRONYM\",\n        ),\n        ScrapeDescription(\n            key=\"voltitle\",\n            tag=\"span\",\n            attribute=\"class\",\n            value=\"CEURVOLTITLE\",\n        ),\n        ScrapeDescription(\n            key=\"title\",\n            tag=\"span\",\n            attribute=\"class\",\n            value=\"CEURFULLTITLE\",\n        ),\n        ScrapeDescription(\n            key=\"loctime\",\n            tag=\"span\",\n            attribute=\"class\",\n            value=\"CEURLOCTIME\",\n        ),\n        ScrapeDescription(\n            key=\"colocated\",\n            tag=\"span\",\n            attribute=\"class\",\n            value=\"CEURCOLOCATED\",\n        ),\n    ]\n    scrapedDict = self.scrape.parseWithScrapeDescription(soup, scrapeDescr)\n    return scrapedDict\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.parse_soup","title":"<code>parse_soup(soup, number=None)</code>","text":"<p>parse the volume page data from the given soup</p> <p>Parameters:</p> Name Type Description Default <code>number(str)</code> <p>the volume number</p> required <code>soup(BeautifulSoup)</code> <p>html parser to extract the content from</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>parsed content</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def parse_soup(self, soup: BeautifulSoup, number: str | None = None) -&gt; dict:\n    \"\"\"\n    parse the volume page data from the given soup\n\n    Args:\n        number(str): the volume number\n        soup(BeautifulSoup): html parser to extract the content from\n\n    Returns:\n        dict: parsed content\n    \"\"\"\n    if soup is None:\n        return {\"vol_number\": number}\n    # first try RDFa annotations\n    scrapedDict = self.parseRDFa(soup)\n    for key in scrapedDict:\n        scrapedDict[key] = Textparser.sanitize(scrapedDict[key])\n\n    # second part\n    for descValue in [\"description\", \"descripton\"]:\n        # descripton is a typo in the Volume index files not here!\n        firstDesc = soup.find(\"meta\", {\"name\": descValue})\n        if isinstance(firstDesc, Tag):\n            desc = firstDesc[\"content\"]\n            desc = Textparser.sanitize(desc, [\"CEUR Workshop Proceedings \"])\n            scrapedDict[\"desc\"] = desc\n            break\n\n    # first H1 has title info\n    firstH1 = soup.find(\"h1\")\n    if firstH1 is not None:\n        h1 = firstH1.text\n        h1 = Textparser.sanitize(h1, ['&lt;TD bgcolor=\"#FFFFFF\"&gt;'])\n        scrapedDict[\"h1\"] = h1\n        link = firstH1.find(\"a\")\n        if link is not None and isinstance(link, Tag) and len(link.text) &lt; 20:\n            acronym = link.text.strip()\n            if not acronym:\n                acronym = h1 if len(h1) &lt; 28 else h1.split()[0]\n\n            eventHomepage = link.attrs.get(\"href\")\n            scrapedDict[\"acronym\"] = acronym\n            scrapedDict[\"homepage\"] = eventHomepage\n\n    # first h3 has loctime\n    firstH3 = soup.find(\"h3\")\n    if firstH3 is not None:\n        h3 = firstH3.text\n        h3 = Textparser.sanitize(h3)\n        scrapedDict[\"h3\"] = h3\n\n    if self.hasValue(scrapedDict, \"desc\") and not self.hasValue(scrapedDict, \"acronym\"):\n        scrapedDict[\"acronym\"] = scrapedDict[\"desc\"]\n    if self.hasValue(scrapedDict, \"h1\") and not self.hasValue(scrapedDict, \"title\"):\n        scrapedDict[\"title\"] = scrapedDict[\"h1\"]\n    if (\n        self.hasValue(scrapedDict, \"h1\")\n        and self.hasValue(scrapedDict, \"title\")\n        and not self.hasValue(scrapedDict, \"acronym\")\n    ):\n        scrapedDict[\"acronym\"] = scrapedDict[\"h1\"]\n    # editorsRecords = self.parseEditors(soup)\n    # scrapedDict[\"editors\"] = editorsRecords\n    return scrapedDict\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.parse_volume","title":"<code>parse_volume(number, use_cache=True)</code>","text":"<p>parse the given volume caches the volume pages at ~/.ceurws/volumes</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>int</code> <p>volume number of the volume to parse</p> required <code>use_cache</code> <code>bool</code> <p>If True use volume page from cache if present otherwise load from web and cache</p> <code>True</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>tuple[dict, BeautifulSoup | None]</code> <p>extracted information</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def parse_volume(self, number: int, use_cache: bool = True) -&gt; tuple[dict, BeautifulSoup | None]:\n    \"\"\"\n    parse the given volume\n    caches the volume pages at ~/.ceurws/volumes\n\n    Args:\n        number: volume number of the volume to parse\n        use_cache: If True use volume page from cache if present otherwise load from web and cache\n\n    Returns:\n        dict: extracted information\n    \"\"\"\n    soup = self.get_volume_soup(number, use_cache=use_cache)\n    parsed_dict = self.parse_soup(number=str(number), soup=soup) if soup else {}\n    self.check_parsed_dict(parsed_dict)\n    return parsed_dict, soup\n</code></pre>"},{"location":"#ceurws.volumeparser.VolumeParser.volumeUrl","title":"<code>volumeUrl(volnumber)</code>","text":"<p>get the url for the given volume number</p> <p>Parameters:</p> Name Type Description Default <code>volnumber(str)</code> <p>the volume number</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>url - the url of the volume</p> Source code in <code>ceurws/volumeparser.py</code> <pre><code>def volumeUrl(self, volnumber: str | int):\n    \"\"\"\n    get the url for the given volume number\n\n    Args:\n        volnumber(str): the volume number\n\n    Returns:\n        str: url - the url of the volume\n    \"\"\"\n    # e.g. http://ceur-ws.org/Vol-2635/\n    url = f\"{self.baseurl}/Vol-{volnumber}\"\n    return url\n</code></pre>"},{"location":"#ceurws.webserver","title":"<code>webserver</code>","text":"<p>Created on 2024-02-22</p> <p>@author: wf</p>"},{"location":"#ceurws.webserver.CeurWsSolution","title":"<code>CeurWsSolution</code>","text":"<p>               Bases: <code>InputWebSolution</code></p> <p>CEUR-WS Volume browser solution</p> Source code in <code>ceurws/webserver.py</code> <pre><code>class CeurWsSolution(InputWebSolution):\n    \"\"\"\n    CEUR-WS Volume browser solution\n\n    \"\"\"\n\n    def __init__(self, webserver: CeurWsWebServer, client: Client):\n        \"\"\"\n        Initialize the solution\n\n        Calls the constructor of the base solution\n        Args:\n            webserver (CeurWsWebServer): The webserver instance associated with this context.\n            client (Client): The client instance this context is associated with.\n        \"\"\"\n        super().__init__(webserver, client)  # Call to the superclass constructor\n        self.wdSync = self.webserver.wdSync\n\n    def configure_menu(self):\n        InputWebSolution.configure_menu(self)\n        self.link_button(name=\"volumes\", icon_name=\"table\", target=\"/volumes\", new_tab=False)\n        self.link_button(name=\"wikidata\", icon_name=\"cloud_sync\", target=\"/wikidatasync\", new_tab=False)\n\n    def prepare_ui(self):\n        \"\"\"\n        prepare the user interface\n        \"\"\"\n        InputWebSolution.prepare_ui(self)\n        # does not work as expected ...\n        # self.add_css()\n\n    def add_css(self):\n        # Get the correct path to the 'css' directory\n        css_directory_path = Path(__file__).parent.parent / \"css\"\n        # Check if the directory exists before trying to serve it\n        if css_directory_path.is_dir():\n            # Serve files from the 'css' directory at the '/css' route\n            app.add_static_files(\"/css\", str(css_directory_path))\n\n            # Iterate over all .css files in the directory\n            for css_file in os.listdir(css_directory_path):\n                if css_file.endswith(\".css\"):\n                    # Add the link tag for the css file to the head of the HTML document\n                    ui.add_head_html(f'&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/css/{css_file}\"&gt;')\n\n    async def wikidatasync(self):\n        \"\"\"\n        show the wikidata sync table\n        \"\"\"\n\n        def show():\n            self.wikidata_view = WikidataView(self, self.container)\n\n        await self.setup_content_div(show)\n\n    async def volumes(self):\n        \"\"\"\n        show the volumes table\n        \"\"\"\n\n        def show():\n            self.volume_list_view = VolumeListView(self, self.container)\n\n        await self.setup_content_div(show)\n\n    async def home(self):\n        \"\"\"\n        home page selection\n        \"\"\"\n\n        def show():\n            try:\n                with self.container:\n                    with ui.row() as self.select_container:\n                        self.volume_select = self.add_select(\n                            \"Volume\",\n                            selection=self.wdSync.volumeOptions,\n                            with_input=True,\n                            on_change=self.volume_selected,\n                        ).props(\"size=120\")\n                    self.volume_view = VolumeView(self, self.container)\n            except Exception as ex:\n                self.handle_exception(ex)\n\n        await self.setup_content_div(show)\n\n    async def volume_selected(self, args: ValueChangeEventArguments):\n        \"\"\"\n        when a volume is selected show the details in the Volume View\n        \"\"\"\n        vol_number = args.value\n        volume = self.wdSync.volumesByNumber[vol_number]\n        self.volume_view.showVolume(volume)\n        pass\n</code></pre>"},{"location":"#ceurws.webserver.CeurWsSolution.__init__","title":"<code>__init__(webserver, client)</code>","text":"<p>Initialize the solution</p> <p>Calls the constructor of the base solution Args:     webserver (CeurWsWebServer): The webserver instance associated with this context.     client (Client): The client instance this context is associated with.</p> Source code in <code>ceurws/webserver.py</code> <pre><code>def __init__(self, webserver: CeurWsWebServer, client: Client):\n    \"\"\"\n    Initialize the solution\n\n    Calls the constructor of the base solution\n    Args:\n        webserver (CeurWsWebServer): The webserver instance associated with this context.\n        client (Client): The client instance this context is associated with.\n    \"\"\"\n    super().__init__(webserver, client)  # Call to the superclass constructor\n    self.wdSync = self.webserver.wdSync\n</code></pre>"},{"location":"#ceurws.webserver.CeurWsSolution.home","title":"<code>home()</code>  <code>async</code>","text":"<p>home page selection</p> Source code in <code>ceurws/webserver.py</code> <pre><code>async def home(self):\n    \"\"\"\n    home page selection\n    \"\"\"\n\n    def show():\n        try:\n            with self.container:\n                with ui.row() as self.select_container:\n                    self.volume_select = self.add_select(\n                        \"Volume\",\n                        selection=self.wdSync.volumeOptions,\n                        with_input=True,\n                        on_change=self.volume_selected,\n                    ).props(\"size=120\")\n                self.volume_view = VolumeView(self, self.container)\n        except Exception as ex:\n            self.handle_exception(ex)\n\n    await self.setup_content_div(show)\n</code></pre>"},{"location":"#ceurws.webserver.CeurWsSolution.prepare_ui","title":"<code>prepare_ui()</code>","text":"<p>prepare the user interface</p> Source code in <code>ceurws/webserver.py</code> <pre><code>def prepare_ui(self):\n    \"\"\"\n    prepare the user interface\n    \"\"\"\n    InputWebSolution.prepare_ui(self)\n</code></pre>"},{"location":"#ceurws.webserver.CeurWsSolution.volume_selected","title":"<code>volume_selected(args)</code>  <code>async</code>","text":"<p>when a volume is selected show the details in the Volume View</p> Source code in <code>ceurws/webserver.py</code> <pre><code>async def volume_selected(self, args: ValueChangeEventArguments):\n    \"\"\"\n    when a volume is selected show the details in the Volume View\n    \"\"\"\n    vol_number = args.value\n    volume = self.wdSync.volumesByNumber[vol_number]\n    self.volume_view.showVolume(volume)\n    pass\n</code></pre>"},{"location":"#ceurws.webserver.CeurWsSolution.volumes","title":"<code>volumes()</code>  <code>async</code>","text":"<p>show the volumes table</p> Source code in <code>ceurws/webserver.py</code> <pre><code>async def volumes(self):\n    \"\"\"\n    show the volumes table\n    \"\"\"\n\n    def show():\n        self.volume_list_view = VolumeListView(self, self.container)\n\n    await self.setup_content_div(show)\n</code></pre>"},{"location":"#ceurws.webserver.CeurWsSolution.wikidatasync","title":"<code>wikidatasync()</code>  <code>async</code>","text":"<p>show the wikidata sync table</p> Source code in <code>ceurws/webserver.py</code> <pre><code>async def wikidatasync(self):\n    \"\"\"\n    show the wikidata sync table\n    \"\"\"\n\n    def show():\n        self.wikidata_view = WikidataView(self, self.container)\n\n    await self.setup_content_div(show)\n</code></pre>"},{"location":"#ceurws.webserver.CeurWsWebServer","title":"<code>CeurWsWebServer</code>","text":"<p>               Bases: <code>InputWebserver</code></p> <p>webserver</p> Source code in <code>ceurws/webserver.py</code> <pre><code>class CeurWsWebServer(InputWebserver):\n    \"\"\"\n    webserver\n    \"\"\"\n\n    @classmethod\n    def get_config(cls) -&gt; WebserverConfig:\n        copy_right = \"(c)2023-2024 Wolfgang Fahl\"\n        config = WebserverConfig(\n            copy_right=copy_right,\n            version=Version(),\n            default_port=9998,\n            timeout=10.0,\n            short_name=\"spf\",\n        )\n        server_config = WebserverConfig.get(config)\n        server_config.solution_class = CeurWsSolution\n        return server_config\n\n    def __init__(self):\n        \"\"\"\n        constructor\n        \"\"\"\n        InputWebserver.__init__(self, config=CeurWsWebServer.get_config())\n\n        @ui.page(\"/volumes\")\n        async def show_volumes(client: Client):\n            return await self.page(client, CeurWsSolution.volumes)\n\n        @ui.page(\"/volume/{volnumber}\")\n        async def show_volume_page(client: Client, vol_number):\n            return await self.page(client, CeurWsSolution.volumePage, vol_number)\n\n        @ui.page(\"/wikidatasync\")\n        async def wikidatasync(client: Client):\n            return await self.page(client, CeurWsSolution.wikidatasync)\n\n        @app.get(\"/volumes.json\")\n        async def volumes():\n            \"\"\"\n            direct fastapi return of volumes\n            \"\"\"\n            volumeList = self.wdSync.vm.getList()\n            return volumeList\n\n        @app.get(\"/proceedings.json\")\n        async def proceedings():\n            \"\"\"\n            direct fastapi return of proceedings\n            \"\"\"\n            proceedingsList = self.wdSync.loadProceedingsFromCache()\n            return ORJSONResponse(proceedingsList)\n\n        @app.get(\"/papers.json\")\n        async def papers():\n            \"\"\"\n            direct fastapi return of papers\n            \"\"\"\n            paperList = self.wdSync.pm.getList()\n            return paperList\n\n        @app.get(\n            \"/papers_dblp.json\",\n            tags=[\"dblp complete dataset\"],\n            # response_model= List[DblpPaper]\n        )\n        async def papers_dblp():\n            \"\"\"\n            direct fastapi return of paper information from dblp\n            \"\"\"\n            self.wdSync.dblpEndpoint.dblp_papers.load()\n            papers = self.wdSync.dblpEndpoint.dblp_papers.papers\n            records = [p.to_json() for p in papers]\n            lod = [orjson.loads(json_str) for json_str in records]\n            return ORJSONResponse(lod)\n\n        @app.get(\n            \"/authors_dblp.json\",\n            tags=[\"dblp complete dataset\"],\n            # response_model=List[DblpAuthor]\n        )\n        async def authors_papers_dblp():\n            \"\"\"\n            direct fastapi return of paper information from dblp\n            \"\"\"\n            authors = self.wdSync.dblpEndpoint.get_all_ceur_authors()\n            return ORJSONResponse(content=authors)\n\n        @app.get(\"/dblp/papers\", tags=[\"dblp complete dataset\"])\n        async def dblp_papers(limit: int = 100, offset: int = 0) -&gt; list[DblpPaper]:\n            \"\"\"\n            Get ceur-ws volumes form dblp\n            Args:\n                limit: max number of returned papers\n                offset:\n\n            Returns:\n            \"\"\"\n            papers = self.wdSync.dblpEndpoint.get_all_ceur_papers()\n            return papers[offset:limit]\n\n        @app.get(\"/dblp/editors\", tags=[\"dblp complete dataset\"])\n        async def dblp_editors(limit: int = 100, offset: int = 0) -&gt; list[DblpScholar]:\n            \"\"\"\n            Get ceur-ws volume editors form dblp\n            Args:\n                limit: max number of returned papers\n                offset:\n\n            Returns:\n            \"\"\"\n            editors = self.wdSync.dblpEndpoint.get_all_ceur_editors()\n            return editors[offset:limit]\n\n        @app.get(\"/dblp/volumes\", tags=[\"dblp complete dataset\"])\n        async def dblp_volumes(limit: int = 100, offset: int = 0) -&gt; list[DblpPaper]:\n            \"\"\"\n            Get ceur-ws volumes form dblp\n            Args:\n                limit: max number of returned papers\n                offset:\n\n            Returns:\n            \"\"\"\n            proceedings = self.wdSync.dblpEndpoint.get_all_ceur_proceedings()\n            return proceedings[offset:limit]\n\n        @app.get(\"/dblp/volume/{volume_number}\", tags=[\"dblp\"])\n        async def dblp_volume(volume_number: int) -&gt; DblpProceeding:\n            \"\"\"\n            Get ceur-ws volume form dblp\n            \"\"\"\n            try:\n                proceeding = self.wdSync.dblpEndpoint.get_ceur_proceeding(volume_number)\n            except Exception as e:\n                raise HTTPException(status_code=404, detail=str(e)) from e\n            if proceeding:\n                return proceeding\n            else:\n                raise HTTPException(status_code=404, detail=\"Volume not found\")\n\n        @app.get(\"/dblp/volume/{volume_number}/editor\", tags=[\"dblp\"])\n        async def dblp_volume_editors(volume_number: int) -&gt; list[DblpScholar]:\n            \"\"\"\n            Get ceur-ws volume editors form dblp\n            \"\"\"\n            try:\n                proceeding = self.wdSync.dblpEndpoint.get_ceur_proceeding(volume_number)\n            except Exception as e:\n                raise HTTPException(status_code=404, detail=str(e)) from e\n            if proceeding:\n                return proceeding.editors\n            else:\n                raise HTTPException(status_code=404, detail=\"Volume not found\")\n\n        @app.get(\"/dblp/volume/{volume_number}/paper\", tags=[\"dblp\"])\n        async def dblp_volume_papers(volume_number: int) -&gt; list[DblpPaper]:\n            \"\"\"\n            Get ceur-ws volume papers form dblp\n            Args:\n                volume_number: number of the volume\n\n            Returns:\n            \"\"\"\n            papers = self.wdSync.dblpEndpoint.get_ceur_volume_papers(volume_number)\n            return papers\n\n        @app.get(\"/dblp/volume/{volume_number}/paper/{paper_id}\", tags=[\"dblp\"])\n        async def dblp_paper(volume_number: int, paper_id: str) -&gt; DblpPaper:\n            \"\"\"\n            Get ceur-ws volume paper form dblp\n            \"\"\"\n            papers = self.wdSync.dblpEndpoint.get_ceur_volume_papers(volume_number)\n            if papers:\n                for paper in papers:\n                    if paper.pdf_id == f\"Vol-{volume_number}/{paper_id}\":\n                        return paper\n                raise HTTPException(status_code=404, detail=\"Paper not found\")\n            else:\n                raise HTTPException(status_code=404, detail=\"Volume not found\")\n\n        @app.get(\n            \"/dblp/volume/{volume_number}/paper/{paper_id}/author\",\n            tags=[\"dblp\"],\n        )\n        async def dblp_paper_authors(volume_number: int, paper_id: str) -&gt; list[DblpScholar]:\n            \"\"\"\n            Get ceur-ws volume paper form dblp\n            \"\"\"\n            papers = self.wdSync.dblpEndpoint.get_ceur_volume_papers(volume_number)\n            if papers:\n                for paper in papers:\n                    if paper.pdf_id == f\"Vol-{volume_number}/{paper_id}\":\n                        return paper.authors\n                raise HTTPException(status_code=404, detail=\"Paper not found\")\n            else:\n                raise HTTPException(status_code=404, detail=\"Volume not found\")\n\n    def configure_run(self):\n        \"\"\"\n        configure command line specific details\n        \"\"\"\n        InputWebserver.configure_run(self)\n        self.wdSync = WikidataSync.from_args(self.args)\n</code></pre>"},{"location":"#ceurws.webserver.CeurWsWebServer.__init__","title":"<code>__init__()</code>","text":"<p>constructor</p> Source code in <code>ceurws/webserver.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    constructor\n    \"\"\"\n    InputWebserver.__init__(self, config=CeurWsWebServer.get_config())\n\n    @ui.page(\"/volumes\")\n    async def show_volumes(client: Client):\n        return await self.page(client, CeurWsSolution.volumes)\n\n    @ui.page(\"/volume/{volnumber}\")\n    async def show_volume_page(client: Client, vol_number):\n        return await self.page(client, CeurWsSolution.volumePage, vol_number)\n\n    @ui.page(\"/wikidatasync\")\n    async def wikidatasync(client: Client):\n        return await self.page(client, CeurWsSolution.wikidatasync)\n\n    @app.get(\"/volumes.json\")\n    async def volumes():\n        \"\"\"\n        direct fastapi return of volumes\n        \"\"\"\n        volumeList = self.wdSync.vm.getList()\n        return volumeList\n\n    @app.get(\"/proceedings.json\")\n    async def proceedings():\n        \"\"\"\n        direct fastapi return of proceedings\n        \"\"\"\n        proceedingsList = self.wdSync.loadProceedingsFromCache()\n        return ORJSONResponse(proceedingsList)\n\n    @app.get(\"/papers.json\")\n    async def papers():\n        \"\"\"\n        direct fastapi return of papers\n        \"\"\"\n        paperList = self.wdSync.pm.getList()\n        return paperList\n\n    @app.get(\n        \"/papers_dblp.json\",\n        tags=[\"dblp complete dataset\"],\n        # response_model= List[DblpPaper]\n    )\n    async def papers_dblp():\n        \"\"\"\n        direct fastapi return of paper information from dblp\n        \"\"\"\n        self.wdSync.dblpEndpoint.dblp_papers.load()\n        papers = self.wdSync.dblpEndpoint.dblp_papers.papers\n        records = [p.to_json() for p in papers]\n        lod = [orjson.loads(json_str) for json_str in records]\n        return ORJSONResponse(lod)\n\n    @app.get(\n        \"/authors_dblp.json\",\n        tags=[\"dblp complete dataset\"],\n        # response_model=List[DblpAuthor]\n    )\n    async def authors_papers_dblp():\n        \"\"\"\n        direct fastapi return of paper information from dblp\n        \"\"\"\n        authors = self.wdSync.dblpEndpoint.get_all_ceur_authors()\n        return ORJSONResponse(content=authors)\n\n    @app.get(\"/dblp/papers\", tags=[\"dblp complete dataset\"])\n    async def dblp_papers(limit: int = 100, offset: int = 0) -&gt; list[DblpPaper]:\n        \"\"\"\n        Get ceur-ws volumes form dblp\n        Args:\n            limit: max number of returned papers\n            offset:\n\n        Returns:\n        \"\"\"\n        papers = self.wdSync.dblpEndpoint.get_all_ceur_papers()\n        return papers[offset:limit]\n\n    @app.get(\"/dblp/editors\", tags=[\"dblp complete dataset\"])\n    async def dblp_editors(limit: int = 100, offset: int = 0) -&gt; list[DblpScholar]:\n        \"\"\"\n        Get ceur-ws volume editors form dblp\n        Args:\n            limit: max number of returned papers\n            offset:\n\n        Returns:\n        \"\"\"\n        editors = self.wdSync.dblpEndpoint.get_all_ceur_editors()\n        return editors[offset:limit]\n\n    @app.get(\"/dblp/volumes\", tags=[\"dblp complete dataset\"])\n    async def dblp_volumes(limit: int = 100, offset: int = 0) -&gt; list[DblpPaper]:\n        \"\"\"\n        Get ceur-ws volumes form dblp\n        Args:\n            limit: max number of returned papers\n            offset:\n\n        Returns:\n        \"\"\"\n        proceedings = self.wdSync.dblpEndpoint.get_all_ceur_proceedings()\n        return proceedings[offset:limit]\n\n    @app.get(\"/dblp/volume/{volume_number}\", tags=[\"dblp\"])\n    async def dblp_volume(volume_number: int) -&gt; DblpProceeding:\n        \"\"\"\n        Get ceur-ws volume form dblp\n        \"\"\"\n        try:\n            proceeding = self.wdSync.dblpEndpoint.get_ceur_proceeding(volume_number)\n        except Exception as e:\n            raise HTTPException(status_code=404, detail=str(e)) from e\n        if proceeding:\n            return proceeding\n        else:\n            raise HTTPException(status_code=404, detail=\"Volume not found\")\n\n    @app.get(\"/dblp/volume/{volume_number}/editor\", tags=[\"dblp\"])\n    async def dblp_volume_editors(volume_number: int) -&gt; list[DblpScholar]:\n        \"\"\"\n        Get ceur-ws volume editors form dblp\n        \"\"\"\n        try:\n            proceeding = self.wdSync.dblpEndpoint.get_ceur_proceeding(volume_number)\n        except Exception as e:\n            raise HTTPException(status_code=404, detail=str(e)) from e\n        if proceeding:\n            return proceeding.editors\n        else:\n            raise HTTPException(status_code=404, detail=\"Volume not found\")\n\n    @app.get(\"/dblp/volume/{volume_number}/paper\", tags=[\"dblp\"])\n    async def dblp_volume_papers(volume_number: int) -&gt; list[DblpPaper]:\n        \"\"\"\n        Get ceur-ws volume papers form dblp\n        Args:\n            volume_number: number of the volume\n\n        Returns:\n        \"\"\"\n        papers = self.wdSync.dblpEndpoint.get_ceur_volume_papers(volume_number)\n        return papers\n\n    @app.get(\"/dblp/volume/{volume_number}/paper/{paper_id}\", tags=[\"dblp\"])\n    async def dblp_paper(volume_number: int, paper_id: str) -&gt; DblpPaper:\n        \"\"\"\n        Get ceur-ws volume paper form dblp\n        \"\"\"\n        papers = self.wdSync.dblpEndpoint.get_ceur_volume_papers(volume_number)\n        if papers:\n            for paper in papers:\n                if paper.pdf_id == f\"Vol-{volume_number}/{paper_id}\":\n                    return paper\n            raise HTTPException(status_code=404, detail=\"Paper not found\")\n        else:\n            raise HTTPException(status_code=404, detail=\"Volume not found\")\n\n    @app.get(\n        \"/dblp/volume/{volume_number}/paper/{paper_id}/author\",\n        tags=[\"dblp\"],\n    )\n    async def dblp_paper_authors(volume_number: int, paper_id: str) -&gt; list[DblpScholar]:\n        \"\"\"\n        Get ceur-ws volume paper form dblp\n        \"\"\"\n        papers = self.wdSync.dblpEndpoint.get_ceur_volume_papers(volume_number)\n        if papers:\n            for paper in papers:\n                if paper.pdf_id == f\"Vol-{volume_number}/{paper_id}\":\n                    return paper.authors\n            raise HTTPException(status_code=404, detail=\"Paper not found\")\n        else:\n            raise HTTPException(status_code=404, detail=\"Volume not found\")\n</code></pre>"},{"location":"#ceurws.webserver.CeurWsWebServer.configure_run","title":"<code>configure_run()</code>","text":"<p>configure command line specific details</p> Source code in <code>ceurws/webserver.py</code> <pre><code>def configure_run(self):\n    \"\"\"\n    configure command line specific details\n    \"\"\"\n    InputWebserver.configure_run(self)\n    self.wdSync = WikidataSync.from_args(self.args)\n</code></pre>"},{"location":"#ceurws.wikidata_view","title":"<code>wikidata_view</code>","text":"<p>Created on 2024-02-23</p> <p>@author: wf</p>"},{"location":"#ceurws.wikidata_view.WikidataView","title":"<code>WikidataView</code>","text":"<p>               Bases: <code>View</code></p> <p>Wikidata View</p> Source code in <code>ceurws/wikidata_view.py</code> <pre><code>class WikidataView(View):\n    \"\"\"\n    Wikidata View\n    \"\"\"\n\n    def __init__(self, solution, parent):\n        \"\"\"\n        constructor\n\n        Args:\n            solution: the solution\n            parent: the parent UI container\n\n        \"\"\"\n        self.solution = solution\n        self.parent = parent\n        self.setup_ui()\n\n    async def update_proceedings(self):\n        \"\"\"\n        update the cached proceedings\n        \"\"\"\n        try:\n            self.proceedings_records = self.solution.wdSync.loadProceedingsFromCache()\n            with self.parent:\n                ui.notify(f\"found {len(self.proceedings_records)} cached wikidata proceedings records\")\n                self.reload_aggrid(self.proceedings_records)\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n\n    def reload_aggrid(self, olod: list):\n        \"\"\"\n        reload my aggrid with the list of Volumes\n        \"\"\"\n        reverseLod = sorted(\n            olod,\n            key=lambda row: int(row.get(\"sVolume\") or row.get(\"Volume\") or 0),\n            reverse=True,\n        )\n        lod = []\n        for row in reverseLod:\n            volume = self.getRowValue(row, \"sVolume\")\n            if volume == self.noneValue:\n                volume = self.getRowValue(row, \"Volume\")\n            if volume != self.noneValue:\n                try:\n                    vol_no = int(volume)\n                    volumeLink = self.createLink(\n                        f\"http://ceur-ws.org/Vol-{volume}\",\n                        f\"Vol-{vol_no:04}\",\n                    )\n                except Exception as _ex:\n                    volumeLink = self.noneValue\n            else:\n                volumeLink = self.noneValue\n            itemLink = self.createItemLink(row, \"item\")\n            eventLink = self.createItemLink(row, \"event\", separator=\"|\")\n            eventSeriesLink = self.createItemLink(row, \"eventSeries\", separator=\"|\")\n            dblpLink = self.createExternalLink(row, \"dblpProceedingsId\", \"dblp\", DblpEndpoint.DBLP_REC_PREFIX)\n            k10PlusLink = self.createExternalLink(\n                row, \"ppnId\", \"k10plus\", \"https://opac.k10plus.de/DB=2.299/PPNSET?PPN=\"\n            )\n            lod.append(\n                {\n                    \"#\": volume,\n                    \"item\": itemLink,\n                    \"volume\": volumeLink,\n                    \"acronym\": self.getRowValue(row, \"short_name\"),\n                    \"dblp\": dblpLink,\n                    \"k10plus\": k10PlusLink,\n                    \"event\": eventLink,\n                    \"series\": eventSeriesLink,\n                    \"ordinal\": self.getRowValue(row, \"eventSeriesOrdinal\"),\n                    # \"title\":row.get(\"title\",\"?\"),\n                }\n            )\n        self.lod_grid.load_lod(lod)\n        # set max width of Item column\n        self.lod_grid.set_column_def(\"item\", \"maxWidth\", 380)\n        self.lod_grid.set_column_def(\"event\", \"maxWidth\", 380)\n        self.lod_grid.sizeColumnsToFit()\n\n    async def on_refresh_button_click(self):\n        \"\"\"\n        handle the refreshing of the proceedings from wikidata\n        \"\"\"\n        await run.io_bound(self.refresh_wikidata)\n\n    def refresh_wikidata(self):\n        try:\n            with self.solution.container:\n                ui.notify(\"wikidata refresh button clicked\")\n            wd_records = self.solution.wdSync.update()\n            with self.solution.container:\n                ui.notify(f\"read {len(wd_records)} proceeding records from wikidata\")\n            with self.parent:\n                self.reload_aggrid(wd_records)\n            pass\n        except Exception as ex:\n            self.solution.handle_exception(ex)\n\n    def setup_ui(self):\n        \"\"\"\n        setup my User Interface elements\n        \"\"\"\n        with self.parent:\n            with ui.row() as self.tool_bar:\n                self.refresh_button = (\n                    ui.button(\n                        icon=\"refresh\",\n                        on_click=self.on_refresh_button_click,\n                    )\n                    .classes(\"btn btn-primary btn-sm col-1\")\n                    .tooltip(\"Refresh from Wikidata SPARQL endpoint\")\n                )\n                self.query_view = QueryView(\n                    self.solution,\n                    name=\"CEUR-WS wikidata sync\",\n                    sparql_endpoint=self.solution.wdSync.wikidata_endpoint,\n                )\n                self.query_view.show_query(self.solution.wdSync.wdQuery.query)\n\n            # grid_config = GridConfig(\n            #        key_col=\"Vol\",\n            #        multiselect=True)\n\n            self.lod_grid = ListOfDictsGrid()\n            ui.timer(0, self.update_proceedings, once=True)\n            pass\n</code></pre>"},{"location":"#ceurws.wikidata_view.WikidataView.__init__","title":"<code>__init__(solution, parent)</code>","text":"<p>constructor</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <p>the solution</p> required <code>parent</code> <p>the parent UI container</p> required Source code in <code>ceurws/wikidata_view.py</code> <pre><code>def __init__(self, solution, parent):\n    \"\"\"\n    constructor\n\n    Args:\n        solution: the solution\n        parent: the parent UI container\n\n    \"\"\"\n    self.solution = solution\n    self.parent = parent\n    self.setup_ui()\n</code></pre>"},{"location":"#ceurws.wikidata_view.WikidataView.on_refresh_button_click","title":"<code>on_refresh_button_click()</code>  <code>async</code>","text":"<p>handle the refreshing of the proceedings from wikidata</p> Source code in <code>ceurws/wikidata_view.py</code> <pre><code>async def on_refresh_button_click(self):\n    \"\"\"\n    handle the refreshing of the proceedings from wikidata\n    \"\"\"\n    await run.io_bound(self.refresh_wikidata)\n</code></pre>"},{"location":"#ceurws.wikidata_view.WikidataView.reload_aggrid","title":"<code>reload_aggrid(olod)</code>","text":"<p>reload my aggrid with the list of Volumes</p> Source code in <code>ceurws/wikidata_view.py</code> <pre><code>def reload_aggrid(self, olod: list):\n    \"\"\"\n    reload my aggrid with the list of Volumes\n    \"\"\"\n    reverseLod = sorted(\n        olod,\n        key=lambda row: int(row.get(\"sVolume\") or row.get(\"Volume\") or 0),\n        reverse=True,\n    )\n    lod = []\n    for row in reverseLod:\n        volume = self.getRowValue(row, \"sVolume\")\n        if volume == self.noneValue:\n            volume = self.getRowValue(row, \"Volume\")\n        if volume != self.noneValue:\n            try:\n                vol_no = int(volume)\n                volumeLink = self.createLink(\n                    f\"http://ceur-ws.org/Vol-{volume}\",\n                    f\"Vol-{vol_no:04}\",\n                )\n            except Exception as _ex:\n                volumeLink = self.noneValue\n        else:\n            volumeLink = self.noneValue\n        itemLink = self.createItemLink(row, \"item\")\n        eventLink = self.createItemLink(row, \"event\", separator=\"|\")\n        eventSeriesLink = self.createItemLink(row, \"eventSeries\", separator=\"|\")\n        dblpLink = self.createExternalLink(row, \"dblpProceedingsId\", \"dblp\", DblpEndpoint.DBLP_REC_PREFIX)\n        k10PlusLink = self.createExternalLink(\n            row, \"ppnId\", \"k10plus\", \"https://opac.k10plus.de/DB=2.299/PPNSET?PPN=\"\n        )\n        lod.append(\n            {\n                \"#\": volume,\n                \"item\": itemLink,\n                \"volume\": volumeLink,\n                \"acronym\": self.getRowValue(row, \"short_name\"),\n                \"dblp\": dblpLink,\n                \"k10plus\": k10PlusLink,\n                \"event\": eventLink,\n                \"series\": eventSeriesLink,\n                \"ordinal\": self.getRowValue(row, \"eventSeriesOrdinal\"),\n                # \"title\":row.get(\"title\",\"?\"),\n            }\n        )\n    self.lod_grid.load_lod(lod)\n    # set max width of Item column\n    self.lod_grid.set_column_def(\"item\", \"maxWidth\", 380)\n    self.lod_grid.set_column_def(\"event\", \"maxWidth\", 380)\n    self.lod_grid.sizeColumnsToFit()\n</code></pre>"},{"location":"#ceurws.wikidata_view.WikidataView.setup_ui","title":"<code>setup_ui()</code>","text":"<p>setup my User Interface elements</p> Source code in <code>ceurws/wikidata_view.py</code> <pre><code>def setup_ui(self):\n    \"\"\"\n    setup my User Interface elements\n    \"\"\"\n    with self.parent:\n        with ui.row() as self.tool_bar:\n            self.refresh_button = (\n                ui.button(\n                    icon=\"refresh\",\n                    on_click=self.on_refresh_button_click,\n                )\n                .classes(\"btn btn-primary btn-sm col-1\")\n                .tooltip(\"Refresh from Wikidata SPARQL endpoint\")\n            )\n            self.query_view = QueryView(\n                self.solution,\n                name=\"CEUR-WS wikidata sync\",\n                sparql_endpoint=self.solution.wdSync.wikidata_endpoint,\n            )\n            self.query_view.show_query(self.solution.wdSync.wdQuery.query)\n\n        # grid_config = GridConfig(\n        #        key_col=\"Vol\",\n        #        multiselect=True)\n\n        self.lod_grid = ListOfDictsGrid()\n        ui.timer(0, self.update_proceedings, once=True)\n        pass\n</code></pre>"},{"location":"#ceurws.wikidata_view.WikidataView.update_proceedings","title":"<code>update_proceedings()</code>  <code>async</code>","text":"<p>update the cached proceedings</p> Source code in <code>ceurws/wikidata_view.py</code> <pre><code>async def update_proceedings(self):\n    \"\"\"\n    update the cached proceedings\n    \"\"\"\n    try:\n        self.proceedings_records = self.solution.wdSync.loadProceedingsFromCache()\n        with self.parent:\n            ui.notify(f\"found {len(self.proceedings_records)} cached wikidata proceedings records\")\n            self.reload_aggrid(self.proceedings_records)\n    except Exception as ex:\n        self.solution.handle_exception(ex)\n</code></pre>"},{"location":"#ceurws.wikidatasync","title":"<code>wikidatasync</code>","text":"<p>Created on 2022-08-14</p> <p>@author: wf</p>"},{"location":"#ceurws.wikidatasync.WikidataSync","title":"<code>WikidataSync</code>","text":"<p>synchronize with wikidata</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>class WikidataSync:\n    \"\"\"\n    synchronize with wikidata\n    \"\"\"\n\n    def __init__(\n        self,\n        baseurl: str = \"https://www.wikidata.org\",\n        debug: bool = False,\n        dblp_endpoint_url: str | None = None,\n    ):\n        \"\"\"\n        Constructor\n\n        Args:\n            baseurl(str): the baseurl of the wikidata endpoint\n            debug(bool): if True switch on debugging\n            dblp_endpoint_url: sparql endpoint url of dblp\n        \"\"\"\n        if dblp_endpoint_url is None:\n            dblp_endpoint_url = DBLP_ENDPOINT.endpoint\n        self.debug = debug\n        self.prepareVolumeManager()\n        self.preparePaperManager()\n        self.prepareRDF()\n        self.wdQuery = self.qm.queriesByName[\"Proceedings\"]\n        self.baseurl = baseurl\n        self.wd = Wikidata(debug=debug)\n        self.sqldb = SQLDB(CEURWS.CACHE_FILE, check_same_thread=False)\n        self.procRecords = None\n        self.procsByVolnumber = None\n        self.dblpEndpoint = DblpEndpoint(endpoint=dblp_endpoint_url)\n        self.wikidata_endpoint: Endpoint | None = None\n\n    @classmethod\n    def from_args(cls, args) -&gt; \"WikidataSync\":\n        \"\"\"\n        create a WikidataSync object from the given command line arguments\n\n        Args:\n            args(Namespace): the command line arguments\n        \"\"\"\n        wd_en = args.wikidata_endpoint_name\n        dblp_en = args.dblp_endpoint_name\n        wd_sync = cls.from_endpoint_names(wd_en, dblp_en, debug=args.debug)\n        return wd_sync\n\n    @classmethod\n    def from_endpoint_names(cls, wd_en: str, dblp_en: str, debug: bool = False) -&gt; \"WikidataSync\":\n        \"\"\"\n        create a WikidataSync object from the given endpoint names\n\n        Args:\n            wd_en(str): wikidata endpoint name\n            dblp_en(str): dblp endpoint name\n        \"\"\"\n        endpoints = EndpointManager.getEndpoints()\n        if wd_en not in endpoints:\n            raise Exception(f\"invalid wikidata endpoint name {wd_en}\\nsee sparqlquery -le \")\n        if dblp_en not in endpoints:\n            raise Exception(f\"invalid dblp endpoint name {dblp_en}\\nsee sparqlquery -le \")\n        dblp_ep = endpoints[dblp_en]\n        wd_ep = endpoints[wd_en]\n        wd_sync = cls(\n            baseurl=wd_ep.endpoint,\n            dblp_endpoint_url=dblp_ep.endpoint,\n            debug=debug,\n        )\n        wd_sync.wikidata_endpoint = wd_ep\n        return wd_sync\n\n    def login(self):\n        self.wd.loginWithCredentials()\n\n    def logout(self):\n        self.wd.logout()\n\n    def itemUrl(self, qId):\n        url = f\"{self.baseurl}/wiki/{qId}\"\n        return url\n\n    def prepareRDF(self):\n        # SPARQL setup\n        self.endpoints = EndpointManager.getEndpoints(lang=\"sparql\")\n        self.endpointConf = self.endpoints.get(\"wikidata\")\n        self.sparql = SPARQL(self.endpointConf.endpoint)\n        path = os.path.dirname(__file__)\n        qYamlFile = f\"{path}/resources/queries/ceurws.yaml\"\n        if os.path.isfile(qYamlFile):\n            self.qm = QueryManager(lang=\"sparql\", queriesPath=qYamlFile)\n\n    def preparePaperManager(self):\n        \"\"\"\n        prepare my paper Manager\n        \"\"\"\n        self.pm = PaperManager()\n        if self.pm.isCached():\n            self.pm.fromStore(cacheFile=CEURWS.CACHE_FILE)\n        else:\n            print(\n                \"PaperManager not cached you might want to run ceur-ws --recreate\",\n                file=sys.stderr,\n            )\n\n    def prepareVolumeManager(self):\n        \"\"\"\n        prepare my volume manager\n        \"\"\"\n        self.vm = VolumeManager()\n        self.vm.load()\n        self.volumesByNumber, _duplicates = LOD.getLookup(self.vm.getList(), \"number\")\n        self.volumeList = self.vm.getList()\n        self.volumeCount = len(self.volumeList)\n        self.volumeOptions = {}\n        reverse_keys = sorted(self.volumesByNumber.keys(), reverse=True)\n        for volume_number in reverse_keys:\n            volume = self.volumesByNumber[volume_number]\n            self.volumeOptions[volume.number] = f\"Vol-{volume.number}:{volume.title}\"\n\n    def addVolume(self, volume: Volume):\n        \"\"\"\n        add the given volume\n\n        Args:\n            volume(Volume): the volume to add\n        \"\"\"\n        self.volumeList.append(volume)\n        self.volumesByNumber[volume.number] = volume\n        self.volumeCount += 1\n\n    def getRecentlyAddedVolumeList(self) -&gt; tuple[dict[int, dict], list[dict]]:\n        \"\"\"\n        get the list of volumes that have recently been added\n        we do not expect deletions\n\n        Returns:\n            list[int]: list of volume numbers recently added\n\n        \"\"\"\n        self.prepareVolumeManager()\n        refreshVm = VolumeManager()\n        parser_config = ParserConfig()\n        parser_config.force_download = True\n        self.vm.set_down_to_volume(parser_config)\n        refreshVm.loadFromIndexHtml(parser_config=parser_config)\n        refreshVolumesByNumber, _duplicates = LOD.getLookup(refreshVm.getList(), \"number\")\n        # https://stackoverflow.com/questions/3462143/get-difference-between-two-lists\n        newVolumes = list(set(list(refreshVolumesByNumber.keys())) - set(list(self.volumesByNumber.keys())))\n        return refreshVolumesByNumber, newVolumes\n\n    def storeVolumes(self):\n        \"\"\"\n        store my volumes\n        \"\"\"\n        self.vm.store()\n\n    def getWikidataProceedingsRecord(self, volume):\n        \"\"\"\n        get the wikidata Record for the given volume\n        \"\"\"\n        record = {\n            \"title\": getattr(volume, \"title\", None),\n            \"label\": getattr(volume, \"title\", None),\n            \"description\": f\"Proceedings of {getattr(volume, 'acronym', None)} workshop\",\n            \"urn\": getattr(volume, \"urn\", None),\n            \"short name\": getattr(volume, \"acronym\", None),\n            \"volume\": getattr(volume, \"number\", None),\n            \"pubDate\": getattr(volume, \"pubDate\", None),\n            \"ceurwsUrl\": getattr(volume, \"url\", None),\n            \"language of work or name\": \"Q1860\",\n            \"fullWorkUrl\": getattr(volume, \"url\", None),\n        }\n        if isinstance(record.get(\"pubDate\"), datetime.datetime):\n            record[\"pubDate\"] = record[\"pubDate\"].isoformat()\n        return record\n\n    def getWikidataEventRecord(self, volume: Volume):\n        \"\"\"\n        get the wikidata Record for the given volume\n        \"\"\"\n        volumeTitle = volume.title\n        volumeNumber = volume.number\n        dblpEntityIds = self.dblpEndpoint.getDblpIdByVolumeNumber(number=volumeNumber)\n        title = label = instanceOf = description = None\n        if volumeTitle:\n            instanceOf, description = self.getEventTypeFromTitle(volumeTitle)\n            title = label = self.getEventNameFromTitle(volumeTitle)\n        start_time = volume.dateFrom\n        end_time = volume.dateTo\n        record = {\n            \"title\": title,\n            \"label\": label,\n            \"description\": description,\n            \"instanceOf\": instanceOf,\n            \"short name\": volume.acronym,\n            \"locationWikidataId\": volume.cityWikidataId,\n            \"countryWikidataId\": volume.countryWikidataId,\n            \"start time\": start_time.isoformat() if start_time is not None else start_time,\n            \"end time\": end_time.isoformat() if end_time is not None else end_time,\n            \"referenceUrl\": volume.getVolumeUrl(),\n        }\n        if dblpEntityIds is not None and len(dblpEntityIds) &gt; 0:\n            dblpEntityId = dblpEntityIds[0]\n            record[\"describedAt\"] = self.dblpEndpoint.toDblpUrl(dblpEntityId)\n            record[\"language of work or name\"] = \"Q1860\"\n            record[\"dblpEventId\"] = self.dblpEndpoint.convertEntityIdToUrlId(entityId=dblpEntityId)\n        # the modeling of virtual events has changed in wikidata\n        # virtual event (Q7935096) is discontinued for conferences\n        # if volume.isVirtualEvent():\n        #     record[\"instanceOf\"] = [instanceOf, \"Q7935096\"]\n        return record\n\n    def update(self, withStore: bool = True):\n        \"\"\"\n        update my table from the Wikidata Proceedings SPARQL query\n        \"\"\"\n        if self.debug:\n            print(f\"Querying proceedings from {self.baseurl} ...\")\n        # query proceedings\n        wd_proceedings_records: list[dict] = self.sparql.queryAsListOfDicts(self.wdQuery.query)\n        # query events\n        event_query = self.qm.queriesByName[\"EventsByProceeding\"]\n        wd_event_records: list[dict] = self.sparql.queryAsListOfDicts(event_query.query)\n        # add events to proceeding records\n        proceedings_event_map, _duplicates = LOD.getLookup(wd_event_records, \"item\")\n        for proceedings_record in wd_proceedings_records:\n            item = proceedings_record.get(\"item\")\n            if item in proceedings_event_map:\n                event_record = proceedings_event_map.get(item)\n                proceedings_record.update(**event_record)\n        primaryKey = \"URN_NBN\"\n        withCreate = True\n        withDrop = True\n        entityInfo = self.sqldb.createTable(\n            wd_proceedings_records,\n            \"Proceedings\",\n            primaryKey,\n            withCreate,\n            withDrop,\n            sampleRecordCount=5000,\n            failIfTooFew=False,\n        )\n        procsByURN, duplicates = LOD.getLookup(wd_proceedings_records, \"URN_NBN\")\n        if withStore:\n            self.sqldb.store(procsByURN.values(), entityInfo, executeMany=True, fixNone=True)\n        if self.debug:\n            print(f\"stored {len(procsByURN.values())} proceedings records\")\n        if len(duplicates) &gt; 0:\n            print(f\"found {len(duplicates)} duplicates URN entries\")\n            if len(duplicates) &lt; 10:\n                print(duplicates)\n        return wd_proceedings_records\n\n    def loadProceedingsFromCache(self):\n        \"\"\"\n        load the proceedings records from the cache\n        \"\"\"\n        sqlQuery = \"SELECT * from Proceedings\"\n        self.procRecords = self.sqldb.query(sqlQuery)\n        return self.procRecords\n\n    def getProceedingsForVolume(self, searchVolnumber: int) -&gt; dict | None:\n        \"\"\"\n        get the proceedings record for the given searchVolnumber\n\n        Args:\n            searchVolnumber(int): the number of the volume to search\n\n        Returns:\n            dict: the record for the proceedings in wikidata\n            None: if the proceeding record in not found for the given searchVolnumber\n        \"\"\"\n        if self.procRecords is None:\n            self.loadProceedingsFromCache()\n        if self.procsByVolnumber is None:\n            self.procsByVolnumber: dict[int, dict] = {}\n            if isinstance(self.procRecords, list):\n                for procRecord in self.procRecords:\n                    volnumber = procRecord.get(\"sVolume\", None)\n                    if volnumber is None:\n                        procRecord.get(\"Volume\", None)\n                    if volnumber is not None:\n                        self.procsByVolnumber[int(volnumber)] = procRecord\n        volProcRecord = self.procsByVolnumber.get(searchVolnumber, None)\n        return volProcRecord\n\n    def getProceedingWdItemsByUrn(self, urn: str) -&gt; list[str]:\n        \"\"\"\n        queries the wikidata items that have the given urn for the property P4109\n        Args:\n            urn: URN id to query for\n\n        Returns:\n            List of corresponding wikidata item ids or empty list of no matching item is found\n        \"\"\"\n        query = f\"\"\"SELECT ?proceeding WHERE{{ ?proceeding wdt:P4109 \"{urn}\"}}\"\"\"\n        qres = self.sparql.queryAsListOfDicts(query)\n        wdItems = [record.get(\"proceeding\") for record in qres]\n        return wdItems\n\n    def getEventWdItemsByUrn(self, urn: str) -&gt; list[str]:\n        \"\"\"\n        queries the wikidata proceedings that have the given urn assigned to P4109 and returns the assigned event\n        Args:\n            urn: URN id to query for\n\n        Returns:\n            List of corresponding wikidata item ids or empty list of no matching item is found\n        \"\"\"\n        query = f\"\"\"SELECT ?event WHERE{{ ?proceeding wdt:P4109 \"{urn}\"; wdt:P4745 ?event .}}\"\"\"\n        qres = self.sparql.queryAsListOfDicts(query)\n        wdItems = [record.get(\"event\") for record in qres]\n        return wdItems\n\n    def getEventsOfProceedings(self, itemId: str) -&gt; list[str]:\n        \"\"\"\n        get the item ids of the events the given proceedings ids is the proceedings from\n        Args:\n            itemId: Qid of the proceedings\n\n        Returns:\n            List of the events\n        \"\"\"\n        query = f\"\"\"SELECT ?event WHERE {{ wd:{itemId} wdt:P4745 ?event.}}\"\"\"\n        qres = self.sparql.queryAsListOfDicts(query)\n        wdItems = [record.get(\"event\")[len(\"http://www.wikidata.org/entity/\") :] for record in qres]\n        return wdItems\n\n    def getEventsOfProceedingsByVolnumber(self, volnumber: int | str) -&gt; list[str]:\n        \"\"\"\n        get the item ids of the events the given proceedings ids is the proceedings from\n        Args:\n            volnumber: Volume number of the proceedings\n\n        Returns:\n            List of the events\n        \"\"\"\n        query = f\"\"\"SELECT ?event \n                    WHERE {{\n                    ?proceeding wdt:P31 wd:Q1143604; \n                                p:P179 [ps:P179 wd:Q27230297; pq:P478 \"{volnumber}\"]; \n                                wdt:P4745 ?event.}}\n        \"\"\"\n        qres = self.sparql.queryAsListOfDicts(query)\n        wdItems = [record.get(\"event\")[len(\"http://www.wikidata.org/entity/\") :] for record in qres]\n        return wdItems\n\n    def addProceedingsToWikidata(self, record: dict, write: bool = True, ignoreErrors: bool = False):\n        \"\"\"\n        Creates a wikidata entry for the given record\n\n        Args:\n            record(dict): the data to add\n            write(bool): if True actually write\n            ignoreErrors(bool): if True ignore errors\n\n        \"\"\"\n        if write:\n            self.login()\n        result = self.doAddProceedingsToWikidata(record, write, ignoreErrors)\n        if write:\n            self.logout()\n        return result\n\n    def doAddProceedingsToWikidata(\n        self, record: dict, write: bool = True, ignoreErrors: bool = False\n    ) -&gt; WikidataResult:\n        \"\"\"\n        Creates a wikidata proceedings entry for the given record\n\n        Args:\n            record(dict): the data to add\n            write(bool): if True actually write\n            ignoreErrors(bool): if True ignore errors\n        Returns:\n            WikidataResult: the result of the add operation\n        \"\"\"\n        mappings = [\n            PropertyMapping(\n                column=\"instanceof\",\n                propertyName=\"instanceof\",\n                propertyId=\"P31\",\n                propertyType=WdDatatype.itemid,\n                value=\"Q1143604\",\n            ),\n            PropertyMapping(\n                column=\"part of the series\",\n                propertyName=\"part of the series\",\n                propertyId=\"P179\",\n                propertyType=WdDatatype.itemid,\n                value=\"Q27230297\",\n            ),\n            PropertyMapping(\n                column=\"volume\",\n                propertyName=\"volume\",\n                propertyId=\"P478\",\n                propertyType=WdDatatype.string,\n                qualifierOf=\"part of the series\",\n            ),  # ToDo: refactor qualifier of anchor column or property name?\n            PropertyMapping(\n                column=\"short name\",\n                propertyName=\"short name\",\n                propertyId=\"P1813\",\n                propertyType=WdDatatype.text,\n            ),\n            PropertyMapping(\n                column=\"pubDate\",\n                propertyName=\"publication date\",\n                propertyId=\"P577\",\n                propertyType=WdDatatype.date,\n            ),\n            PropertyMapping(\n                column=\"title\",\n                propertyName=\"title\",\n                propertyId=\"P1476\",\n                propertyType=WdDatatype.text,\n            ),\n            PropertyMapping(\n                column=\"ceurwsUrl\",\n                propertyName=\"described at URL\",\n                propertyId=\"P973\",\n                propertyType=WdDatatype.url,\n            ),\n            PropertyMapping(\n                column=\"language of work or name\",\n                propertyName=\"language of work or name\",\n                propertyId=\"P407\",\n                propertyType=WdDatatype.itemid,\n                qualifierOf=\"ceurwsUrl\",\n            ),\n            PropertyMapping(\n                column=\"fullWorkUrl\",\n                propertyName=\"full work available at URL\",\n                propertyId=\"P953\",\n                propertyType=WdDatatype.url,\n            ),\n            PropertyMapping(\n                column=\"urn\",\n                propertyName=\"URN-NBN\",\n                propertyId=\"P4109\",\n                propertyType=WdDatatype.extid,\n            ),\n        ]\n        reference = UrlReference(url=record.get(\"ceurwsUrl\"))\n        result = self.wd.add_record(\n            record=record,\n            property_mappings=mappings,\n            write=write,\n            ignore_errors=ignoreErrors,\n            reference=reference,\n        )\n        return result\n\n    def askWikidata(self, askQuery: str) -&gt; bool:\n        try:\n            qres = self.sparql.rawQuery(askQuery).convert()\n            return qres.get(\"boolean\", False)\n        except Exception as ex:\n            print(ex)\n            return False\n\n    def checkIfProceedingsFromExists(self, volumeNumber: int, eventItemQid: str | None) -&gt; bool:\n        \"\"\"Returns True if the is proceedings from relation already exists between the given proceedings and event\"\"\"\n        eventVar = \"?event\"\n        if eventItemQid is not None:\n            eventVar = f\"wd:{eventItemQid}\"\n        proceedingsWikidataId = self.getWikidataIdByVolumeNumber(number=volumeNumber)\n        query = f\"\"\"ASK{{ wd:{proceedingsWikidataId} wdt:P4745 {eventVar}.}}\"\"\"\n        proceedingExists = self.askWikidata(query)\n        return proceedingExists\n\n    def hasItemPropertyValueFor(self, item, propertyId: str):\n        \"\"\"\n        ask wikidata if the given item has a value for the given property\n        Args:\n            item: item Qid\n            propertyId: property Pid\n        Returns:\n            True if the item has the property else False\n        \"\"\"\n        query = f\"\"\"ASK{{ wd:{item} wdt:{propertyId} ?value.}}\"\"\"\n        return self.askWikidata(query)\n\n    def addLinkBetweenProceedingsAndEvent(\n        self,\n        eventItemQid: str,\n        volumeNumber: int | None = None,\n        proceedingsWikidataId: str | None = None,\n        write: bool = True,\n        ignoreErrors: bool = False,\n    ) -&gt; WikidataResult:\n        \"\"\"\n        add the link between the wikidata proceedings item and the given event wikidata item\n        Args:\n            volumeNumber: ceurws volume number of the proceedings\n            eventItemQid: wikidata Qid of the event\n            proceedingsWikidataId: wikidata id of the proceedings item\n            write(bool): if True actually write\n            ignoreErrors(bool): if True ignore errors\n\n        Returns:\n            WikidataResult: the result of the add operation\n\n        Raises:\n            ValueError: if the volume number is not provided or the volume is not unique in Wikidata\n        \"\"\"\n        if proceedingsWikidataId is None:\n            proceedingsWikidataId = self.getWikidataIdByVolumeNumber(number=volumeNumber)\n        if proceedingsWikidataId is None:\n            raise ValueError(\"Volume is not unique \u2192 Proceedings item can not be determined\")\n        mappings = [\n            PropertyMapping(\n                column=\"isProceedingsFrom\",\n                propertyName=\"is proceedings from\",\n                propertyId=\"P4745\",\n                propertyType=WdDatatype.itemid,\n            )\n        ]\n        reference = None\n        if volumeNumber is not None:\n            volume_url = Volume.getVolumeUrlOf(volumeNumber)\n            reference = UrlReference(volume_url)\n        record = {\"isProceedingsFrom\": eventItemQid}\n        result = self.wd.add_record(\n            item_id=proceedingsWikidataId,\n            record=record,\n            property_mappings=mappings,\n            write=write,\n            ignore_errors=ignoreErrors,\n            reference=reference,\n        )\n        return result\n\n    def doAddEventToWikidata(self, record: dict, write: bool = True, ignoreErrors: bool = False):\n        \"\"\"\n        Creates a wikidata event entry for the given record\n        Args:\n            record(dict): the data to add\n            write(bool): if True actually write\n            ignoreErrors(bool): if True ignore errors\n\n        Returns:\n            WikidataResult: the result of the add operation\n        \"\"\"\n        entityQid = record.get(\"instanceOf\")\n        # entity = record.get(\"description\")\n        mappings = [\n            PropertyMapping(\n                column=\"instanceof\",\n                propertyName=\"instanceof\",\n                propertyId=\"P31\",\n                propertyType=WdDatatype.itemid,\n                value=entityQid,\n            ),\n            PropertyMapping(\n                column=\"short name\",\n                propertyName=\"short name\",\n                propertyId=\"P1813\",\n                propertyType=WdDatatype.text,\n            ),\n            PropertyMapping(\n                column=\"describedAt\",\n                propertyName=\"described at URL\",\n                propertyId=\"P973\",\n                propertyType=WdDatatype.url,\n            ),\n            PropertyMapping(\n                column=\"language of work or name\",\n                propertyName=\"language of work or name\",\n                propertyId=\"P407\",\n                propertyType=WdDatatype.itemid,\n                qualifierOf=\"describedAt\",\n                value=\"Q1860\",\n            ),\n            PropertyMapping(\n                column=\"title\",\n                propertyName=\"title\",\n                propertyId=\"P1476\",\n                propertyType=WdDatatype.text,\n            ),\n            PropertyMapping(\n                column=\"describedAt\",\n                propertyName=\"described at URL\",\n                propertyId=\"P973\",\n                propertyType=WdDatatype.url,\n            ),\n            PropertyMapping(\n                column=\"dblpEventId\",\n                propertyName=\"DBLP event ID\",\n                propertyId=\"P10692\",\n                propertyType=WdDatatype.extid,\n            ),\n            PropertyMapping(\n                column=\"start time\",\n                propertyName=\"start time\",\n                propertyId=\"P580\",\n                propertyType=WdDatatype.date,\n            ),\n            PropertyMapping(\n                column=\"end time\",\n                propertyName=\"end time\",\n                propertyId=\"P582\",\n                propertyType=WdDatatype.date,\n            ),\n            PropertyMapping(\n                column=\"locationWikidataId\",\n                propertyName=\"location\",\n                propertyId=\"P276\",\n                propertyType=WdDatatype.itemid,\n            ),\n            PropertyMapping(\n                column=\"countryWikidataId\",\n                propertyName=\"country\",\n                propertyId=\"P17\",\n                propertyType=WdDatatype.itemid,\n            ),\n        ]\n        reference_url = record.pop(\"referenceUrl\")\n        reference = UrlReference(url=reference_url)\n        result = self.wd.add_record(\n            record=record,\n            property_mappings=mappings,\n            write=write,\n            ignore_errors=ignoreErrors,\n            reference=reference,\n        )\n        return result\n\n    def addDblpPublicationId(\n        self,\n        volumeNumber: int,\n        dblpRecordId: str | None = None,\n        write: bool = True,\n        ignoreErrors: bool = False,\n    ) -&gt; WikidataResult:\n        \"\"\"\n        try to add the dblp publication id (P8978) to the proceedings record\n        Args:\n            volumeNumber: ceurws volumenumber of the proceedings\n            dblpRecordId: dblp record id to add to the proceedings item. If None query dblp for the record id\n            write: if True actually write\n            ignoreErrors(bool): if True ignore errors\n\n        Returns:\n            WikidataResult: the result of the add operation\n        \"\"\"\n        proceedingsWikidataId = self.getWikidataIdByVolumeNumber(number=volumeNumber)\n        if proceedingsWikidataId is None:\n            return False, \"Proceedings item can not be determined\"\n        if self.hasItemPropertyValueFor(item=proceedingsWikidataId, propertyId=\"P8978\"):\n            return (\n                False,\n                \"dblp publication id is already assigned to the proceedings item\",\n            )\n        if dblpRecordId is None:\n            dblpRecordIds = self.dblpEndpoint.getDblpIdByVolumeNumber(volumeNumber)\n            if len(dblpRecordIds) == 1:\n                dblpRecordId = dblpRecordIds[0]\n            elif len(dblpRecordIds) &gt; 1:\n                return (\n                    False,\n                    f\"More than one proceedings record found ({dblpRecordIds})\",\n                )\n            else:\n                return (\n                    False,\n                    f\"Proceedings of volume {volumeNumber} are not in dblp\",\n                )\n        mappings = [\n            PropertyMapping(\n                column=\"DBLP publication ID\",\n                propertyName=\"DBLP publication ID\",\n                propertyId=\"P8978\",\n                propertyType=WdDatatype.extid,\n            )\n        ]\n        wdMetadata = [\n            {\n                \"Entity\": \"proceedings\",\n                \"Column\": \"DBLP publication ID\",\n                \"PropertyName\": \"DBLP publication ID\",\n                \"PropertyId\": \"P8978\",\n                \"Type\": \"extid\",\n                \"Qualifier\": None,\n                \"Lookup\": \"\",\n            }\n        ]\n        mapDict, _ = LOD.getLookup(wdMetadata, \"PropertyId\")\n        volume_url = Volume.getVolumeUrlOf(volumeNumber)\n        reference = UrlReference(volume_url)\n        record = {\"DBLP publication ID\": dblpRecordId}\n        result = self.wd.add_record(\n            item_id=proceedingsWikidataId,\n            record=record,\n            property_mappings=mappings,\n            write=write,\n            ignore_errors=ignoreErrors,\n            reference=reference,\n        )\n        return result\n\n    def addAcronymToItem(\n        self,\n        itemId: str,\n        acronym: str,\n        desc: str | None = None,\n        label: str | None = None,\n        write: bool = True,\n        ignoreErrors: bool = False,\n    ):\n        \"\"\"\n        add the acronym to the given item\n        Args:\n            itemId: item to add the acronym to\n            acronym(str): acronym of the item\n            write(bool): if True actually write\n            ignoreErrors(bool): if True ignore errors\n\n        Returns:\n            (qid, errors) id of the created entry and occurred errors\n        \"\"\"\n        wdMetadata = [\n            {\n                \"Column\": \"short name\",\n                \"PropertyName\": \"short name\",\n                \"PropertyId\": \"P1813\",\n                \"Type\": \"text\",\n                \"Lookup\": \"\",\n            }\n        ]\n        record = {\"short name\": acronym, \"description\": desc, \"label\": label}\n        map_dict, _ = LOD.getLookup(wdMetadata, \"PropertyId\")\n        qId, errors = self.wd.addDict(\n            itemId=itemId,\n            row=record,\n            mapDict=map_dict,\n            write=write,\n            ignoreErrors=ignoreErrors,\n        )\n        return qId, errors\n\n    def addOfficialWebsiteToItem(\n        self,\n        itemId: str,\n        officialWebsite: str,\n        write: bool = True,\n        ignoreErrors: bool = False,\n    ):\n        \"\"\"\n        add the official website to the given item\n        Args:\n            itemId: item to add the acronym to\n            officialWebsite(str): officialWebsite of the item\n            write(bool): if True actually write\n            ignoreErrors(bool): if True ignore errors\n\n        Returns:\n            WikidataResult: the result of the add operation\n        \"\"\"\n        mappings = [\n            PropertyMapping(\n                column=\"official website\",\n                propertyName=\"official website\",\n                propertyId=\"P856\",\n                propertyType=WdDatatype.url,\n            ),\n            PropertyMapping(\n                column=\"language of work or name\",\n                propertyName=\"language of work or name\",\n                propertyId=\"P407\",\n                propertyType=WdDatatype.itemid,\n            ),\n        ]\n        record = {\n            \"official website\": officialWebsite,\n            \"language of work or name\": \"Q1860\",\n        }\n        qId, errors = self.wd.add_record(\n            item_id=itemId,\n            record=record,\n            property_mappings=mappings,\n            write=write,\n            ignore_errors=ignoreErrors,\n        )\n        return qId, errors\n\n    def getWikidataIdByVolumeNumber(self, number: int | None) -&gt; str | None:\n        \"\"\"\n        query wikidata for the qId of the proceedings of the given volume number\n        Args:\n            number: volume number\n\n        Returns:\n            str: wikidata id corresponding to the given volume number\n            None: if the corresponding wikidata id was not found\n        \"\"\"\n        if number is None:\n            return None\n        query = f\"\"\"SELECT * WHERE{{ ?proceeding p:P179 [ps:P179 wd:Q27230297; pq:P478 \"{number}\"].}}\"\"\"\n        qres = self.sparql.queryAsListOfDicts(query)\n        qid = None\n        if qres is not None and qres != []:\n            qids = [record.get(\"proceeding\").split(\"/\")[-1] for record in qres]\n            if len(qids) &gt; 1:\n                print(\"CEUR-WS volume number is not unique\")\n            else:\n                qid = qids[0]\n        return qid\n\n    def getWikidataIdByDblpEventId(self, entityId: str | None, volumeNumber: int | None = None) -&gt; list[str]:\n        \"\"\"\n        query wikidata for the qId of items that correspond to the given dblpEventId\n        Args:\n            entityId: id of a dblp event\n            volumeNumber: volume number\n\n        Returns:\n            list of matching wikidata items\n        \"\"\"\n        dblpEventId = self.dblpEndpoint.convertEntityIdToUrlId(entityId=entityId)\n        dblpIds = [entityId, dblpEventId]\n        dblpIdsStr = \" \".join([f'\"{dblpId}\"' for dblpId in dblpIds])\n        urls = \"\"\n        if entityId is not None:\n            urls = \" \".join(\n                [\n                    f\"&lt;{self.dblpEndpoint.toDblpUrl(entityId)}&gt;\",\n                    f\"&lt;{self.dblpEndpoint.toDblpUrl(entityId, True)}&gt;\",\n                ]\n            )\n        volumeQuery = \"\"\n        if volumeNumber is not None:\n            volumeQuery = f\"\"\"\n            UNION\n                  {{\n                  ?proceeding p:P179 [ps:P179 wd:Q27230297; pq:P478 \"{volumeNumber}\"].\n                  ?proceeding wdt:P4745 ?qid.\n                  }}\n            \"\"\"\n        query = f\"\"\"SELECT DISTINCT ?qid\n            WHERE{{\n              VALUES ?url {{ {urls} }}\n              VALUES ?dblpEventId {{ {dblpIdsStr} }}\n              VALUES ?eventType {{wd:Q2020153 wd:Q40444998}}\n              {{?qid wdt:P31 ?eventType; wdt:P973 ?url}}\n              UNION\n              {{?qid wdt:P31 ?eventType; wdt:P10692 ?dblpEventId}}\n              {volumeQuery}\n            }}\n        \"\"\"\n        qres = self.sparql.queryAsListOfDicts(query)\n        qIds = []\n        if qres is not None and qres != []:\n            qIds = [self.removeWdPrefix(record.get(\"qid\")) for record in qres]\n        return qIds\n\n    @classmethod\n    def getEventNameFromTitle(cls, title: str) -&gt; str:\n        \"\"\"\n        Get the event name from the given proceedings title\n        Args:\n            title: title of the proceeding\n\n        Returns:\n            name of the event\n        \"\"\"\n        prefixes = [\n            \"Proceedings of the\",\n            \"Proceedings of\",\n            \"Joint Proceedings of the\",\n            \"Joint Proceedings of\",\n            \"Joint Proceedings\",\n            \"Joint Proceeding of the\",\n            \"Joint Proceeding of\",\n            \"Selected Papers of the\",\n            \"Selected Contributions of the\",\n            \"Workshops Proceedings for the\",\n            \"Supplementary Proceedings of the\",\n            \"Short Paper Proceedings of\",\n            \"Short Paper Proceedings of the\",\n            \"Working Notes Proceedings of the\",\n            \"Working Notes of\",\n            \"Working Notes for\",\n            \"Joint Workshop Proceedings of the\",\n            \"Joint Workshop Proceedings of\",\n            \"Workshop Proceedings from\",\n            \"Workshop and Poster Proceedings of the\",\n            \"Workshops Proceedings and Tutorials of the\",\n            \"Extended Papers of the\",\n            \"Short Papers Proceedings of the\",\n            \"Short Papers Proceedings of\",\n            \"Proceedings of the Selected Papers of the\",\n            \"Proceedings of the Working Notes of\",\n            \"Proceedings of the Doctoral Consortium Papers Presented at the\",\n            \"Selected Contributions to the\",\n            \"Selected and Revised Papers of\",\n            \"Selected Papers of\",\n            \"Up-and-Coming and Short Papers of the\",\n            \"Academic Papers at\",\n            \"Poster Track of the\",\n            \"Actes de la\",\n            \"Post-proceedings of the\",\n            \"Late Breaking Papers of the\",\n            \"Anais do\",\n            \"Proceedings del\",\n            \"Proceedings\",\n            \"Gemeinsamer Tagungsband der\",\n            \"Local Proceedings of the\",\n            \"Local Proceedings and Materials of\",\n        ]\n        postfixes = [\n            \"Workshop Proceedings\",\n            \"Proceedings\",\n            \"Conference Proceedings\",\n            \"Workshops Proceedings\",\n            \"Adjunct Proceedings\",\n            \"Poster and Demo Proceedings\",\n            \"(full papers)\",\n        ]\n        if title is not None:\n            prefixes.sort(key=lambda prefix: len(prefix), reverse=True)\n            for prefix in prefixes:\n                if title.lower().startswith(prefix.lower()):\n                    title = title[len(prefix) :]\n                    title = title.strip()\n                    break\n            postfixes.sort(key=lambda postfix: len(postfix), reverse=True)\n            for postfix in postfixes:\n                if title.lower().endswith(postfix.lower()):\n                    title = title[: -len(postfix)]\n                    title = title.strip(\" .,\")\n                    break\n        return title\n\n    @classmethod\n    def getEventTypeFromTitle(cls, title: str) -&gt; tuple[str | None, str | None]:\n        \"\"\"\n        Extract the event type from the given title\n        Assumption: lowest mentioned type is the correct one\n        Args:\n            title: title of the event\n\n        Returns:\n            wikidata id and label of the event type\n        \"\"\"\n        if title is None or title == \"\":\n            return None, None\n        academicConference = (\"Q2020153\", \"academic conference\")\n        academicWorkshop = (\"Q40444998\", \"academic workshop\")\n        if \"workshop\" in title.lower():\n            return academicWorkshop\n        elif \"conference\" in title.lower() or \"symposium\" in title.lower():\n            return academicConference\n        else:\n            return academicWorkshop\n\n    def doCreateEventItemAndLinkProceedings(\n        self,\n        volume: Volume,\n        proceedingsWikidataId: str | None = None,\n        write: bool = False,\n    ) -&gt; dict[str, WikidataResult]:\n        \"\"\"\n        Create event  wikidata item for given volume and link the proceedings with the event\n        Args:\n            volume: volume to create the event for\n            proceedingsWikidataId: proceedings wikidata id of the event\n            write: If True actually write\n\n        Returns:\n            proceedingsQId, eventQId, msg\n        \"\"\"\n        results = {}\n        vol_number = volume.number\n        if (\n            proceedingsWikidataId is None\n            and vol_number is not None\n            and self.checkIfProceedingsFromExists(vol_number, eventItemQid=None)\n        ):\n            # link between proceedings and event already exists\n            proceedingsWikidataId = self.getWikidataIdByVolumeNumber(number=vol_number)\n            results[\"Proceedings\"] = WikidataResult(\n                qid=proceedingsWikidataId,\n                msg=f\"Proceedings for Vol-{vol_number} already exists\",\n            )\n        dblpEntityIds = self.dblpEndpoint.getDblpIdByVolumeNumber(vol_number)\n        dblpEntityId = None\n        msg = None\n        if len(dblpEntityIds) &gt; 1:\n            msg = f\"Multiple dblpEventIds found for Vol-{vol_number}: {','.join(dblpEntityIds)}\"\n        elif len(dblpEntityIds) == 1:\n            dblpEntityId = dblpEntityIds[0]\n        else:\n            dblpEntityId = None\n        results[\"dblp\"] = WikidataResult(qid=dblpEntityId, msg=msg)\n        wdItems = self.getWikidataIdByDblpEventId(dblpEntityId, vol_number)\n        msg = \"\"\n        eventQid = None\n        if len(wdItems) == 0:\n            # event item does not exist \u2192 create a new one\n            volume.resolveLoctime()\n            eventRecord = self.getWikidataEventRecord(volume)\n            event_result = self.doAddEventToWikidata(record=eventRecord, write=write)\n            eventQid = event_result.qid\n            results[\"Event\"] = event_result\n        elif len(wdItems) == 1:\n            results[\"Event\"] = WikidataResult(\n                # the event item already exists\n                qid=wdItems[0],\n                msg=\"Event item already exists;\",\n            )\n        else:\n            results[\"Event\"] = WikidataResult(msg=f\"Multiple event entries exist: {','.join(wdItems)}\")\n        if eventQid is not None:\n            # add link between Proceedings and the event item\n            link_result = self.addLinkBetweenProceedingsAndEvent(\n                volumeNumber=vol_number,\n                eventItemQid=eventQid,\n                proceedingsWikidataId=proceedingsWikidataId,\n                write=write,\n            )\n            link_result.msg = \"Added Link between Proceedings and Event item;\"\n            results[\"link\"] = link_result\n        return results\n\n    @classmethod\n    def removeWdPrefix(cls, value: str):\n        \"\"\"\n        removes the wikidata entity prefix\n        Args:\n            value: wikidata entity url\n        \"\"\"\n        wd_prefix = \"http://www.wikidata.org/entity/\"\n        if value is not None and isinstance(value, str) and value.startswith(wd_prefix):\n            value = value[len(\"http://www.wikidata.org/entity/\") :]\n        return value\n\n    def getAuthorByIds(self, identifiers: dict) -&gt; dict[str, str]:\n        \"\"\"\n        Based on the given identifiers get potential author items\n        the names of the identifiers must be according to DblpAuthorIdentifier\n        Args:\n            identifiers: known identifiers of the author\n        \"\"\"\n        if identifiers is None or len(identifiers) == 0:\n            return dict()\n        id_map = DblpAuthorIdentifier.getAllAsMap()\n        optional_clauses = []\n        for id_name, id_value in identifiers.items():\n            if id_value is not None and id_value != \"\":\n                id_query = None\n                if id_name in id_map:\n                    id_query = DblpAuthorIdentifier.getWikidataIdQueryPart(id_name, id_value, \"?person\")\n                else:\n                    if id_name == \"homepage\":\n                        id_query = f\"{{ ?person wdt:P856 &lt;{id_value}&gt;. }}\"\n                if id_query is not None:\n                    optional_clauses.append(id_query)\n        id_queries = \"\\nUNION\\n\".join(optional_clauses)\n        query = f\"\"\"SELECT DISTINCT ?person ?personLabel\n                    WHERE\n                    {{\n                        {id_queries}\n                        ?person rdfs:label ?personLabel. FILTER(lang(?personLabel)=\"en\").\n                    }}\"\"\"\n        qres = self.sparql.queryAsListOfDicts(query)\n        res = dict()\n        for record in qres:\n            if record is None or len(record) == 0:\n                continue\n            item_id = self.removeWdPrefix(record.get(\"person\"))\n            name = record.get(\"personLabel\")\n            res[item_id] = name\n        return res\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.__init__","title":"<code>__init__(baseurl='https://www.wikidata.org', debug=False, dblp_endpoint_url=None)</code>","text":"<p>Constructor</p> <p>Parameters:</p> Name Type Description Default <code>baseurl(str)</code> <p>the baseurl of the wikidata endpoint</p> required <code>debug(bool)</code> <p>if True switch on debugging</p> required <code>dblp_endpoint_url</code> <code>str | None</code> <p>sparql endpoint url of dblp</p> <code>None</code> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def __init__(\n    self,\n    baseurl: str = \"https://www.wikidata.org\",\n    debug: bool = False,\n    dblp_endpoint_url: str | None = None,\n):\n    \"\"\"\n    Constructor\n\n    Args:\n        baseurl(str): the baseurl of the wikidata endpoint\n        debug(bool): if True switch on debugging\n        dblp_endpoint_url: sparql endpoint url of dblp\n    \"\"\"\n    if dblp_endpoint_url is None:\n        dblp_endpoint_url = DBLP_ENDPOINT.endpoint\n    self.debug = debug\n    self.prepareVolumeManager()\n    self.preparePaperManager()\n    self.prepareRDF()\n    self.wdQuery = self.qm.queriesByName[\"Proceedings\"]\n    self.baseurl = baseurl\n    self.wd = Wikidata(debug=debug)\n    self.sqldb = SQLDB(CEURWS.CACHE_FILE, check_same_thread=False)\n    self.procRecords = None\n    self.procsByVolnumber = None\n    self.dblpEndpoint = DblpEndpoint(endpoint=dblp_endpoint_url)\n    self.wikidata_endpoint: Endpoint | None = None\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.addAcronymToItem","title":"<code>addAcronymToItem(itemId, acronym, desc=None, label=None, write=True, ignoreErrors=False)</code>","text":"<p>add the acronym to the given item Args:     itemId: item to add the acronym to     acronym(str): acronym of the item     write(bool): if True actually write     ignoreErrors(bool): if True ignore errors</p> <p>Returns:</p> Type Description <p>(qid, errors) id of the created entry and occurred errors</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def addAcronymToItem(\n    self,\n    itemId: str,\n    acronym: str,\n    desc: str | None = None,\n    label: str | None = None,\n    write: bool = True,\n    ignoreErrors: bool = False,\n):\n    \"\"\"\n    add the acronym to the given item\n    Args:\n        itemId: item to add the acronym to\n        acronym(str): acronym of the item\n        write(bool): if True actually write\n        ignoreErrors(bool): if True ignore errors\n\n    Returns:\n        (qid, errors) id of the created entry and occurred errors\n    \"\"\"\n    wdMetadata = [\n        {\n            \"Column\": \"short name\",\n            \"PropertyName\": \"short name\",\n            \"PropertyId\": \"P1813\",\n            \"Type\": \"text\",\n            \"Lookup\": \"\",\n        }\n    ]\n    record = {\"short name\": acronym, \"description\": desc, \"label\": label}\n    map_dict, _ = LOD.getLookup(wdMetadata, \"PropertyId\")\n    qId, errors = self.wd.addDict(\n        itemId=itemId,\n        row=record,\n        mapDict=map_dict,\n        write=write,\n        ignoreErrors=ignoreErrors,\n    )\n    return qId, errors\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.addDblpPublicationId","title":"<code>addDblpPublicationId(volumeNumber, dblpRecordId=None, write=True, ignoreErrors=False)</code>","text":"<p>try to add the dblp publication id (P8978) to the proceedings record Args:     volumeNumber: ceurws volumenumber of the proceedings     dblpRecordId: dblp record id to add to the proceedings item. If None query dblp for the record id     write: if True actually write     ignoreErrors(bool): if True ignore errors</p> <p>Returns:</p> Name Type Description <code>WikidataResult</code> <code>WikidataResult</code> <p>the result of the add operation</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def addDblpPublicationId(\n    self,\n    volumeNumber: int,\n    dblpRecordId: str | None = None,\n    write: bool = True,\n    ignoreErrors: bool = False,\n) -&gt; WikidataResult:\n    \"\"\"\n    try to add the dblp publication id (P8978) to the proceedings record\n    Args:\n        volumeNumber: ceurws volumenumber of the proceedings\n        dblpRecordId: dblp record id to add to the proceedings item. If None query dblp for the record id\n        write: if True actually write\n        ignoreErrors(bool): if True ignore errors\n\n    Returns:\n        WikidataResult: the result of the add operation\n    \"\"\"\n    proceedingsWikidataId = self.getWikidataIdByVolumeNumber(number=volumeNumber)\n    if proceedingsWikidataId is None:\n        return False, \"Proceedings item can not be determined\"\n    if self.hasItemPropertyValueFor(item=proceedingsWikidataId, propertyId=\"P8978\"):\n        return (\n            False,\n            \"dblp publication id is already assigned to the proceedings item\",\n        )\n    if dblpRecordId is None:\n        dblpRecordIds = self.dblpEndpoint.getDblpIdByVolumeNumber(volumeNumber)\n        if len(dblpRecordIds) == 1:\n            dblpRecordId = dblpRecordIds[0]\n        elif len(dblpRecordIds) &gt; 1:\n            return (\n                False,\n                f\"More than one proceedings record found ({dblpRecordIds})\",\n            )\n        else:\n            return (\n                False,\n                f\"Proceedings of volume {volumeNumber} are not in dblp\",\n            )\n    mappings = [\n        PropertyMapping(\n            column=\"DBLP publication ID\",\n            propertyName=\"DBLP publication ID\",\n            propertyId=\"P8978\",\n            propertyType=WdDatatype.extid,\n        )\n    ]\n    wdMetadata = [\n        {\n            \"Entity\": \"proceedings\",\n            \"Column\": \"DBLP publication ID\",\n            \"PropertyName\": \"DBLP publication ID\",\n            \"PropertyId\": \"P8978\",\n            \"Type\": \"extid\",\n            \"Qualifier\": None,\n            \"Lookup\": \"\",\n        }\n    ]\n    mapDict, _ = LOD.getLookup(wdMetadata, \"PropertyId\")\n    volume_url = Volume.getVolumeUrlOf(volumeNumber)\n    reference = UrlReference(volume_url)\n    record = {\"DBLP publication ID\": dblpRecordId}\n    result = self.wd.add_record(\n        item_id=proceedingsWikidataId,\n        record=record,\n        property_mappings=mappings,\n        write=write,\n        ignore_errors=ignoreErrors,\n        reference=reference,\n    )\n    return result\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.addLinkBetweenProceedingsAndEvent","title":"<code>addLinkBetweenProceedingsAndEvent(eventItemQid, volumeNumber=None, proceedingsWikidataId=None, write=True, ignoreErrors=False)</code>","text":"<p>add the link between the wikidata proceedings item and the given event wikidata item Args:     volumeNumber: ceurws volume number of the proceedings     eventItemQid: wikidata Qid of the event     proceedingsWikidataId: wikidata id of the proceedings item     write(bool): if True actually write     ignoreErrors(bool): if True ignore errors</p> <p>Returns:</p> Name Type Description <code>WikidataResult</code> <code>WikidataResult</code> <p>the result of the add operation</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the volume number is not provided or the volume is not unique in Wikidata</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def addLinkBetweenProceedingsAndEvent(\n    self,\n    eventItemQid: str,\n    volumeNumber: int | None = None,\n    proceedingsWikidataId: str | None = None,\n    write: bool = True,\n    ignoreErrors: bool = False,\n) -&gt; WikidataResult:\n    \"\"\"\n    add the link between the wikidata proceedings item and the given event wikidata item\n    Args:\n        volumeNumber: ceurws volume number of the proceedings\n        eventItemQid: wikidata Qid of the event\n        proceedingsWikidataId: wikidata id of the proceedings item\n        write(bool): if True actually write\n        ignoreErrors(bool): if True ignore errors\n\n    Returns:\n        WikidataResult: the result of the add operation\n\n    Raises:\n        ValueError: if the volume number is not provided or the volume is not unique in Wikidata\n    \"\"\"\n    if proceedingsWikidataId is None:\n        proceedingsWikidataId = self.getWikidataIdByVolumeNumber(number=volumeNumber)\n    if proceedingsWikidataId is None:\n        raise ValueError(\"Volume is not unique \u2192 Proceedings item can not be determined\")\n    mappings = [\n        PropertyMapping(\n            column=\"isProceedingsFrom\",\n            propertyName=\"is proceedings from\",\n            propertyId=\"P4745\",\n            propertyType=WdDatatype.itemid,\n        )\n    ]\n    reference = None\n    if volumeNumber is not None:\n        volume_url = Volume.getVolumeUrlOf(volumeNumber)\n        reference = UrlReference(volume_url)\n    record = {\"isProceedingsFrom\": eventItemQid}\n    result = self.wd.add_record(\n        item_id=proceedingsWikidataId,\n        record=record,\n        property_mappings=mappings,\n        write=write,\n        ignore_errors=ignoreErrors,\n        reference=reference,\n    )\n    return result\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.addOfficialWebsiteToItem","title":"<code>addOfficialWebsiteToItem(itemId, officialWebsite, write=True, ignoreErrors=False)</code>","text":"<p>add the official website to the given item Args:     itemId: item to add the acronym to     officialWebsite(str): officialWebsite of the item     write(bool): if True actually write     ignoreErrors(bool): if True ignore errors</p> <p>Returns:</p> Name Type Description <code>WikidataResult</code> <p>the result of the add operation</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def addOfficialWebsiteToItem(\n    self,\n    itemId: str,\n    officialWebsite: str,\n    write: bool = True,\n    ignoreErrors: bool = False,\n):\n    \"\"\"\n    add the official website to the given item\n    Args:\n        itemId: item to add the acronym to\n        officialWebsite(str): officialWebsite of the item\n        write(bool): if True actually write\n        ignoreErrors(bool): if True ignore errors\n\n    Returns:\n        WikidataResult: the result of the add operation\n    \"\"\"\n    mappings = [\n        PropertyMapping(\n            column=\"official website\",\n            propertyName=\"official website\",\n            propertyId=\"P856\",\n            propertyType=WdDatatype.url,\n        ),\n        PropertyMapping(\n            column=\"language of work or name\",\n            propertyName=\"language of work or name\",\n            propertyId=\"P407\",\n            propertyType=WdDatatype.itemid,\n        ),\n    ]\n    record = {\n        \"official website\": officialWebsite,\n        \"language of work or name\": \"Q1860\",\n    }\n    qId, errors = self.wd.add_record(\n        item_id=itemId,\n        record=record,\n        property_mappings=mappings,\n        write=write,\n        ignore_errors=ignoreErrors,\n    )\n    return qId, errors\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.addProceedingsToWikidata","title":"<code>addProceedingsToWikidata(record, write=True, ignoreErrors=False)</code>","text":"<p>Creates a wikidata entry for the given record</p> <p>Parameters:</p> Name Type Description Default <code>record(dict)</code> <p>the data to add</p> required <code>write(bool)</code> <p>if True actually write</p> required <code>ignoreErrors(bool)</code> <p>if True ignore errors</p> required Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def addProceedingsToWikidata(self, record: dict, write: bool = True, ignoreErrors: bool = False):\n    \"\"\"\n    Creates a wikidata entry for the given record\n\n    Args:\n        record(dict): the data to add\n        write(bool): if True actually write\n        ignoreErrors(bool): if True ignore errors\n\n    \"\"\"\n    if write:\n        self.login()\n    result = self.doAddProceedingsToWikidata(record, write, ignoreErrors)\n    if write:\n        self.logout()\n    return result\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.addVolume","title":"<code>addVolume(volume)</code>","text":"<p>add the given volume</p> <p>Parameters:</p> Name Type Description Default <code>volume(Volume)</code> <p>the volume to add</p> required Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def addVolume(self, volume: Volume):\n    \"\"\"\n    add the given volume\n\n    Args:\n        volume(Volume): the volume to add\n    \"\"\"\n    self.volumeList.append(volume)\n    self.volumesByNumber[volume.number] = volume\n    self.volumeCount += 1\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.checkIfProceedingsFromExists","title":"<code>checkIfProceedingsFromExists(volumeNumber, eventItemQid)</code>","text":"<p>Returns True if the is proceedings from relation already exists between the given proceedings and event</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def checkIfProceedingsFromExists(self, volumeNumber: int, eventItemQid: str | None) -&gt; bool:\n    \"\"\"Returns True if the is proceedings from relation already exists between the given proceedings and event\"\"\"\n    eventVar = \"?event\"\n    if eventItemQid is not None:\n        eventVar = f\"wd:{eventItemQid}\"\n    proceedingsWikidataId = self.getWikidataIdByVolumeNumber(number=volumeNumber)\n    query = f\"\"\"ASK{{ wd:{proceedingsWikidataId} wdt:P4745 {eventVar}.}}\"\"\"\n    proceedingExists = self.askWikidata(query)\n    return proceedingExists\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.doAddEventToWikidata","title":"<code>doAddEventToWikidata(record, write=True, ignoreErrors=False)</code>","text":"<p>Creates a wikidata event entry for the given record Args:     record(dict): the data to add     write(bool): if True actually write     ignoreErrors(bool): if True ignore errors</p> <p>Returns:</p> Name Type Description <code>WikidataResult</code> <p>the result of the add operation</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def doAddEventToWikidata(self, record: dict, write: bool = True, ignoreErrors: bool = False):\n    \"\"\"\n    Creates a wikidata event entry for the given record\n    Args:\n        record(dict): the data to add\n        write(bool): if True actually write\n        ignoreErrors(bool): if True ignore errors\n\n    Returns:\n        WikidataResult: the result of the add operation\n    \"\"\"\n    entityQid = record.get(\"instanceOf\")\n    # entity = record.get(\"description\")\n    mappings = [\n        PropertyMapping(\n            column=\"instanceof\",\n            propertyName=\"instanceof\",\n            propertyId=\"P31\",\n            propertyType=WdDatatype.itemid,\n            value=entityQid,\n        ),\n        PropertyMapping(\n            column=\"short name\",\n            propertyName=\"short name\",\n            propertyId=\"P1813\",\n            propertyType=WdDatatype.text,\n        ),\n        PropertyMapping(\n            column=\"describedAt\",\n            propertyName=\"described at URL\",\n            propertyId=\"P973\",\n            propertyType=WdDatatype.url,\n        ),\n        PropertyMapping(\n            column=\"language of work or name\",\n            propertyName=\"language of work or name\",\n            propertyId=\"P407\",\n            propertyType=WdDatatype.itemid,\n            qualifierOf=\"describedAt\",\n            value=\"Q1860\",\n        ),\n        PropertyMapping(\n            column=\"title\",\n            propertyName=\"title\",\n            propertyId=\"P1476\",\n            propertyType=WdDatatype.text,\n        ),\n        PropertyMapping(\n            column=\"describedAt\",\n            propertyName=\"described at URL\",\n            propertyId=\"P973\",\n            propertyType=WdDatatype.url,\n        ),\n        PropertyMapping(\n            column=\"dblpEventId\",\n            propertyName=\"DBLP event ID\",\n            propertyId=\"P10692\",\n            propertyType=WdDatatype.extid,\n        ),\n        PropertyMapping(\n            column=\"start time\",\n            propertyName=\"start time\",\n            propertyId=\"P580\",\n            propertyType=WdDatatype.date,\n        ),\n        PropertyMapping(\n            column=\"end time\",\n            propertyName=\"end time\",\n            propertyId=\"P582\",\n            propertyType=WdDatatype.date,\n        ),\n        PropertyMapping(\n            column=\"locationWikidataId\",\n            propertyName=\"location\",\n            propertyId=\"P276\",\n            propertyType=WdDatatype.itemid,\n        ),\n        PropertyMapping(\n            column=\"countryWikidataId\",\n            propertyName=\"country\",\n            propertyId=\"P17\",\n            propertyType=WdDatatype.itemid,\n        ),\n    ]\n    reference_url = record.pop(\"referenceUrl\")\n    reference = UrlReference(url=reference_url)\n    result = self.wd.add_record(\n        record=record,\n        property_mappings=mappings,\n        write=write,\n        ignore_errors=ignoreErrors,\n        reference=reference,\n    )\n    return result\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.doAddProceedingsToWikidata","title":"<code>doAddProceedingsToWikidata(record, write=True, ignoreErrors=False)</code>","text":"<p>Creates a wikidata proceedings entry for the given record</p> <p>Parameters:</p> Name Type Description Default <code>record(dict)</code> <p>the data to add</p> required <code>write(bool)</code> <p>if True actually write</p> required <code>ignoreErrors(bool)</code> <p>if True ignore errors</p> required <p>Returns:     WikidataResult: the result of the add operation</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def doAddProceedingsToWikidata(\n    self, record: dict, write: bool = True, ignoreErrors: bool = False\n) -&gt; WikidataResult:\n    \"\"\"\n    Creates a wikidata proceedings entry for the given record\n\n    Args:\n        record(dict): the data to add\n        write(bool): if True actually write\n        ignoreErrors(bool): if True ignore errors\n    Returns:\n        WikidataResult: the result of the add operation\n    \"\"\"\n    mappings = [\n        PropertyMapping(\n            column=\"instanceof\",\n            propertyName=\"instanceof\",\n            propertyId=\"P31\",\n            propertyType=WdDatatype.itemid,\n            value=\"Q1143604\",\n        ),\n        PropertyMapping(\n            column=\"part of the series\",\n            propertyName=\"part of the series\",\n            propertyId=\"P179\",\n            propertyType=WdDatatype.itemid,\n            value=\"Q27230297\",\n        ),\n        PropertyMapping(\n            column=\"volume\",\n            propertyName=\"volume\",\n            propertyId=\"P478\",\n            propertyType=WdDatatype.string,\n            qualifierOf=\"part of the series\",\n        ),  # ToDo: refactor qualifier of anchor column or property name?\n        PropertyMapping(\n            column=\"short name\",\n            propertyName=\"short name\",\n            propertyId=\"P1813\",\n            propertyType=WdDatatype.text,\n        ),\n        PropertyMapping(\n            column=\"pubDate\",\n            propertyName=\"publication date\",\n            propertyId=\"P577\",\n            propertyType=WdDatatype.date,\n        ),\n        PropertyMapping(\n            column=\"title\",\n            propertyName=\"title\",\n            propertyId=\"P1476\",\n            propertyType=WdDatatype.text,\n        ),\n        PropertyMapping(\n            column=\"ceurwsUrl\",\n            propertyName=\"described at URL\",\n            propertyId=\"P973\",\n            propertyType=WdDatatype.url,\n        ),\n        PropertyMapping(\n            column=\"language of work or name\",\n            propertyName=\"language of work or name\",\n            propertyId=\"P407\",\n            propertyType=WdDatatype.itemid,\n            qualifierOf=\"ceurwsUrl\",\n        ),\n        PropertyMapping(\n            column=\"fullWorkUrl\",\n            propertyName=\"full work available at URL\",\n            propertyId=\"P953\",\n            propertyType=WdDatatype.url,\n        ),\n        PropertyMapping(\n            column=\"urn\",\n            propertyName=\"URN-NBN\",\n            propertyId=\"P4109\",\n            propertyType=WdDatatype.extid,\n        ),\n    ]\n    reference = UrlReference(url=record.get(\"ceurwsUrl\"))\n    result = self.wd.add_record(\n        record=record,\n        property_mappings=mappings,\n        write=write,\n        ignore_errors=ignoreErrors,\n        reference=reference,\n    )\n    return result\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.doCreateEventItemAndLinkProceedings","title":"<code>doCreateEventItemAndLinkProceedings(volume, proceedingsWikidataId=None, write=False)</code>","text":"<p>Create event  wikidata item for given volume and link the proceedings with the event Args:     volume: volume to create the event for     proceedingsWikidataId: proceedings wikidata id of the event     write: If True actually write</p> <p>Returns:</p> Type Description <code>dict[str, WikidataResult]</code> <p>proceedingsQId, eventQId, msg</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def doCreateEventItemAndLinkProceedings(\n    self,\n    volume: Volume,\n    proceedingsWikidataId: str | None = None,\n    write: bool = False,\n) -&gt; dict[str, WikidataResult]:\n    \"\"\"\n    Create event  wikidata item for given volume and link the proceedings with the event\n    Args:\n        volume: volume to create the event for\n        proceedingsWikidataId: proceedings wikidata id of the event\n        write: If True actually write\n\n    Returns:\n        proceedingsQId, eventQId, msg\n    \"\"\"\n    results = {}\n    vol_number = volume.number\n    if (\n        proceedingsWikidataId is None\n        and vol_number is not None\n        and self.checkIfProceedingsFromExists(vol_number, eventItemQid=None)\n    ):\n        # link between proceedings and event already exists\n        proceedingsWikidataId = self.getWikidataIdByVolumeNumber(number=vol_number)\n        results[\"Proceedings\"] = WikidataResult(\n            qid=proceedingsWikidataId,\n            msg=f\"Proceedings for Vol-{vol_number} already exists\",\n        )\n    dblpEntityIds = self.dblpEndpoint.getDblpIdByVolumeNumber(vol_number)\n    dblpEntityId = None\n    msg = None\n    if len(dblpEntityIds) &gt; 1:\n        msg = f\"Multiple dblpEventIds found for Vol-{vol_number}: {','.join(dblpEntityIds)}\"\n    elif len(dblpEntityIds) == 1:\n        dblpEntityId = dblpEntityIds[0]\n    else:\n        dblpEntityId = None\n    results[\"dblp\"] = WikidataResult(qid=dblpEntityId, msg=msg)\n    wdItems = self.getWikidataIdByDblpEventId(dblpEntityId, vol_number)\n    msg = \"\"\n    eventQid = None\n    if len(wdItems) == 0:\n        # event item does not exist \u2192 create a new one\n        volume.resolveLoctime()\n        eventRecord = self.getWikidataEventRecord(volume)\n        event_result = self.doAddEventToWikidata(record=eventRecord, write=write)\n        eventQid = event_result.qid\n        results[\"Event\"] = event_result\n    elif len(wdItems) == 1:\n        results[\"Event\"] = WikidataResult(\n            # the event item already exists\n            qid=wdItems[0],\n            msg=\"Event item already exists;\",\n        )\n    else:\n        results[\"Event\"] = WikidataResult(msg=f\"Multiple event entries exist: {','.join(wdItems)}\")\n    if eventQid is not None:\n        # add link between Proceedings and the event item\n        link_result = self.addLinkBetweenProceedingsAndEvent(\n            volumeNumber=vol_number,\n            eventItemQid=eventQid,\n            proceedingsWikidataId=proceedingsWikidataId,\n            write=write,\n        )\n        link_result.msg = \"Added Link between Proceedings and Event item;\"\n        results[\"link\"] = link_result\n    return results\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.from_args","title":"<code>from_args(args)</code>  <code>classmethod</code>","text":"<p>create a WikidataSync object from the given command line arguments</p> <p>Parameters:</p> Name Type Description Default <code>args(Namespace)</code> <p>the command line arguments</p> required Source code in <code>ceurws/wikidatasync.py</code> <pre><code>@classmethod\ndef from_args(cls, args) -&gt; \"WikidataSync\":\n    \"\"\"\n    create a WikidataSync object from the given command line arguments\n\n    Args:\n        args(Namespace): the command line arguments\n    \"\"\"\n    wd_en = args.wikidata_endpoint_name\n    dblp_en = args.dblp_endpoint_name\n    wd_sync = cls.from_endpoint_names(wd_en, dblp_en, debug=args.debug)\n    return wd_sync\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.from_endpoint_names","title":"<code>from_endpoint_names(wd_en, dblp_en, debug=False)</code>  <code>classmethod</code>","text":"<p>create a WikidataSync object from the given endpoint names</p> <p>Parameters:</p> Name Type Description Default <code>wd_en(str)</code> <p>wikidata endpoint name</p> required <code>dblp_en(str)</code> <p>dblp endpoint name</p> required Source code in <code>ceurws/wikidatasync.py</code> <pre><code>@classmethod\ndef from_endpoint_names(cls, wd_en: str, dblp_en: str, debug: bool = False) -&gt; \"WikidataSync\":\n    \"\"\"\n    create a WikidataSync object from the given endpoint names\n\n    Args:\n        wd_en(str): wikidata endpoint name\n        dblp_en(str): dblp endpoint name\n    \"\"\"\n    endpoints = EndpointManager.getEndpoints()\n    if wd_en not in endpoints:\n        raise Exception(f\"invalid wikidata endpoint name {wd_en}\\nsee sparqlquery -le \")\n    if dblp_en not in endpoints:\n        raise Exception(f\"invalid dblp endpoint name {dblp_en}\\nsee sparqlquery -le \")\n    dblp_ep = endpoints[dblp_en]\n    wd_ep = endpoints[wd_en]\n    wd_sync = cls(\n        baseurl=wd_ep.endpoint,\n        dblp_endpoint_url=dblp_ep.endpoint,\n        debug=debug,\n    )\n    wd_sync.wikidata_endpoint = wd_ep\n    return wd_sync\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getAuthorByIds","title":"<code>getAuthorByIds(identifiers)</code>","text":"<p>Based on the given identifiers get potential author items the names of the identifiers must be according to DblpAuthorIdentifier Args:     identifiers: known identifiers of the author</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getAuthorByIds(self, identifiers: dict) -&gt; dict[str, str]:\n    \"\"\"\n    Based on the given identifiers get potential author items\n    the names of the identifiers must be according to DblpAuthorIdentifier\n    Args:\n        identifiers: known identifiers of the author\n    \"\"\"\n    if identifiers is None or len(identifiers) == 0:\n        return dict()\n    id_map = DblpAuthorIdentifier.getAllAsMap()\n    optional_clauses = []\n    for id_name, id_value in identifiers.items():\n        if id_value is not None and id_value != \"\":\n            id_query = None\n            if id_name in id_map:\n                id_query = DblpAuthorIdentifier.getWikidataIdQueryPart(id_name, id_value, \"?person\")\n            else:\n                if id_name == \"homepage\":\n                    id_query = f\"{{ ?person wdt:P856 &lt;{id_value}&gt;. }}\"\n            if id_query is not None:\n                optional_clauses.append(id_query)\n    id_queries = \"\\nUNION\\n\".join(optional_clauses)\n    query = f\"\"\"SELECT DISTINCT ?person ?personLabel\n                WHERE\n                {{\n                    {id_queries}\n                    ?person rdfs:label ?personLabel. FILTER(lang(?personLabel)=\"en\").\n                }}\"\"\"\n    qres = self.sparql.queryAsListOfDicts(query)\n    res = dict()\n    for record in qres:\n        if record is None or len(record) == 0:\n            continue\n        item_id = self.removeWdPrefix(record.get(\"person\"))\n        name = record.get(\"personLabel\")\n        res[item_id] = name\n    return res\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getEventNameFromTitle","title":"<code>getEventNameFromTitle(title)</code>  <code>classmethod</code>","text":"<p>Get the event name from the given proceedings title Args:     title: title of the proceeding</p> <p>Returns:</p> Type Description <code>str</code> <p>name of the event</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>@classmethod\ndef getEventNameFromTitle(cls, title: str) -&gt; str:\n    \"\"\"\n    Get the event name from the given proceedings title\n    Args:\n        title: title of the proceeding\n\n    Returns:\n        name of the event\n    \"\"\"\n    prefixes = [\n        \"Proceedings of the\",\n        \"Proceedings of\",\n        \"Joint Proceedings of the\",\n        \"Joint Proceedings of\",\n        \"Joint Proceedings\",\n        \"Joint Proceeding of the\",\n        \"Joint Proceeding of\",\n        \"Selected Papers of the\",\n        \"Selected Contributions of the\",\n        \"Workshops Proceedings for the\",\n        \"Supplementary Proceedings of the\",\n        \"Short Paper Proceedings of\",\n        \"Short Paper Proceedings of the\",\n        \"Working Notes Proceedings of the\",\n        \"Working Notes of\",\n        \"Working Notes for\",\n        \"Joint Workshop Proceedings of the\",\n        \"Joint Workshop Proceedings of\",\n        \"Workshop Proceedings from\",\n        \"Workshop and Poster Proceedings of the\",\n        \"Workshops Proceedings and Tutorials of the\",\n        \"Extended Papers of the\",\n        \"Short Papers Proceedings of the\",\n        \"Short Papers Proceedings of\",\n        \"Proceedings of the Selected Papers of the\",\n        \"Proceedings of the Working Notes of\",\n        \"Proceedings of the Doctoral Consortium Papers Presented at the\",\n        \"Selected Contributions to the\",\n        \"Selected and Revised Papers of\",\n        \"Selected Papers of\",\n        \"Up-and-Coming and Short Papers of the\",\n        \"Academic Papers at\",\n        \"Poster Track of the\",\n        \"Actes de la\",\n        \"Post-proceedings of the\",\n        \"Late Breaking Papers of the\",\n        \"Anais do\",\n        \"Proceedings del\",\n        \"Proceedings\",\n        \"Gemeinsamer Tagungsband der\",\n        \"Local Proceedings of the\",\n        \"Local Proceedings and Materials of\",\n    ]\n    postfixes = [\n        \"Workshop Proceedings\",\n        \"Proceedings\",\n        \"Conference Proceedings\",\n        \"Workshops Proceedings\",\n        \"Adjunct Proceedings\",\n        \"Poster and Demo Proceedings\",\n        \"(full papers)\",\n    ]\n    if title is not None:\n        prefixes.sort(key=lambda prefix: len(prefix), reverse=True)\n        for prefix in prefixes:\n            if title.lower().startswith(prefix.lower()):\n                title = title[len(prefix) :]\n                title = title.strip()\n                break\n        postfixes.sort(key=lambda postfix: len(postfix), reverse=True)\n        for postfix in postfixes:\n            if title.lower().endswith(postfix.lower()):\n                title = title[: -len(postfix)]\n                title = title.strip(\" .,\")\n                break\n    return title\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getEventTypeFromTitle","title":"<code>getEventTypeFromTitle(title)</code>  <code>classmethod</code>","text":"<p>Extract the event type from the given title Assumption: lowest mentioned type is the correct one Args:     title: title of the event</p> <p>Returns:</p> Type Description <code>tuple[str | None, str | None]</code> <p>wikidata id and label of the event type</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>@classmethod\ndef getEventTypeFromTitle(cls, title: str) -&gt; tuple[str | None, str | None]:\n    \"\"\"\n    Extract the event type from the given title\n    Assumption: lowest mentioned type is the correct one\n    Args:\n        title: title of the event\n\n    Returns:\n        wikidata id and label of the event type\n    \"\"\"\n    if title is None or title == \"\":\n        return None, None\n    academicConference = (\"Q2020153\", \"academic conference\")\n    academicWorkshop = (\"Q40444998\", \"academic workshop\")\n    if \"workshop\" in title.lower():\n        return academicWorkshop\n    elif \"conference\" in title.lower() or \"symposium\" in title.lower():\n        return academicConference\n    else:\n        return academicWorkshop\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getEventWdItemsByUrn","title":"<code>getEventWdItemsByUrn(urn)</code>","text":"<p>queries the wikidata proceedings that have the given urn assigned to P4109 and returns the assigned event Args:     urn: URN id to query for</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of corresponding wikidata item ids or empty list of no matching item is found</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getEventWdItemsByUrn(self, urn: str) -&gt; list[str]:\n    \"\"\"\n    queries the wikidata proceedings that have the given urn assigned to P4109 and returns the assigned event\n    Args:\n        urn: URN id to query for\n\n    Returns:\n        List of corresponding wikidata item ids or empty list of no matching item is found\n    \"\"\"\n    query = f\"\"\"SELECT ?event WHERE{{ ?proceeding wdt:P4109 \"{urn}\"; wdt:P4745 ?event .}}\"\"\"\n    qres = self.sparql.queryAsListOfDicts(query)\n    wdItems = [record.get(\"event\") for record in qres]\n    return wdItems\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getEventsOfProceedings","title":"<code>getEventsOfProceedings(itemId)</code>","text":"<p>get the item ids of the events the given proceedings ids is the proceedings from Args:     itemId: Qid of the proceedings</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of the events</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getEventsOfProceedings(self, itemId: str) -&gt; list[str]:\n    \"\"\"\n    get the item ids of the events the given proceedings ids is the proceedings from\n    Args:\n        itemId: Qid of the proceedings\n\n    Returns:\n        List of the events\n    \"\"\"\n    query = f\"\"\"SELECT ?event WHERE {{ wd:{itemId} wdt:P4745 ?event.}}\"\"\"\n    qres = self.sparql.queryAsListOfDicts(query)\n    wdItems = [record.get(\"event\")[len(\"http://www.wikidata.org/entity/\") :] for record in qres]\n    return wdItems\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getEventsOfProceedingsByVolnumber","title":"<code>getEventsOfProceedingsByVolnumber(volnumber)</code>","text":"<p>get the item ids of the events the given proceedings ids is the proceedings from Args:     volnumber: Volume number of the proceedings</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of the events</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getEventsOfProceedingsByVolnumber(self, volnumber: int | str) -&gt; list[str]:\n    \"\"\"\n    get the item ids of the events the given proceedings ids is the proceedings from\n    Args:\n        volnumber: Volume number of the proceedings\n\n    Returns:\n        List of the events\n    \"\"\"\n    query = f\"\"\"SELECT ?event \n                WHERE {{\n                ?proceeding wdt:P31 wd:Q1143604; \n                            p:P179 [ps:P179 wd:Q27230297; pq:P478 \"{volnumber}\"]; \n                            wdt:P4745 ?event.}}\n    \"\"\"\n    qres = self.sparql.queryAsListOfDicts(query)\n    wdItems = [record.get(\"event\")[len(\"http://www.wikidata.org/entity/\") :] for record in qres]\n    return wdItems\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getProceedingWdItemsByUrn","title":"<code>getProceedingWdItemsByUrn(urn)</code>","text":"<p>queries the wikidata items that have the given urn for the property P4109 Args:     urn: URN id to query for</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of corresponding wikidata item ids or empty list of no matching item is found</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getProceedingWdItemsByUrn(self, urn: str) -&gt; list[str]:\n    \"\"\"\n    queries the wikidata items that have the given urn for the property P4109\n    Args:\n        urn: URN id to query for\n\n    Returns:\n        List of corresponding wikidata item ids or empty list of no matching item is found\n    \"\"\"\n    query = f\"\"\"SELECT ?proceeding WHERE{{ ?proceeding wdt:P4109 \"{urn}\"}}\"\"\"\n    qres = self.sparql.queryAsListOfDicts(query)\n    wdItems = [record.get(\"proceeding\") for record in qres]\n    return wdItems\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getProceedingsForVolume","title":"<code>getProceedingsForVolume(searchVolnumber)</code>","text":"<p>get the proceedings record for the given searchVolnumber</p> <p>Parameters:</p> Name Type Description Default <code>searchVolnumber(int)</code> <p>the number of the volume to search</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict | None</code> <p>the record for the proceedings in wikidata</p> <code>None</code> <code>dict | None</code> <p>if the proceeding record in not found for the given searchVolnumber</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getProceedingsForVolume(self, searchVolnumber: int) -&gt; dict | None:\n    \"\"\"\n    get the proceedings record for the given searchVolnumber\n\n    Args:\n        searchVolnumber(int): the number of the volume to search\n\n    Returns:\n        dict: the record for the proceedings in wikidata\n        None: if the proceeding record in not found for the given searchVolnumber\n    \"\"\"\n    if self.procRecords is None:\n        self.loadProceedingsFromCache()\n    if self.procsByVolnumber is None:\n        self.procsByVolnumber: dict[int, dict] = {}\n        if isinstance(self.procRecords, list):\n            for procRecord in self.procRecords:\n                volnumber = procRecord.get(\"sVolume\", None)\n                if volnumber is None:\n                    procRecord.get(\"Volume\", None)\n                if volnumber is not None:\n                    self.procsByVolnumber[int(volnumber)] = procRecord\n    volProcRecord = self.procsByVolnumber.get(searchVolnumber, None)\n    return volProcRecord\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getRecentlyAddedVolumeList","title":"<code>getRecentlyAddedVolumeList()</code>","text":"<p>get the list of volumes that have recently been added we do not expect deletions</p> <p>Returns:</p> Type Description <code>tuple[dict[int, dict], list[dict]]</code> <p>list[int]: list of volume numbers recently added</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getRecentlyAddedVolumeList(self) -&gt; tuple[dict[int, dict], list[dict]]:\n    \"\"\"\n    get the list of volumes that have recently been added\n    we do not expect deletions\n\n    Returns:\n        list[int]: list of volume numbers recently added\n\n    \"\"\"\n    self.prepareVolumeManager()\n    refreshVm = VolumeManager()\n    parser_config = ParserConfig()\n    parser_config.force_download = True\n    self.vm.set_down_to_volume(parser_config)\n    refreshVm.loadFromIndexHtml(parser_config=parser_config)\n    refreshVolumesByNumber, _duplicates = LOD.getLookup(refreshVm.getList(), \"number\")\n    # https://stackoverflow.com/questions/3462143/get-difference-between-two-lists\n    newVolumes = list(set(list(refreshVolumesByNumber.keys())) - set(list(self.volumesByNumber.keys())))\n    return refreshVolumesByNumber, newVolumes\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getWikidataEventRecord","title":"<code>getWikidataEventRecord(volume)</code>","text":"<p>get the wikidata Record for the given volume</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getWikidataEventRecord(self, volume: Volume):\n    \"\"\"\n    get the wikidata Record for the given volume\n    \"\"\"\n    volumeTitle = volume.title\n    volumeNumber = volume.number\n    dblpEntityIds = self.dblpEndpoint.getDblpIdByVolumeNumber(number=volumeNumber)\n    title = label = instanceOf = description = None\n    if volumeTitle:\n        instanceOf, description = self.getEventTypeFromTitle(volumeTitle)\n        title = label = self.getEventNameFromTitle(volumeTitle)\n    start_time = volume.dateFrom\n    end_time = volume.dateTo\n    record = {\n        \"title\": title,\n        \"label\": label,\n        \"description\": description,\n        \"instanceOf\": instanceOf,\n        \"short name\": volume.acronym,\n        \"locationWikidataId\": volume.cityWikidataId,\n        \"countryWikidataId\": volume.countryWikidataId,\n        \"start time\": start_time.isoformat() if start_time is not None else start_time,\n        \"end time\": end_time.isoformat() if end_time is not None else end_time,\n        \"referenceUrl\": volume.getVolumeUrl(),\n    }\n    if dblpEntityIds is not None and len(dblpEntityIds) &gt; 0:\n        dblpEntityId = dblpEntityIds[0]\n        record[\"describedAt\"] = self.dblpEndpoint.toDblpUrl(dblpEntityId)\n        record[\"language of work or name\"] = \"Q1860\"\n        record[\"dblpEventId\"] = self.dblpEndpoint.convertEntityIdToUrlId(entityId=dblpEntityId)\n    # the modeling of virtual events has changed in wikidata\n    # virtual event (Q7935096) is discontinued for conferences\n    # if volume.isVirtualEvent():\n    #     record[\"instanceOf\"] = [instanceOf, \"Q7935096\"]\n    return record\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getWikidataIdByDblpEventId","title":"<code>getWikidataIdByDblpEventId(entityId, volumeNumber=None)</code>","text":"<p>query wikidata for the qId of items that correspond to the given dblpEventId Args:     entityId: id of a dblp event     volumeNumber: volume number</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list of matching wikidata items</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getWikidataIdByDblpEventId(self, entityId: str | None, volumeNumber: int | None = None) -&gt; list[str]:\n    \"\"\"\n    query wikidata for the qId of items that correspond to the given dblpEventId\n    Args:\n        entityId: id of a dblp event\n        volumeNumber: volume number\n\n    Returns:\n        list of matching wikidata items\n    \"\"\"\n    dblpEventId = self.dblpEndpoint.convertEntityIdToUrlId(entityId=entityId)\n    dblpIds = [entityId, dblpEventId]\n    dblpIdsStr = \" \".join([f'\"{dblpId}\"' for dblpId in dblpIds])\n    urls = \"\"\n    if entityId is not None:\n        urls = \" \".join(\n            [\n                f\"&lt;{self.dblpEndpoint.toDblpUrl(entityId)}&gt;\",\n                f\"&lt;{self.dblpEndpoint.toDblpUrl(entityId, True)}&gt;\",\n            ]\n        )\n    volumeQuery = \"\"\n    if volumeNumber is not None:\n        volumeQuery = f\"\"\"\n        UNION\n              {{\n              ?proceeding p:P179 [ps:P179 wd:Q27230297; pq:P478 \"{volumeNumber}\"].\n              ?proceeding wdt:P4745 ?qid.\n              }}\n        \"\"\"\n    query = f\"\"\"SELECT DISTINCT ?qid\n        WHERE{{\n          VALUES ?url {{ {urls} }}\n          VALUES ?dblpEventId {{ {dblpIdsStr} }}\n          VALUES ?eventType {{wd:Q2020153 wd:Q40444998}}\n          {{?qid wdt:P31 ?eventType; wdt:P973 ?url}}\n          UNION\n          {{?qid wdt:P31 ?eventType; wdt:P10692 ?dblpEventId}}\n          {volumeQuery}\n        }}\n    \"\"\"\n    qres = self.sparql.queryAsListOfDicts(query)\n    qIds = []\n    if qres is not None and qres != []:\n        qIds = [self.removeWdPrefix(record.get(\"qid\")) for record in qres]\n    return qIds\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getWikidataIdByVolumeNumber","title":"<code>getWikidataIdByVolumeNumber(number)</code>","text":"<p>query wikidata for the qId of the proceedings of the given volume number Args:     number: volume number</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str | None</code> <p>wikidata id corresponding to the given volume number</p> <code>None</code> <code>str | None</code> <p>if the corresponding wikidata id was not found</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getWikidataIdByVolumeNumber(self, number: int | None) -&gt; str | None:\n    \"\"\"\n    query wikidata for the qId of the proceedings of the given volume number\n    Args:\n        number: volume number\n\n    Returns:\n        str: wikidata id corresponding to the given volume number\n        None: if the corresponding wikidata id was not found\n    \"\"\"\n    if number is None:\n        return None\n    query = f\"\"\"SELECT * WHERE{{ ?proceeding p:P179 [ps:P179 wd:Q27230297; pq:P478 \"{number}\"].}}\"\"\"\n    qres = self.sparql.queryAsListOfDicts(query)\n    qid = None\n    if qres is not None and qres != []:\n        qids = [record.get(\"proceeding\").split(\"/\")[-1] for record in qres]\n        if len(qids) &gt; 1:\n            print(\"CEUR-WS volume number is not unique\")\n        else:\n            qid = qids[0]\n    return qid\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.getWikidataProceedingsRecord","title":"<code>getWikidataProceedingsRecord(volume)</code>","text":"<p>get the wikidata Record for the given volume</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def getWikidataProceedingsRecord(self, volume):\n    \"\"\"\n    get the wikidata Record for the given volume\n    \"\"\"\n    record = {\n        \"title\": getattr(volume, \"title\", None),\n        \"label\": getattr(volume, \"title\", None),\n        \"description\": f\"Proceedings of {getattr(volume, 'acronym', None)} workshop\",\n        \"urn\": getattr(volume, \"urn\", None),\n        \"short name\": getattr(volume, \"acronym\", None),\n        \"volume\": getattr(volume, \"number\", None),\n        \"pubDate\": getattr(volume, \"pubDate\", None),\n        \"ceurwsUrl\": getattr(volume, \"url\", None),\n        \"language of work or name\": \"Q1860\",\n        \"fullWorkUrl\": getattr(volume, \"url\", None),\n    }\n    if isinstance(record.get(\"pubDate\"), datetime.datetime):\n        record[\"pubDate\"] = record[\"pubDate\"].isoformat()\n    return record\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.hasItemPropertyValueFor","title":"<code>hasItemPropertyValueFor(item, propertyId)</code>","text":"<p>ask wikidata if the given item has a value for the given property Args:     item: item Qid     propertyId: property Pid Returns:     True if the item has the property else False</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def hasItemPropertyValueFor(self, item, propertyId: str):\n    \"\"\"\n    ask wikidata if the given item has a value for the given property\n    Args:\n        item: item Qid\n        propertyId: property Pid\n    Returns:\n        True if the item has the property else False\n    \"\"\"\n    query = f\"\"\"ASK{{ wd:{item} wdt:{propertyId} ?value.}}\"\"\"\n    return self.askWikidata(query)\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.loadProceedingsFromCache","title":"<code>loadProceedingsFromCache()</code>","text":"<p>load the proceedings records from the cache</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def loadProceedingsFromCache(self):\n    \"\"\"\n    load the proceedings records from the cache\n    \"\"\"\n    sqlQuery = \"SELECT * from Proceedings\"\n    self.procRecords = self.sqldb.query(sqlQuery)\n    return self.procRecords\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.preparePaperManager","title":"<code>preparePaperManager()</code>","text":"<p>prepare my paper Manager</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def preparePaperManager(self):\n    \"\"\"\n    prepare my paper Manager\n    \"\"\"\n    self.pm = PaperManager()\n    if self.pm.isCached():\n        self.pm.fromStore(cacheFile=CEURWS.CACHE_FILE)\n    else:\n        print(\n            \"PaperManager not cached you might want to run ceur-ws --recreate\",\n            file=sys.stderr,\n        )\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.prepareVolumeManager","title":"<code>prepareVolumeManager()</code>","text":"<p>prepare my volume manager</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def prepareVolumeManager(self):\n    \"\"\"\n    prepare my volume manager\n    \"\"\"\n    self.vm = VolumeManager()\n    self.vm.load()\n    self.volumesByNumber, _duplicates = LOD.getLookup(self.vm.getList(), \"number\")\n    self.volumeList = self.vm.getList()\n    self.volumeCount = len(self.volumeList)\n    self.volumeOptions = {}\n    reverse_keys = sorted(self.volumesByNumber.keys(), reverse=True)\n    for volume_number in reverse_keys:\n        volume = self.volumesByNumber[volume_number]\n        self.volumeOptions[volume.number] = f\"Vol-{volume.number}:{volume.title}\"\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.removeWdPrefix","title":"<code>removeWdPrefix(value)</code>  <code>classmethod</code>","text":"<p>removes the wikidata entity prefix Args:     value: wikidata entity url</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>@classmethod\ndef removeWdPrefix(cls, value: str):\n    \"\"\"\n    removes the wikidata entity prefix\n    Args:\n        value: wikidata entity url\n    \"\"\"\n    wd_prefix = \"http://www.wikidata.org/entity/\"\n    if value is not None and isinstance(value, str) and value.startswith(wd_prefix):\n        value = value[len(\"http://www.wikidata.org/entity/\") :]\n    return value\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.storeVolumes","title":"<code>storeVolumes()</code>","text":"<p>store my volumes</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def storeVolumes(self):\n    \"\"\"\n    store my volumes\n    \"\"\"\n    self.vm.store()\n</code></pre>"},{"location":"#ceurws.wikidatasync.WikidataSync.update","title":"<code>update(withStore=True)</code>","text":"<p>update my table from the Wikidata Proceedings SPARQL query</p> Source code in <code>ceurws/wikidatasync.py</code> <pre><code>def update(self, withStore: bool = True):\n    \"\"\"\n    update my table from the Wikidata Proceedings SPARQL query\n    \"\"\"\n    if self.debug:\n        print(f\"Querying proceedings from {self.baseurl} ...\")\n    # query proceedings\n    wd_proceedings_records: list[dict] = self.sparql.queryAsListOfDicts(self.wdQuery.query)\n    # query events\n    event_query = self.qm.queriesByName[\"EventsByProceeding\"]\n    wd_event_records: list[dict] = self.sparql.queryAsListOfDicts(event_query.query)\n    # add events to proceeding records\n    proceedings_event_map, _duplicates = LOD.getLookup(wd_event_records, \"item\")\n    for proceedings_record in wd_proceedings_records:\n        item = proceedings_record.get(\"item\")\n        if item in proceedings_event_map:\n            event_record = proceedings_event_map.get(item)\n            proceedings_record.update(**event_record)\n    primaryKey = \"URN_NBN\"\n    withCreate = True\n    withDrop = True\n    entityInfo = self.sqldb.createTable(\n        wd_proceedings_records,\n        \"Proceedings\",\n        primaryKey,\n        withCreate,\n        withDrop,\n        sampleRecordCount=5000,\n        failIfTooFew=False,\n    )\n    procsByURN, duplicates = LOD.getLookup(wd_proceedings_records, \"URN_NBN\")\n    if withStore:\n        self.sqldb.store(procsByURN.values(), entityInfo, executeMany=True, fixNone=True)\n    if self.debug:\n        print(f\"stored {len(procsByURN.values())} proceedings records\")\n    if len(duplicates) &gt; 0:\n        print(f\"found {len(duplicates)} duplicates URN entries\")\n        if len(duplicates) &lt; 10:\n            print(duplicates)\n    return wd_proceedings_records\n</code></pre>"},{"location":"#ceurws.workshop","title":"<code>workshop</code>","text":"<p>Created on 2020-11-12</p> <p>@author: wf</p>"},{"location":"#ceurws.workshop.Workshop","title":"<code>Workshop</code>","text":"<p>a single Workshop</p> Source code in <code>ceurws/workshop.py</code> <pre><code>class Workshop:\n    \"\"\"\n    a single Workshop\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Constructor\n        \"\"\"\n\n    @staticmethod\n    def ofURI(uri):\n        xml = urlopen(uri).read().decode()\n        ws = Workshop()\n        ws.wsdict = xmltodict.parse(xml)\n        return ws\n</code></pre>"},{"location":"#ceurws.workshop.Workshop.__init__","title":"<code>__init__()</code>","text":"<p>Constructor</p> Source code in <code>ceurws/workshop.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Constructor\n    \"\"\"\n</code></pre>"}]}